

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Examples &mdash; pyDML 0.0.1 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Installation" href="installation.html" />
    <link rel="prev" title="Applications" href="applications.html" /> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> pyDML
          

          
          </a>

          
            
            
              <div class="version">
                0.0.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Current Algorithms:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dml.pca.html">Principal Component Analysis (PCA)</a></li>
<li class="toctree-l1"><a class="reference internal" href="dml.lda.html">Linear Discriminant Analysis (LDA)</a></li>
<li class="toctree-l1"><a class="reference internal" href="dml.anmm.html">Average Neighborhood Margin Maximization (ANMM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="dml.lmnn.html">Large Margin Nearest Neighbors (LMNN)</a></li>
<li class="toctree-l1"><a class="reference internal" href="dml.nca.html">Neighborhood Component Analysis (NCA)</a></li>
<li class="toctree-l1"><a class="reference internal" href="dml.ncmml.html">Nearest Class Mean Metric Learning (NCMML)</a></li>
<li class="toctree-l1"><a class="reference internal" href="dml.ncmc.html">Nearest Class with Multiple Centroids (NCMC)</a></li>
<li class="toctree-l1"><a class="reference internal" href="dml.itml.html">Information Theoretic Metric Learning (ITML)</a></li>
<li class="toctree-l1"><a class="reference internal" href="dml.dmlmj.html">Distance Metric Learning through the Maximization of the Jeffrey Divergence (DMLMJ)</a></li>
<li class="toctree-l1"><a class="reference internal" href="dml.mcml.html">Maximally Collapsing Metric Learning (MCML)</a></li>
<li class="toctree-l1"><a class="reference internal" href="dml.lsi.html">Learning with Side Information (LSI)</a></li>
<li class="toctree-l1"><a class="reference internal" href="dml.dml_eig.html">Distance Metric Learning with Eigenvalue Optimization (DML-eig)</a></li>
<li class="toctree-l1"><a class="reference internal" href="dml.ldml.html">Logistic Discriminant Metric Learning (LDML)</a></li>
<li class="toctree-l1"><a class="reference internal" href="dml.klmnn.html">Kernel Large Margin Nearest Neighbors (KLMNN)</a></li>
<li class="toctree-l1"><a class="reference internal" href="dml.kanmm.html">Kernel Average Neighborhood Margin Maximization (KANMM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="dml.kdmlmj.html">Kernel Distance Metric Learning through the Maximization of the Jeffrey divergence (KDMLMJ)</a></li>
<li class="toctree-l1"><a class="reference internal" href="dml.kda.html">Kernel Discriminant Analysis (KDA)</a></li>
</ul>
<p class="caption"><span class="caption-text">Additional functionalities</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="similarity_classifiers.html">Distance metric learning extensions for some Scikit-Learn classifiers</a></li>
<li class="toctree-l1"><a class="reference internal" href="plot.html">Distance metric and classifier plots</a></li>
<li class="toctree-l1"><a class="reference internal" href="tune.html">Tuning parameters</a></li>
</ul>
<p class="caption"><span class="caption-text">Overview</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="docindex.html">Package documentation - Indices and tables</a></li>
<li class="toctree-l1"><a class="reference internal" href="modules.html">dml</a></li>
<li class="toctree-l1"><a class="reference internal" href="applications.html">Applications</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Examples</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#fitting-distance-metric-learning-algorithms">Fitting distance metric learning algorithms</a></li>
<li class="toctree-l2"><a class="reference internal" href="#similarity-learning-classifier-extensions-for-scikit-learn">Similarity learning classifier extensions for Scikit-learn</a></li>
<li class="toctree-l2"><a class="reference internal" href="#plotting-classifier-regions-induced-by-different-distances">Plotting classifier regions induced by different distances</a></li>
<li class="toctree-l2"><a class="reference internal" href="#tuning-parameters">Tuning parameters</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="references.html">References</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">pyDML</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Examples</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/examples.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="examples">
<h1>Examples<a class="headerlink" href="#examples" title="Permalink to this headline">¶</a></h1>
<div class="section" id="fitting-distance-metric-learning-algorithms">
<h2>Fitting distance metric learning algorithms<a class="headerlink" href="#fitting-distance-metric-learning-algorithms" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="k">import</span> <span class="n">load_iris</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Loading DML Algorithm</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">dml</span> <span class="k">import</span> <span class="n">NCA</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Loading dataset</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">iris</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># DML construction</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nca</span> <span class="o">=</span> <span class="n">NCA</span><span class="p">()</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Fitting algorithm</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nca</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># We can look at the algorithm metadata after fitting it</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">meta</span> <span class="o">=</span> <span class="n">nca</span><span class="o">.</span><span class="n">metadata</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">meta</span>
<span class="go">{&#39;final_expectance&#39;: 0.95771240234375,</span>
<span class="go"> &#39;initial_expectance&#39;: 0.8380491129557291,</span>
<span class="go"> &#39;num_iters&#39;: 3}</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># We can see the metric the algorithm has learned.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># This metric is the PSD matrix that defines how the distance is measured:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># d(x,y) = (x-y).T.dot(M).dot(x-y)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">M</span> <span class="o">=</span> <span class="n">nca</span><span class="o">.</span><span class="n">metric</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">M</span>
<span class="go">array([[ 1.19098678,  0.51293714, -2.15818151, -2.01464351],</span>
<span class="go">       [ 0.51293714,  1.58128238, -2.14573777, -2.10714773],</span>
<span class="go">       [-2.15818151, -2.14573777,  6.46881853,  5.86280474],</span>
<span class="go">       [-2.01464351, -2.10714773,  5.86280474,  6.83271473]])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Equivalently, we can see the learned linear map.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># The distance coincides with the euclidean distance after applying the linear map.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">L</span> <span class="o">=</span> <span class="n">nca</span><span class="o">.</span><span class="n">transformer</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">L</span>
<span class="go">array([[ 0.77961001, -0.01911998, -0.35862791, -0.23992861],</span>
<span class="go">       [-0.04442949,  1.00747788, -0.29936559, -0.25812144],</span>
<span class="go">       [-0.60744415, -0.57288453,  2.16095076,  1.35212555],</span>
<span class="go">       [-0.46068713, -0.48755353,  1.25732916,  2.20913531]])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Finally, we can obtain the transformed data ...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Lx</span> <span class="o">=</span> <span class="n">nca</span><span class="o">.</span><span class="n">transform</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Lx</span><span class="p">[:</span><span class="mi">5</span><span class="p">,:]</span>
<span class="go">array([[ 3.35902632,  2.8288461 , -1.80730485, -1.85385382],</span>
<span class="go">       [ 3.21266431,  2.33399305, -1.39937375, -1.51793964],</span>
<span class="go">       [ 3.0887811 ,  2.57431109, -1.60855691, -1.64904583],</span>
<span class="go">       [ 2.94100652,  2.41813313, -1.05833389, -1.30275593],</span>
<span class="go">       [ 3.27915332,  2.93403684, -1.80384889, -1.85654046]])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># ... or transform new data.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">],[</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">],[</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Lx_</span> <span class="o">=</span> <span class="n">nca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Lx_</span>
<span class="go">array([[ 0.77961001, -0.04442949, -0.60744415, -0.46068713],</span>
<span class="go">       [ 0.76049003,  0.9630484 , -1.18032868, -0.94824066],</span>
<span class="go">       [ 0.40186212,  0.66368281,  0.98062208,  0.3090885 ]])</span>
</pre></div>
</div>
</div>
<div class="section" id="similarity-learning-classifier-extensions-for-scikit-learn">
<h2>Similarity learning classifier extensions for Scikit-learn<a class="headerlink" href="#similarity-learning-classifier-extensions-for-scikit-learn" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="k">import</span> <span class="n">load_iris</span>

<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">dml</span> <span class="k">import</span> <span class="n">NCA</span><span class="p">,</span> <span class="n">kNN</span><span class="p">,</span> <span class="n">MultiDML_kNN</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Loading dataset</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">iris</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Initializing transformer and predictor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nca</span> <span class="o">=</span> <span class="n">NCA</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">knn</span> <span class="o">=</span> <span class="n">kNN</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span><span class="n">dml_algorithm</span><span class="o">=</span><span class="n">nca</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Fitting transformer and predictor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nca</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>

<span class="go"># Now we can predict the labels for k-NN with the learned distance.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">()</span> <span class="c1"># Also we can use predict(X_) for other datasets.</span>
<span class="gp">&gt;&gt;&gt; </span>              <span class="c1"># When using the training set predictions are made</span>
<span class="gp">&gt;&gt;&gt; </span>              <span class="c1"># leaving the sample to predict out.</span>
<span class="go">array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,</span>
<span class="go">        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,</span>
<span class="go">        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,</span>
<span class="go">        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,</span>
<span class="go">        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,</span>
<span class="go">        1.,  1.,  1.,  1.,  1.,  2.,  1.,  2.,  1.,  1.,  1.,  1.,  2.,</span>
<span class="go">        1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,</span>
<span class="go">        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  2.,  2.,  2.,</span>
<span class="go">        2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,</span>
<span class="go">        2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,</span>
<span class="go">        2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,</span>
<span class="go">        2.,  2.,  2.,  2.,  2.,  2.,  2.])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">knn</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">()[</span><span class="o">-</span><span class="mi">10</span><span class="p">:,:]</span> <span class="c1"># Again it can be used for other datasets.</span>
<span class="go">array([[ 0.        ,  0.        ,  1.        ],</span>
<span class="go">       [ 0.        ,  0.        ,  1.        ],</span>
<span class="go">       [ 0.        ,  0.        ,  1.        ],</span>
<span class="go">       [ 0.        ,  0.        ,  1.        ],</span>
<span class="go">       [ 0.        ,  0.        ,  1.        ],</span>
<span class="go">       [ 0.        ,  0.        ,  1.        ],</span>
<span class="go">       [ 0.        ,  0.14285714,  0.85714286],</span>
<span class="go">       [ 0.        ,  0.        ,  1.        ],</span>
<span class="go">       [ 0.        ,  0.        ,  1.        ],</span>
<span class="go">       [ 0.        ,  0.14285714,  0.85714286]])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">()</span> <span class="c1"># The classification score (score(X_,y_) for other datasets).</span>
<span class="go">0.97333333333333338</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># We can also compare with the euclidean distance k-NN</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">knn</span><span class="o">.</span><span class="n">score_orig</span><span class="p">()</span>
<span class="go">0.96666666666666667</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># With MultiDML_kNN we can test multiple dmls. In this case, dmls are fitted automatically.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lda</span> <span class="o">=</span> <span class="n">LDA</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mknn</span> <span class="o">=</span> <span class="n">MultiDML_kNN</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span><span class="n">dmls</span><span class="o">=</span><span class="p">[</span><span class="n">lda</span><span class="p">,</span><span class="n">nca</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mknn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># And we can predict and take scores in the same way, for every dml.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># The euclidean distance will be added always in first place.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mknn</span><span class="o">.</span><span class="n">score_all</span><span class="p">()</span> <span class="c1"># It will show [euclidean, lda, nca]</span>
<span class="go">array([ 0.96666667,  0.96666667,  0.97333333])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># The NCMC Classifier works like every ClassifierMixin.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ncmc</span> <span class="o">=</span> <span class="n">NCMC_Classifier</span><span class="p">(</span><span class="n">centroids_num</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ncmc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ncmc</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="go">0.95333333333333337</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># To learn a distance to use with NCMC Classifier, and with any other distance classifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># we can use pipelines.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="k">import</span> <span class="n">Pipeline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dml_ncmc</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s1">&#39;nca&#39;</span><span class="p">,</span><span class="n">nca</span><span class="p">),(</span><span class="s1">&#39;ncmc&#39;</span><span class="p">,</span><span class="n">ncmc</span><span class="p">)])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dml_ncmc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dml_ncmc</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="go">0.97999999999999998</span>
</pre></div>
</div>
</div>
<div class="section" id="plotting-classifier-regions-induced-by-different-distances">
<h2>Plotting classifier regions induced by different distances<a class="headerlink" href="#plotting-classifier-regions-induced-by-different-distances" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="k">import</span> <span class="n">load_iris</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">dml</span> <span class="k">import</span> <span class="n">NCA</span><span class="p">,</span> <span class="n">LDA</span><span class="p">,</span> <span class="n">NCMC_Classifier</span><span class="p">,</span> <span class="n">classifier_plot</span><span class="p">,</span> <span class="n">dml_plot</span><span class="p">,</span> <span class="n">knn_plot</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                <span class="n">dml_multiplot</span><span class="p">,</span> <span class="n">knn_pairplots</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Loading dataset</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">iris</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Initializing transformers and predictors</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nca</span> <span class="o">=</span> <span class="n">NCA</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lda</span> <span class="o">=</span> <span class="n">LDA</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ncmc</span> <span class="o">=</span> <span class="n">NCMC_Classifier</span><span class="p">(</span><span class="n">centroids_num</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># We can plot regions for different classifiers</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f1</span> <span class="o">=</span> <span class="n">classifier_plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]],</span><span class="n">y</span><span class="p">,</span><span class="n">clf</span><span class="o">=</span><span class="n">ncmc</span><span class="p">,</span><span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;NCMC Classification&quot;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                     <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;rainbow&quot;</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
</pre></div>
</div>
<img alt="_images/plotdoc1.png" src="_images/plotdoc1.png" />
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">f2</span> <span class="o">=</span> <span class="n">knn_plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]],</span><span class="n">y</span><span class="p">,</span><span class="n">k</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;3-NN Classification&quot;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;rainbow&quot;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>              <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
</pre></div>
</div>
<img alt="_images/plotdoc2.png" src="_images/plotdoc2.png" />
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># We can also make with the transformation determined by a metric,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># a transformer or a DML Algorithm</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f3</span> <span class="o">=</span> <span class="n">dml_plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]],</span><span class="n">y</span><span class="p">,</span><span class="n">clf</span><span class="o">=</span><span class="n">ncmc</span><span class="p">,</span><span class="n">dml</span><span class="o">=</span><span class="n">nca</span><span class="p">,</span><span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;NCMC Classification + NCA&quot;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>              <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;rainbow&quot;</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
</pre></div>
</div>
<img alt="_images/plotdoc3.png" src="_images/plotdoc3.png" />
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">f4</span> <span class="o">=</span> <span class="n">knn_plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]],</span><span class="n">y</span><span class="p">,</span><span class="n">k</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">dml</span><span class="o">=</span><span class="n">lda</span><span class="p">,</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;3-NN Classification + LDA&quot;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>              <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;rainbow&quot;</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
</pre></div>
</div>
<img alt="_images/plotdoc4.png" src="_images/plotdoc4.png" />
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Or we can see how the distance changes the classifier region</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># using the option transform=False</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f5</span> <span class="o">=</span> <span class="n">dml_plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]],</span><span class="n">y</span><span class="p">,</span><span class="n">clf</span><span class="o">=</span><span class="n">ncmc</span><span class="p">,</span><span class="n">dml</span><span class="o">=</span><span class="n">nca</span><span class="p">,</span><span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;NCMC Classification + NCA&quot;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>              <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;rainbow&quot;</span><span class="p">,</span><span class="n">transform</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
</pre></div>
</div>
<img alt="_images/plotdoc5.png" src="_images/plotdoc5.png" />
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">f6</span> <span class="o">=</span> <span class="n">knn_plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]],</span><span class="n">y</span><span class="p">,</span><span class="n">k</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">dml</span><span class="o">=</span><span class="n">lda</span><span class="p">,</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;3-NN Classification + LDA&quot;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>              <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;rainbow&quot;</span><span class="p">,</span><span class="n">transform</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
</pre></div>
</div>
<img alt="_images/plotdoc6.png" src="_images/plotdoc6.png" />
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># We can compare different algorithms or distances together in the same figure</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f7</span> <span class="o">=</span> <span class="n">dml_multiplot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]],</span><span class="n">y</span><span class="p">,</span><span class="n">nrow</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">ncol</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">ks</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span><span class="kc">None</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>                   <span class="n">clfs</span><span class="o">=</span><span class="p">[</span><span class="n">ncmc</span><span class="p">,</span><span class="n">ncmc</span><span class="p">,</span><span class="kc">None</span><span class="p">,</span><span class="kc">None</span><span class="p">],</span><span class="n">dmls</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span><span class="n">nca</span><span class="p">,</span><span class="kc">None</span><span class="p">,</span><span class="n">lda</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>                   <span class="n">transforms</span><span class="o">=</span><span class="p">[</span><span class="kc">False</span><span class="p">,</span><span class="kc">False</span><span class="p">,</span><span class="kc">False</span><span class="p">,</span><span class="kc">False</span><span class="p">],</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;Comparing&quot;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                   <span class="n">subtitles</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;NCMC&quot;</span><span class="p">,</span><span class="s2">&quot;NCMC + NCA&quot;</span><span class="p">,</span><span class="s2">&quot;3-NN&quot;</span><span class="p">,</span><span class="s2">&quot;3-NN + LDA&quot;</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>                   <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;rainbow&quot;</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">12</span><span class="p">))</span>
</pre></div>
</div>
<img alt="_images/plotdoc7.png" src="_images/plotdoc7.png" />
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Finally, we can also plot each pair of attributes. Here the classifier region</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># is made taking a section in the features space.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f8</span> <span class="o">=</span> <span class="n">knn_pairplots</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">k</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">sections</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span><span class="n">dml</span><span class="o">=</span><span class="n">nca</span><span class="p">,</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;pairplots&quot;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                   <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gist_rainbow&quot;</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">24</span><span class="p">,</span><span class="mi">24</span><span class="p">))</span>
</pre></div>
</div>
<img alt="_images/plotdoc8.png" src="_images/plotdoc8.png" />
</div>
<div class="section" id="tuning-parameters">
<h2>Tuning parameters<a class="headerlink" href="#tuning-parameters" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="k">import</span> <span class="n">load_iris</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">dml</span> <span class="k">import</span> <span class="n">NCA</span><span class="p">,</span> <span class="n">tune</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Loading dataset</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">iris</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Using cross validation we can tune parameters for the DML algorithms.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Here, we tune the NCA algorithm, with a fixed parameter learning_rate=&#39;constant&#39;.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># The parameters we tune are num_dims and eta0.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># The metrics we use are 3-NN and 5-NN scores, and the final expectance metadata of NCA.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># A 5-fold cross validation is done twice, to obtain the results.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">results</span><span class="p">,</span><span class="n">best</span><span class="p">,</span><span class="n">nca_best</span><span class="p">,</span><span class="n">detailed</span> <span class="o">=</span> <span class="n">tune</span><span class="p">(</span><span class="n">NCA</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">dml_params</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span><span class="s1">&#39;constant&#39;</span><span class="p">},</span>
<span class="gp">&gt;&gt;&gt; </span>                                      <span class="n">tune_args</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;num_dims&#39;</span><span class="p">:[</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span><span class="s1">&#39;eta0&#39;</span><span class="p">:[</span><span class="mf">0.001</span><span class="p">,</span><span class="mf">0.01</span><span class="p">,</span><span class="mf">0.1</span><span class="p">]},</span>
<span class="gp">&gt;&gt;&gt; </span>                                      <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="s1">&#39;final_expectance&#39;</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>                                      <span class="n">n_folds</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">n_reps</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">seed</span><span class="o">=</span><span class="mi">28</span><span class="p">,</span><span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="go">*** Tuning Case  {&#39;num_dims&#39;: 3, &#39;eta0&#39;: 0.001} ...</span>
<span class="go">** FOLD  1</span>
<span class="go">** FOLD  2</span>
<span class="go">** FOLD  3</span>
<span class="go">** FOLD  4</span>
<span class="go">** FOLD  5</span>
<span class="go">** FOLD  6</span>
<span class="go">** FOLD  7</span>
<span class="go">** FOLD  8</span>
<span class="go">** FOLD  9</span>
<span class="go">** FOLD  10</span>
<span class="go">*** Tuning Case  {&#39;num_dims&#39;: 3, &#39;eta0&#39;: 0.01} ...</span>
<span class="go">** FOLD  1</span>
<span class="go">** FOLD  2</span>
<span class="go">** FOLD  3</span>
<span class="go">** FOLD  4</span>
<span class="gp">...</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Now we can compare the results obtained for each case.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">results</span>
<span class="go">                                    3-NN      5-NN  final_expectance</span>
<span class="go">{&#39;num_dims&#39;: 3, &#39;eta0&#39;: 0.001}  0.963333  0.970000          0.890105</span>
<span class="go">{&#39;num_dims&#39;: 3, &#39;eta0&#39;: 0.01}   0.966667  0.963333          0.916240</span>
<span class="go">{&#39;num_dims&#39;: 3, &#39;eta0&#39;: 0.1}    0.970000  0.963333          0.935243</span>
<span class="go">{&#39;num_dims&#39;: 4, &#39;eta0&#39;: 0.001}  0.956667  0.963333          0.897238</span>
<span class="go">{&#39;num_dims&#39;: 4, &#39;eta0&#39;: 0.01}   0.956667  0.963333          0.922415</span>
<span class="go">{&#39;num_dims&#39;: 4, &#39;eta0&#39;: 0.1}    0.960000  0.963333          0.947319</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># We can also take the best result (respect to the first metric).</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">best</span>
<span class="go">({&#39;eta0&#39;: 0.1, &#39;num_dims&#39;: 3}, 0.97000000000000008)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># We also obtain the best DML algorithm already constructed to be used.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nca_best</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># If we want, we can look at the detailed results of cross validation for each case.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">detailed</span><span class="p">[</span><span class="s2">&quot;{&#39;num_dims&#39;: 3, &#39;eta0&#39;: 0.01}&quot;</span><span class="p">]</span>
<span class="go">              3-NN      5-NN  final_expectance</span>
<span class="go">SPLIT 1   0.966667  0.966667          0.923293</span>
<span class="go">SPLIT 2   0.966667  0.966667          0.922091</span>
<span class="go">SPLIT 3   1.000000  0.966667          0.907416</span>
<span class="go">SPLIT 4   0.966667  0.966667          0.903700</span>
<span class="go">SPLIT 5   0.966667  0.966667          0.915030</span>
<span class="go">SPLIT 6   0.966667  0.966667          0.905189</span>
<span class="go">SPLIT 7   0.966667  0.966667          0.922051</span>
<span class="go">SPLIT 8   0.933333  0.933333          0.933400</span>
<span class="go">SPLIT 9   0.966667  1.000000          0.912236</span>
<span class="go">SPLIT 10  0.966667  0.933333          0.917992</span>
<span class="go">MEAN      0.966667  0.963333          0.916240</span>
<span class="go">STD       0.014907  0.017951          0.008888</span>
</pre></div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="installation.html" class="btn btn-neutral float-right" title="Installation" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="applications.html" class="btn btn-neutral" title="Applications" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Juan Luis Suárez Díaz.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'0.0.1',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>