

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>dml package &mdash; pyDML 0.0.1 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="dml" href="modules.html" /> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> pyDML
          

          
          </a>

          
            
            
              <div class="version">
                0.0.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Current Algorithms:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dml.pca.html">Principal Component Analysis (PCA)</a></li>
<li class="toctree-l1"><a class="reference internal" href="dml.lda.html">Linear Discriminant Analysis (LDA)</a></li>
<li class="toctree-l1"><a class="reference internal" href="dml.anmm.html">Average Neighborhood Margin Maximization (ANMM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="dml.lmnn.html">Large Margin Nearest Neighbors (LMNN)</a></li>
<li class="toctree-l1"><a class="reference internal" href="dml.nca.html">Neighborhood Component Analysis (NCA)</a></li>
<li class="toctree-l1"><a class="reference internal" href="dml.ncmml.html">Nearest Class Mean Metric Learning (NCMML)</a></li>
<li class="toctree-l1"><a class="reference internal" href="dml.ncmc.html">Nearest Class with Multiple Centroids (NCMC)</a></li>
<li class="toctree-l1"><a class="reference internal" href="dml.itml.html">Information Theoretic Metric Learning (ITML)</a></li>
<li class="toctree-l1"><a class="reference internal" href="dml.dmlmj.html">Distance Metric Learning through the Maximization of the Jeffrey Divergence (DMLMJ)</a></li>
<li class="toctree-l1"><a class="reference internal" href="dml.mcml.html">Maximally Collapsing Metric Learning (MCML)</a></li>
<li class="toctree-l1"><a class="reference internal" href="dml.lsi.html">Learning with Side Information (LSI)</a></li>
<li class="toctree-l1"><a class="reference internal" href="dml.dml_eig.html">Distance Metric Learning with Eigenvalue Optimization (DML-eig)</a></li>
<li class="toctree-l1"><a class="reference internal" href="dml.ldml.html">Logistic Discriminant Metric Learning (LDML)</a></li>
<li class="toctree-l1"><a class="reference internal" href="dml.klmnn.html">Kernel Large Margin Nearest Neighbors (KLMNN)</a></li>
<li class="toctree-l1"><a class="reference internal" href="dml.kanmm.html">Kernel Average Neighborhood Margin Maximization (KANMM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="dml.kdmlmj.html">Kernel Distance Metric Learning through the Maximization of the Jeffrey divergence (KDMLMJ)</a></li>
<li class="toctree-l1"><a class="reference internal" href="dml.kda.html">Kernel Discriminant Analysis (KDA)</a></li>
</ul>
<p class="caption"><span class="caption-text">Additional functionalities</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="similarity_classifiers.html">Distance metric learning extensions for some Scikit-Learn classifiers</a></li>
<li class="toctree-l1"><a class="reference internal" href="plot.html">Distance metric and classifier plots</a></li>
<li class="toctree-l1"><a class="reference internal" href="tune.html">Tuning parameters</a></li>
</ul>
<p class="caption"><span class="caption-text">Overview</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="docindex.html">Package documentation - Indices and tables</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="modules.html">dml</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">dml package</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#submodules">Submodules</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-dml.anmm">dml.anmm module</a><ul class="simple">
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-dml.base">dml.base module</a><ul class="simple">
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-dml.dml_algorithm">dml.dml_algorithm module</a><ul class="simple">
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-dml.dml_eig">dml.dml_eig module</a><ul class="simple">
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-dml.dml_plot">dml.dml_plot module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-dml.dml_utils">dml.dml_utils module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-dml.dmlmj">dml.dmlmj module</a><ul class="simple">
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-dml.itml">dml.itml module</a><ul class="simple">
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-dml.kda">dml.kda module</a><ul class="simple">
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-dml.knn">dml.knn module</a><ul class="simple">
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-dml.lda">dml.lda module</a><ul class="simple">
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-dml.ldml">dml.ldml module</a><ul class="simple">
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-dml.lmnn">dml.lmnn module</a><ul class="simple">
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-dml.lsi">dml.lsi module</a><ul class="simple">
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-dml.mcml">dml.mcml module</a><ul class="simple">
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-dml.multidml_knn">dml.multidml_knn module</a><ul class="simple">
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-dml.nca">dml.nca module</a><ul class="simple">
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-dml.ncmc">dml.ncmc module</a><ul class="simple">
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-dml.ncmml">dml.ncmml module</a><ul class="simple">
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-dml.pca">dml.pca module</a><ul class="simple">
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-dml.tune">dml.tune module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-dml">Module contents</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="applications.html">Applications</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="references.html">References</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">pyDML</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
          <li><a href="modules.html">dml</a> &raquo;</li>
        
      <li>dml package</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/dml.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="dml-package">
<h1>dml package<a class="headerlink" href="#dml-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-dml.anmm">
<span id="dml-anmm-module"></span><h2>dml.anmm module<a class="headerlink" href="#module-dml.anmm" title="Permalink to this headline">¶</a></h2>
<p>Average Neighborhood Margin Maximization (ANMM)</p>
<dl class="class">
<dt id="dml.anmm.ANMM">
<em class="property">class </em><code class="descclassname">dml.anmm.</code><code class="descname">ANMM</code><a class="headerlink" href="#dml.anmm.ANMM" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dml.dml_algorithm.DML_Algorithm" title="dml.dml_algorithm.DML_Algorithm"><code class="xref py py-class docutils literal"><span class="pre">dml.dml_algorithm.DML_Algorithm</span></code></a></p>
<p>Average Neighborhood Margin Maximization (ANMM)</p>
<p>A DML Algorithm that obtains a transformer that maximizes the distance between the nearest friends and the nearest enemies for each example.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>num_dims</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=None</span></dt>
<dd><p class="first last">Dimension desired for the transformed data.</p>
</dd>
<dt><strong>n_friends</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=3</span></dt>
<dd><p class="first last">Number of nearest same-class neighbors to compute homogeneus neighborhood.</p>
</dd>
<dt><strong>n_enemies</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=1</span></dt>
<dd><p class="first last">Number of nearest different-class neighbors to compute heterogeneus neigborhood.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#dml.anmm.ANMM.fit" title="dml.anmm.ANMM.fit"><code class="xref py py-obj docutils literal"><span class="pre">fit</span></code></a></td>
<td>Fit the model from the data in X and the labels in y.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">fit_transform</span></code>(X[,&nbsp;y])</td>
<td>Fit to data, then transform it.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">get_params</span></code>([deep])</td>
<td>Get parameters for this estimator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#dml.anmm.ANMM.metadata" title="dml.anmm.ANMM.metadata"><code class="xref py py-obj docutils literal"><span class="pre">metadata</span></code></a></td>
<td>Obtains algorithm metadata.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">metric</span></code>()</td>
<td>Computes the Mahalanobis matrix from the transformation matrix.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">set_params</span></code>(**params)</td>
<td>Set the parameters of this estimator.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">transform</span></code>([X])</td>
<td>Applies the metric transformation.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#dml.anmm.ANMM.transformer" title="dml.anmm.ANMM.transformer"><code class="xref py py-obj docutils literal"><span class="pre">transformer</span></code></a></td>
<td>Obtains the learned projection.</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="dml.anmm.ANMM.fit">
<code class="descname">fit</code><a class="headerlink" href="#dml.anmm.ANMM.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model from the data in X and the labels in y.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N x d)</span></dt>
<dd><p class="first last">Training vector, where N is the number of samples, and d is the number of features.</p>
</dd>
<dt><strong>y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N)</span></dt>
<dd><p class="first last">Labels vector, where N is the number of samples.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>self</strong> <span class="classifier-delimiter">:</span> <span class="classifier">object</span></dt>
<dd><p class="first last">Returns the instance itself.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="dml.anmm.ANMM.metadata">
<code class="descname">metadata</code><a class="headerlink" href="#dml.anmm.ANMM.metadata" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtains algorithm metadata.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>meta</strong> <span class="classifier-delimiter">:</span> <span class="classifier">A dictionary with the following metadata:</span></dt>
<dd><p class="first">acum_eig : eigenvalue rate accumulated in the learned output respect to the total dimension.</p>
<p class="last">num_dims : dimension of the reduced data.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="dml.anmm.ANMM.transformer">
<code class="descname">transformer</code><a class="headerlink" href="#dml.anmm.ANMM.transformer" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtains the learned projection.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>L</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(d’xd) matrix, where d’ is the desired output dimension and d is the number of features.</span></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="dml.anmm.KANMM">
<em class="property">class </em><code class="descclassname">dml.anmm.</code><code class="descname">KANMM</code><a class="headerlink" href="#dml.anmm.KANMM" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dml.dml_algorithm.KernelDML_Algorithm" title="dml.dml_algorithm.KernelDML_Algorithm"><code class="xref py py-class docutils literal"><span class="pre">dml.dml_algorithm.KernelDML_Algorithm</span></code></a></p>
<p>The kernelized version of ANMM.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>num_dims</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=None</span></dt>
<dd><p class="first last">Dimension desired for the transformed data.</p>
</dd>
<dt><strong>n_friends</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=3</span></dt>
<dd><p class="first last">Number of nearest same-class neighbors to compute homogeneus neighborhood.</p>
</dd>
<dt><strong>n_enemies</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=1</span></dt>
<dd><p class="first last">Number of nearest different-class neighbors to compute heterogeneus neigborhood.</p>
</dd>
<dt><strong>kernel</strong> <span class="classifier-delimiter">:</span> <span class="classifier">“linear” | “poly” | “rbf” | “sigmoid” | “cosine” | “precomputed”</span></dt>
<dd><p class="first last">Kernel. Default=”linear”.</p>
</dd>
<dt><strong>gamma</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1/n_features</span></dt>
<dd><p class="first last">Kernel coefficient for rbf, poly and sigmoid kernels. Ignored by other
kernels.</p>
</dd>
<dt><strong>degree</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=3</span></dt>
<dd><p class="first last">Degree for poly kernels. Ignored by other kernels.</p>
</dd>
<dt><strong>coef0</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1</span></dt>
<dd><p class="first last">Independent term in poly and sigmoid kernels.
Ignored by other kernels.</p>
</dd>
<dt><strong>kernel_params</strong> <span class="classifier-delimiter">:</span> <span class="classifier">mapping of string to any, default=None</span></dt>
<dd><p class="first last">Parameters (keyword arguments) and values for kernel passed as
callable object. Ignored by other kernels.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#dml.anmm.KANMM.fit" title="dml.anmm.KANMM.fit"><code class="xref py py-obj docutils literal"><span class="pre">fit</span></code></a></td>
<td>Fit the model from the data in X and the labels in y.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">fit_transform</span></code>(X[,&nbsp;y])</td>
<td>Fit to data, then transform it.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">get_params</span></code>([deep])</td>
<td>Get parameters for this estimator.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">metadata</span></code>()</td>
<td>Obtains the algorithm metadata.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">metric</span></code>()</td>
<td>Computes the Mahalanobis matrix from the transformation matrix.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">set_params</span></code>(**params)</td>
<td>Set the parameters of this estimator.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">transform</span></code>([X])</td>
<td>Applies the kernel transformation.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#dml.anmm.KANMM.transformer" title="dml.anmm.KANMM.transformer"><code class="xref py py-obj docutils literal"><span class="pre">transformer</span></code></a></td>
<td>Obtains the learned projection.</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="dml.anmm.KANMM.fit">
<code class="descname">fit</code><a class="headerlink" href="#dml.anmm.KANMM.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model from the data in X and the labels in y.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N x d)</span></dt>
<dd><p class="first last">Training vector, where N is the number of samples, and d is the number of features.</p>
</dd>
<dt><strong>y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N)</span></dt>
<dd><p class="first last">Labels vector, where N is the number of samples.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>self</strong> <span class="classifier-delimiter">:</span> <span class="classifier">object</span></dt>
<dd><p class="first last">Returns the instance itself.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="dml.anmm.KANMM.transformer">
<code class="descname">transformer</code><a class="headerlink" href="#dml.anmm.KANMM.transformer" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtains the learned projection.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>A</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(d’x N) matrix, where d’ is the desired output dimension, and N is the number of samples.</span></dt>
<dd><p class="first last">To apply A to a new sample x, A must be multiplied by the kernel vector of dimension N
obtained by taking the kernels between x and each training sample.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-dml.base">
<span id="dml-base-module"></span><h2>dml.base module<a class="headerlink" href="#module-dml.base" title="Permalink to this headline">¶</a></h2>
<p>Some basic DML implementations.</p>
<p>Created on Fri Mar 30 19:13:58 2018</p>
<p>&#64;author: jlsuarezdiaz</p>
<dl class="class">
<dt id="dml.base.Euclidean">
<em class="property">class </em><code class="descclassname">dml.base.</code><code class="descname">Euclidean</code><a class="headerlink" href="#dml.base.Euclidean" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dml.dml_algorithm.DML_Algorithm" title="dml.dml_algorithm.DML_Algorithm"><code class="xref py py-class docutils literal"><span class="pre">dml.dml_algorithm.DML_Algorithm</span></code></a></p>
<p>A basic transformer that represents the euclidean distance.</p>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#dml.base.Euclidean.fit" title="dml.base.Euclidean.fit"><code class="xref py py-obj docutils literal"><span class="pre">fit</span></code></a>(X,&nbsp;y)</td>
<td>Fit the model from the data in X and the labels in y.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">fit_transform</span></code>(X[,&nbsp;y])</td>
<td>Fit to data, then transform it.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">get_params</span></code>([deep])</td>
<td>Get parameters for this estimator.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">metadata</span></code>()</td>
<td>Obtains the algorithm metadata.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#dml.base.Euclidean.metric" title="dml.base.Euclidean.metric"><code class="xref py py-obj docutils literal"><span class="pre">metric</span></code></a>()</td>
<td>Obtains the learned metric.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">set_params</span></code>(**params)</td>
<td>Set the parameters of this estimator.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#dml.base.Euclidean.transform" title="dml.base.Euclidean.transform"><code class="xref py py-obj docutils literal"><span class="pre">transform</span></code></a>([X])</td>
<td>Applies the metric transformation.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#dml.base.Euclidean.transformer" title="dml.base.Euclidean.transformer"><code class="xref py py-obj docutils literal"><span class="pre">transformer</span></code></a>()</td>
<td>Obtains the learned projection.</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="dml.base.Euclidean.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em><span class="sig-paren">)</span><a class="headerlink" href="#dml.base.Euclidean.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model from the data in X and the labels in y.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N x d)</span></dt>
<dd><p class="first last">Training vector, where N is the number of samples, and d is the number of features.</p>
</dd>
<dt><strong>y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N)</span></dt>
<dd><p class="first last">Labels vector, where N is the number of samples.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>self</strong> <span class="classifier-delimiter">:</span> <span class="classifier">object</span></dt>
<dd><p class="first last">Returns the instance itself.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="dml.base.Euclidean.metric">
<code class="descname">metric</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#dml.base.Euclidean.metric" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtains the learned metric.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>M</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(dxd) positive semidefinite matrix, where d is the number of features.</span></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="dml.base.Euclidean.transform">
<code class="descname">transform</code><span class="sig-paren">(</span><em>X=None</em><span class="sig-paren">)</span><a class="headerlink" href="#dml.base.Euclidean.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies the metric transformation.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(N x d) matrix, optional</span></dt>
<dd><p class="first last">Data to transform. If not supplied, the training data will be used.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>transformed</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(N x d’) matrix</span></dt>
<dd><p class="first last">Input data transformed to the metric space by <span class="math">\(XL^{\top}\)</span></p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="dml.base.Euclidean.transformer">
<code class="descname">transformer</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#dml.base.Euclidean.transformer" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtains the learned projection.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>L</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(d’xd) matrix, where d’ is the desired output dimension and d is the number of features.</span></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="dml.base.Metric">
<em class="property">class </em><code class="descclassname">dml.base.</code><code class="descname">Metric</code><span class="sig-paren">(</span><em>metric</em><span class="sig-paren">)</span><a class="headerlink" href="#dml.base.Metric" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dml.dml_algorithm.DML_Algorithm" title="dml.dml_algorithm.DML_Algorithm"><code class="xref py py-class docutils literal"><span class="pre">dml.dml_algorithm.DML_Algorithm</span></code></a></p>
<p>A DML algorithm that defines a distance given a PSD metric matrix.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>metric</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(d x d) matrix. A positive semidefinite matrix, to define a pseudodistance in euclidean d-dimensional space.</span></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#dml.base.Metric.fit" title="dml.base.Metric.fit"><code class="xref py py-obj docutils literal"><span class="pre">fit</span></code></a>(X,&nbsp;y)</td>
<td>Fit the model from the data in X and the labels in y.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">fit_transform</span></code>(X[,&nbsp;y])</td>
<td>Fit to data, then transform it.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">get_params</span></code>([deep])</td>
<td>Get parameters for this estimator.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">metadata</span></code>()</td>
<td>Obtains the algorithm metadata.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#dml.base.Metric.metric" title="dml.base.Metric.metric"><code class="xref py py-obj docutils literal"><span class="pre">metric</span></code></a>()</td>
<td>Obtains the learned metric.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">set_params</span></code>(**params)</td>
<td>Set the parameters of this estimator.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">transform</span></code>([X])</td>
<td>Applies the metric transformation.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">transformer</span></code>()</td>
<td>Computes a transformation matrix from the Mahalanobis matrix.</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="dml.base.Metric.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em><span class="sig-paren">)</span><a class="headerlink" href="#dml.base.Metric.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model from the data in X and the labels in y.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N x d)</span></dt>
<dd><p class="first last">Training vector, where N is the number of samples, and d is the number of features.</p>
</dd>
<dt><strong>y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N)</span></dt>
<dd><p class="first last">Labels vector, where N is the number of samples.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>self</strong> <span class="classifier-delimiter">:</span> <span class="classifier">object</span></dt>
<dd><p class="first last">Returns the instance itself.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="dml.base.Metric.metric">
<code class="descname">metric</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#dml.base.Metric.metric" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtains the learned metric.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>M</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(dxd) positive semidefinite matrix, where d is the number of features.</span></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="dml.base.Transformer">
<em class="property">class </em><code class="descclassname">dml.base.</code><code class="descname">Transformer</code><span class="sig-paren">(</span><em>transformer</em><span class="sig-paren">)</span><a class="headerlink" href="#dml.base.Transformer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dml.dml_algorithm.DML_Algorithm" title="dml.dml_algorithm.DML_Algorithm"><code class="xref py py-class docutils literal"><span class="pre">dml.dml_algorithm.DML_Algorithm</span></code></a></p>
<p>A DML algorithm that defines a distance given a linear transformation.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>transformer</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(d’ x d) matrix, representing a linear transformacion from d-dimensional euclidean space</span></dt>
<dd><p class="first last">to d’-dimensional euclidean space.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#dml.base.Transformer.fit" title="dml.base.Transformer.fit"><code class="xref py py-obj docutils literal"><span class="pre">fit</span></code></a>(X,&nbsp;y)</td>
<td>Fit the model from the data in X and the labels in y.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">fit_transform</span></code>(X[,&nbsp;y])</td>
<td>Fit to data, then transform it.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">get_params</span></code>([deep])</td>
<td>Get parameters for this estimator.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">metadata</span></code>()</td>
<td>Obtains the algorithm metadata.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">metric</span></code>()</td>
<td>Computes the Mahalanobis matrix from the transformation matrix.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">set_params</span></code>(**params)</td>
<td>Set the parameters of this estimator.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">transform</span></code>([X])</td>
<td>Applies the metric transformation.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#dml.base.Transformer.transformer" title="dml.base.Transformer.transformer"><code class="xref py py-obj docutils literal"><span class="pre">transformer</span></code></a>()</td>
<td>Obtains the learned projection.</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="dml.base.Transformer.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em><span class="sig-paren">)</span><a class="headerlink" href="#dml.base.Transformer.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model from the data in X and the labels in y.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N x d)</span></dt>
<dd><p class="first last">Training vector, where N is the number of samples, and d is the number of features.</p>
</dd>
<dt><strong>y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N)</span></dt>
<dd><p class="first last">Labels vector, where N is the number of samples.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>self</strong> <span class="classifier-delimiter">:</span> <span class="classifier">object</span></dt>
<dd><p class="first last">Returns the instance itself.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="dml.base.Transformer.transformer">
<code class="descname">transformer</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#dml.base.Transformer.transformer" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtains the learned projection.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>L</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(d’xd) matrix, where d’ is the desired output dimension and d is the number of features.</span></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-dml.dml_algorithm">
<span id="dml-dml-algorithm-module"></span><h2>dml.dml_algorithm module<a class="headerlink" href="#module-dml.dml_algorithm" title="Permalink to this headline">¶</a></h2>
<p>Distance Metric Algorithm basis.</p>
<dl class="class">
<dt id="dml.dml_algorithm.DML_Algorithm">
<em class="property">class </em><code class="descclassname">dml.dml_algorithm.</code><code class="descname">DML_Algorithm</code><a class="headerlink" href="#dml.dml_algorithm.DML_Algorithm" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">sklearn.base.BaseEstimator</span></code>, <code class="xref py py-class docutils literal"><span class="pre">sklearn.base.TransformerMixin</span></code></p>
<p>Abstract class that defines a distance metric learning algorithm.
Distance metric learning are implemented as subclasses of DML_Algorithm.
A DML Algorithm can compute either a Mahalanobis metric matrix or an associated linear transformation.
DML subclasses must override one of the following methods (metric or transformer), according to their computation way.</p>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">fit_transform</span></code>(X[,&nbsp;y])</td>
<td>Fit to data, then transform it.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">get_params</span></code>([deep])</td>
<td>Get parameters for this estimator.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#dml.dml_algorithm.DML_Algorithm.metadata" title="dml.dml_algorithm.DML_Algorithm.metadata"><code class="xref py py-obj docutils literal"><span class="pre">metadata</span></code></a>()</td>
<td>Obtains the algorithm metadata.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#dml.dml_algorithm.DML_Algorithm.metric" title="dml.dml_algorithm.DML_Algorithm.metric"><code class="xref py py-obj docutils literal"><span class="pre">metric</span></code></a>()</td>
<td>Computes the Mahalanobis matrix from the transformation matrix.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">set_params</span></code>(**params)</td>
<td>Set the parameters of this estimator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#dml.dml_algorithm.DML_Algorithm.transform" title="dml.dml_algorithm.DML_Algorithm.transform"><code class="xref py py-obj docutils literal"><span class="pre">transform</span></code></a>([X])</td>
<td>Applies the metric transformation.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#dml.dml_algorithm.DML_Algorithm.transformer" title="dml.dml_algorithm.DML_Algorithm.transformer"><code class="xref py py-obj docutils literal"><span class="pre">transformer</span></code></a>()</td>
<td>Computes a transformation matrix from the Mahalanobis matrix.</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="dml.dml_algorithm.DML_Algorithm.metadata">
<code class="descname">metadata</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#dml.dml_algorithm.DML_Algorithm.metadata" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtains the algorithm metadata. Must be implemented in subclasses.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>dict</strong> <span class="classifier-delimiter">:</span> <span class="classifier">A map from string to any.</span></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="dml.dml_algorithm.DML_Algorithm.metric">
<code class="descname">metric</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#dml.dml_algorithm.DML_Algorithm.metric" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the Mahalanobis matrix from the transformation matrix.
.. math:: M = L^T L</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>M</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(d x d) matrix. M defines a metric whose distace is given by</span></dt>
<dd></dd>
<dt><strong>..math:: d(x,y) = sqrt{(x-y)^TM(x-y)}.</strong></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="dml.dml_algorithm.DML_Algorithm.transform">
<code class="descname">transform</code><span class="sig-paren">(</span><em>X=None</em><span class="sig-paren">)</span><a class="headerlink" href="#dml.dml_algorithm.DML_Algorithm.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies the metric transformation.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(N x d) matrix, optional</span></dt>
<dd><p class="first last">Data to transform. If not provided, the training data will be used.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>transformed</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(N x d’) matrix</span></dt>
<dd><p class="first last">Input data transformed to the metric space. The learned distance can be measured using
the euclidean distance with the transformed data.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="dml.dml_algorithm.DML_Algorithm.transformer">
<code class="descname">transformer</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#dml.dml_algorithm.DML_Algorithm.transformer" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes a transformation matrix from the Mahalanobis matrix.
..math:: L = M^{1/2}</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>L</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(d’ x d) matrix, with d’ &lt;= d. It defines a projection. The distance can be calculated by</span></dt>
<dd></dd>
<dt><strong>..math:: d(x,y) = |L(x-y)|_2.</strong></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="dml.dml_algorithm.KernelDML_Algorithm">
<em class="property">class </em><code class="descclassname">dml.dml_algorithm.</code><code class="descname">KernelDML_Algorithm</code><a class="headerlink" href="#dml.dml_algorithm.KernelDML_Algorithm" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dml.dml_algorithm.DML_Algorithm" title="dml.dml_algorithm.DML_Algorithm"><code class="xref py py-class docutils literal"><span class="pre">dml.dml_algorithm.DML_Algorithm</span></code></a></p>
<p>Abstract class that defines a kernel distance metric learning algorithm.
Distance metric learning are implemented as subclasses of KernelDML_Algorithm.
A Kernel DML Algorithm can compute a (d’ x n) transformer that maps the high dimensional data using the kernel trick.
Kernel DML subclasses must override the transformer method, providing the matrix A that performs the kernel trick, that is</p>
<div class="math">
\[Lx = A(K(x_1,x),\dots,K(x_n,x)),\]</div>
<p>where L is the high dimensional transformer and K is the kernel function.</p>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">fit_transform</span></code>(X[,&nbsp;y])</td>
<td>Fit to data, then transform it.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">get_params</span></code>([deep])</td>
<td>Get parameters for this estimator.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">metadata</span></code>()</td>
<td>Obtains the algorithm metadata.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">metric</span></code>()</td>
<td>Computes the Mahalanobis matrix from the transformation matrix.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">set_params</span></code>(**params)</td>
<td>Set the parameters of this estimator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#dml.dml_algorithm.KernelDML_Algorithm.transform" title="dml.dml_algorithm.KernelDML_Algorithm.transform"><code class="xref py py-obj docutils literal"><span class="pre">transform</span></code></a>([X])</td>
<td>Applies the kernel transformation.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">transformer</span></code>()</td>
<td>Computes a transformation matrix from the Mahalanobis matrix.</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="dml.dml_algorithm.KernelDML_Algorithm.transform">
<code class="descname">transform</code><span class="sig-paren">(</span><em>X=None</em><span class="sig-paren">)</span><a class="headerlink" href="#dml.dml_algorithm.KernelDML_Algorithm.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies the kernel transformation.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(N x d) matrix, optional</span></dt>
<dd><p class="first last">Data to transform. If not supplied, the training data will be used.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>transformed: (N x d’) matrix.</strong></dt>
<dd><p class="first last">Input data transformed by the learned mapping.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-dml.dml_eig">
<span id="dml-dml-eig-module"></span><h2>dml.dml_eig module<a class="headerlink" href="#module-dml.dml_eig" title="Permalink to this headline">¶</a></h2>
<p>Distance Metric Learning with Eigenvalue Optimization</p>
<p>Created on Fri Mar  9 10:18:35 2018</p>
<p>&#64;author: jlsuarezdiaz</p>
<dl class="class">
<dt id="dml.dml_eig.DML_eig">
<em class="property">class </em><code class="descclassname">dml.dml_eig.</code><code class="descname">DML_eig</code><a class="headerlink" href="#dml.dml_eig.DML_eig" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dml.dml_algorithm.DML_Algorithm" title="dml.dml_algorithm.DML_Algorithm"><code class="xref py py-class docutils literal"><span class="pre">dml.dml_algorithm.DML_Algorithm</span></code></a></p>
<p>Distance Metric Learning with Eigenvalue Optimization (DML-eig)</p>
<p>A DML Algorithm that learns a metric that minimizes the minimum distance between different-class points
constrained to the sum of distances at same-class points be non higher than a constant.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>mu</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1e-4</span></dt>
<dd><p class="first last">Smoothing parameter.</p>
</dd>
<dt><strong>tol</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1e-5</span></dt>
<dd><p class="first last">Tolerance stop criterion (difference between two point iterations at gradient descent.)</p>
</dd>
<dt><strong>eps</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1e-10</span></dt>
<dd><p class="first last">Precision stop criterion (norm of gradient at gradient descent)</p>
</dd>
<dt><strong>max_it: int, default=25</strong></dt>
<dd><p class="first last">Number of iterations at gradient descent.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#dml.dml_eig.DML_eig.fit" title="dml.dml_eig.DML_eig.fit"><code class="xref py py-obj docutils literal"><span class="pre">fit</span></code></a></td>
<td>Fit the model from the data in X and the labels in y.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">fit_transform</span></code>(X[,&nbsp;y])</td>
<td>Fit to data, then transform it.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">get_params</span></code>([deep])</td>
<td>Get parameters for this estimator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#dml.dml_eig.DML_eig.metadata" title="dml.dml_eig.DML_eig.metadata"><code class="xref py py-obj docutils literal"><span class="pre">metadata</span></code></a></td>
<td>Obtains algorithm metadata.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#dml.dml_eig.DML_eig.metric" title="dml.dml_eig.DML_eig.metric"><code class="xref py py-obj docutils literal"><span class="pre">metric</span></code></a></td>
<td>Obtains the learned metric.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">set_params</span></code>(**params)</td>
<td>Set the parameters of this estimator.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">transform</span></code>([X])</td>
<td>Applies the metric transformation.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">transformer</span></code>()</td>
<td>Computes a transformation matrix from the Mahalanobis matrix.</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="dml.dml_eig.DML_eig.fit">
<code class="descname">fit</code><a class="headerlink" href="#dml.dml_eig.DML_eig.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model from the data in X and the labels in y.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N x d)</span></dt>
<dd><p class="first last">Training vector, where N is the number of samples, and d is the number of features.</p>
</dd>
<dt><strong>y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N)</span></dt>
<dd><p class="first last">Labels vector, where N is the number of samples.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>self</strong> <span class="classifier-delimiter">:</span> <span class="classifier">object</span></dt>
<dd><p class="first last">Returns the instance itself.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="dml.dml_eig.DML_eig.metadata">
<code class="descname">metadata</code><a class="headerlink" href="#dml.dml_eig.DML_eig.metadata" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtains algorithm metadata.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>meta</strong> <span class="classifier-delimiter">:</span> <span class="classifier">A dictionary with the following metadata:</span></dt>
<dd><p class="first">initial_error : initial value of the objective error function.</p>
<p class="last">final_error : final value of the objective error function.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="dml.dml_eig.DML_eig.metric">
<code class="descname">metric</code><a class="headerlink" href="#dml.dml_eig.DML_eig.metric" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtains the learned metric.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>M</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(dxd) positive semidefinite matrix, where d is the number of features.</span></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-dml.dml_plot">
<span id="dml-dml-plot-module"></span><h2>dml.dml_plot module<a class="headerlink" href="#module-dml.dml_plot" title="Permalink to this headline">¶</a></h2>
<p>Plot utilies for classifiers and distance metric learners.</p>
<p>Created on Sat Feb  3 16:45:28 2018</p>
<p>&#64;author: jlsuarezdiaz</p>
<dl class="function">
<dt id="dml.dml_plot.classifier_pairplots">
<code class="descclassname">dml.dml_plot.</code><code class="descname">classifier_pairplots</code><span class="sig-paren">(</span><em>X, y, clf, attrs=None, xattrs=None, yattrs=None, diag='hist', sections='mean', fitted=False, title=None, grid_split=[400, 400], grid_step=[0.1, 0.1], label_legend=True, legend_loc='center right', cmap=None, label_colors=None, plot_points=True, plot_regions=True, region_intensity=0.4, legend_plot_points=True, legend_plot_regions=True, legend_on_axis=False, **fig_kw</em><span class="sig-paren">)</span><a class="headerlink" href="#dml.dml_plot.classifier_pairplots" title="Permalink to this definition">¶</a></dt>
<dd><p>This function allows multiple 2D-scatter plots for different pairs of attributes of the same dataset, and
to plot regions defined by different classifiers.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like of size (N x d), where N is the number of samples, and d is the number of features.</span></dt>
<dd></dd>
<dt><strong>y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like of size N, where N is the number of samples.</span></dt>
<dd></dd>
<dt><strong>clf</strong> <span class="classifier-delimiter">:</span> <span class="classifier">A <code class="xref py py-class docutils literal"><span class="pre">ClassifierMixin</span></code>.</span></dt>
<dd><p class="first last">A classifier. It must support the methods fit(X,y) and predict(X), as specified in <code class="xref py py-class docutils literal"><span class="pre">ClassifierMixin</span></code></p>
</dd>
<dt><strong>attrs</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=None</span></dt>
<dd><p class="first last">A list specifying the dataset attributes to show in the scatter plot. The items can be the keys, if X is a pandas dataset,
or integer indexes with the attribute position. If None, and xattrs and yattrs are None, all the attributes will be taken.</p>
</dd>
<dt><strong>xattrs</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=None</span></dt>
<dd><p class="first last">A list specifying the dataset attributes to show in X axis. The items can be the keys, if X is a pandas dataset,
or integer indexes with the attribute position. Ignored if attrs is specified.</p>
</dd>
<dt><strong>yattrs</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=None</span></dt>
<dd><p class="first last">A list specifying the dataset attributes to show in Y axis. The items can be the keys, if X is a pandas dataset,
or integer indexes with the attribute position. Ignored if attrs is specified.</p>
</dd>
<dt><strong>sections</strong> <span class="classifier-delimiter">:</span> <span class="classifier">String, default=fitted</span></dt>
<dd><p class="first">It specifies how to take sections in the features space, if there are more than two features in the dataset. It is used to plot the classifier
fixing the non-ploting attributes in this space section. Allowed values are:</p>
<p>‘mean’ : takes the mean of the remaining attributes to plot the classifier region.</p>
<p class="last">‘zeros’ : takes the remaining attributes as zeros to plot the classifier region.</p>
</dd>
<dt><strong>fitted</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=False.</span></dt>
<dd><p class="first last">It indicates if the classifier has already been fitted. If it is false, the function will call the classifier fit method with parameters X,y.</p>
</dd>
<dt><strong>f</strong> <span class="classifier-delimiter">:</span> <span class="classifier">The :class: <cite>~matplotlib.figure.Figure</cite> object to paint. If None, a new object will be created.</span></dt>
<dd></dd>
<dt><strong>ax</strong> <span class="classifier-delimiter">:</span> <span class="classifier">The :class: <cite>~matplotlib.axes.Axes</cite> object to paint. If None, a new object will be created.</span></dt>
<dd></dd>
<dt><strong>title</strong> <span class="classifier-delimiter">:</span> <span class="classifier">String, default=None. An optional title for the plot.</span></dt>
<dd></dd>
<dt><strong>grid_split</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=[400, 400]</span></dt>
<dd><p class="first last">A list with two items, specifying the number of partitions, in the X and Y axis, to make in the plot to paint
the classifier region. Each split will define a point where the predict method of the classifier is evaluated.
It can be None. In this case, the <cite>grid_step</cite> parameter will be considered.</p>
</dd>
<dt><strong>grid_step</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=[0.1,0.1]</span></dt>
<dd><p class="first last">A list with two items, specifying the distance between the points in the grid that defines the classifier plot.classifier
Each created point in this way will define a point where the predict method of the classifier is evaluated.
It is ignored if the parameter <cite>grid_split</cite> is not None.</p>
</dd>
<dt><strong>label_legend</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True. If True, a legend with the labels and its colors will be ploted.</span></dt>
<dd></dd>
<dt><strong>legend_loc</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, string of a pair of floats, default=”lower right”.</span></dt>
<dd><p class="first">Specifies the legend position. Ignored if legend is not plotted. Allowed values are:
‘best’ (0), ‘upper right’ (1), ‘upper left’ (2), ‘lower left’ (3), ‘lower right’ (4),
‘right’ (5), ‘center left’ (6), ‘center right’ (7), ‘lower center’ (8),
‘upper center’ (9), ‘center’ (10).</p>
<p class="last">Alternatively can be a 2-tuple giving x, y of the lower-left corner of the legend in axes coordinates.</p>
</dd>
<dt><strong>cmap</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Colormap, default=None.</span></dt>
<dd><p class="first last">A <code class="xref py py-class docutils literal"><span class="pre">Colormap</span></code> instance or None. If cmap is None and label_colors is None, a default Colormap is used.</p>
</dd>
<dt><strong>label_colors</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=None.</span></dt>
<dd><p class="first last">A list of size C with matplotlib colors, or strings specitying a color, where C is the number of classes in y. Each class will
be plotted with the corresponding color. If cmap is None and label_colors is None, a default Colormap is used.</p>
</dd>
<dt><strong>plot_points</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True.</span></dt>
<dd><p class="first last">If True, points will be plotted.</p>
</dd>
<dt><strong>plot_regions</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True.</span></dt>
<dd><p class="first last">If True, the classifier regions will be plotted.</p>
</dd>
<dt><strong>region_intensity</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Float, default=0.4.</span></dt>
<dd><p class="first last">A float between 0 and 1, indicating the transparency of the colors in the classifier regions respect the point colors.</p>
</dd>
<dt><strong>legend_plot_points</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True.</span></dt>
<dd><p class="first last">If True, points are plotted in the legend.</p>
</dd>
<dt><strong>legend_plot_regions</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True.</span></dt>
<dd><p class="first last">If True, classifier regions are plotted in the legend.</p>
</dd>
<dt><strong>legend_on_axis</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True.</span></dt>
<dd><p class="first last">If True, the legend is plotted inside the scatter plot. Else, it is plotted out of the scatter plot.</p>
</dd>
<dt><strong>fig_kw</strong> <span class="classifier-delimiter">:</span> <span class="classifier">dict</span></dt>
<dd><p class="first last">Additional keyword args for <code class="xref py py-meth docutils literal"><span class="pre">suplots()</span></code></p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>f</strong> <span class="classifier-delimiter">:</span> <span class="classifier">The plotted :class: <cite>~matplotlib.figure.Figure</cite> object.</span></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="dml.dml_plot.classifier_plot">
<code class="descclassname">dml.dml_plot.</code><code class="descname">classifier_plot</code><span class="sig-paren">(</span><em>X, y, clf, attrs=None, sections='mean', fitted=False, f=None, ax=None, title=None, subtitle=None, xrange=None, yrange=None, xlabel=None, ylabel=None, grid_split=[400, 400], grid_step=[0.1, 0.1], label_legend=True, legend_loc='lower right', cmap=None, label_colors=None, plot_points=True, plot_regions=True, region_intensity=0.4, legend_plot_points=True, legend_plot_regions=True, legend_on_axis=True, **fig_kw</em><span class="sig-paren">)</span><a class="headerlink" href="#dml.dml_plot.classifier_plot" title="Permalink to this definition">¶</a></dt>
<dd><p>A 2D-scatter plot for a labeled dataset, together with a classifier that allows to plot each clasiffier region.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like of size (N x d), where N is the number of samples, and d is the number of features.</span></dt>
<dd></dd>
<dt><strong>y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like of size N, where N is the number of samples.</span></dt>
<dd></dd>
<dt><strong>clf</strong> <span class="classifier-delimiter">:</span> <span class="classifier">A classifier. It must support the methods fit(X,y) and predict(X), as specified in <code class="xref py py-class docutils literal"><span class="pre">ClassifierMixin</span></code></span></dt>
<dd></dd>
<dt><strong>attrs</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=None</span></dt>
<dd><p class="first last">A list of two items specifying the dataset attributes to show in the scatter plot. The items can be the keys, if X is a pandas dataset,
or integer indexes with the attribute position. If None, the two first attributes will be taken.</p>
</dd>
<dt><strong>sections</strong> <span class="classifier-delimiter">:</span> <span class="classifier">String, default=fitted</span></dt>
<dd><p class="first">It specifies how to take sections in the features space, if there are more than two features in the dataset. It is used to plot the classifier
fixing the non-ploting attributes in this space section. Allowed values are:</p>
<p>‘mean’ : takes the mean of the remaining attributes to plot the classifier region.</p>
<p class="last">‘zeros’ : takes the remaining attributes as zeros to plot the classifier region.</p>
</dd>
<dt><strong>fitted</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=False.</span></dt>
<dd><p class="first last">It indicates if the classifier has already been fitted. If it is false, the function will call the classifier fit method with parameters X,y.</p>
</dd>
<dt><strong>f</strong> <span class="classifier-delimiter">:</span> <span class="classifier">The :class: <cite>~matplotlib.figure.Figure</cite> object to paint. If None, a new object will be created.</span></dt>
<dd></dd>
<dt><strong>ax</strong> <span class="classifier-delimiter">:</span> <span class="classifier">The :class: <cite>~matplotlib.axes.Axes</cite> object to paint. If None, a new object will be created.</span></dt>
<dd></dd>
<dt><strong>title</strong> <span class="classifier-delimiter">:</span> <span class="classifier">String, default=None. An optional title for the plot.</span></dt>
<dd></dd>
<dt><strong>subtitle</strong> <span class="classifier-delimiter">:</span> <span class="classifier">String, default=None. An optional subtitle for the plot.</span></dt>
<dd></dd>
<dt><strong>xrange</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=None</span></dt>
<dd><p class="first last">A list with two items, specifying the minimum and maximum range to plot in the X axis.
If None, it will be calculated according to the maximum and minimum of the X feature.</p>
</dd>
<dt><strong>yrange</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=None</span></dt>
<dd><p class="first last">A list with two items, specifying the minimum and maximum range to plot in the Y axis.
If None, it will be calculated according to the maximum and minimum of the Y feature.</p>
</dd>
<dt><strong>xlabel</strong> <span class="classifier-delimiter">:</span> <span class="classifier">String, default=None. An optional title for the X axis.</span></dt>
<dd></dd>
<dt><strong>ylabel</strong> <span class="classifier-delimiter">:</span> <span class="classifier">String, default=None. An optional title for the Y axis.</span></dt>
<dd></dd>
<dt><strong>grid_split</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=[400, 400]</span></dt>
<dd><p class="first last">A list with two items, specifying the number of partitions, in the X and Y axis, to make in the plot to paint
the classifier region. Each split will define a point where the predict method of the classifier is evaluated.
It can be None. In this case, the <cite>grid_step</cite> parameter will be considered.</p>
</dd>
<dt><strong>grid_step</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=[0.1,0.1]</span></dt>
<dd><p class="first last">A list with two items, specifying the distance between the points in the grid that defines the classifier plot.classifier
Each created point in this way will define a point where the predict method of the classifier is evaluated.
It is ignored if the parameter <cite>grid_split</cite> is not None.</p>
</dd>
<dt><strong>label_legend</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True. If True, a legend with the labels and its colors will be ploted.</span></dt>
<dd></dd>
<dt><strong>legend_loc</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, string of a pair of floats, default=”lower right”.</span></dt>
<dd><p class="first">Specifies the legend position. Ignored if legend is not plotted. Allowed values are:
‘best’ (0), ‘upper right’ (1), ‘upper left’ (2), ‘lower left’ (3), ‘lower right’ (4),
‘right’ (5), ‘center left’ (6), ‘center right’ (7), ‘lower center’ (8),
‘upper center’ (9), ‘center’ (10).</p>
<p class="last">Alternatively can be a 2-tuple giving x, y of the lower-left corner of the legend in axes coordinates.</p>
</dd>
<dt><strong>cmap</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Colormap, default=None.</span></dt>
<dd><p class="first last">A <code class="xref py py-class docutils literal"><span class="pre">Colormap</span></code> instance or None. If cmap is None and label_colors is None, a default Colormap is used.</p>
</dd>
<dt><strong>label_colors</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=None.</span></dt>
<dd><p class="first last">A list of size C with matplotlib colors, or strings specitying a color, where C is the number of classes in y. Each class will
be plotted with the corresponding color. If cmap is None and label_colors is None, a default Colormap is used.</p>
</dd>
<dt><strong>plot_points</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True.</span></dt>
<dd><p class="first last">If True, points will be plotted.</p>
</dd>
<dt><strong>plot_regions</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True.</span></dt>
<dd><p class="first last">If True, the classifier regions will be plotted.</p>
</dd>
<dt><strong>region_intensity</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Float, default=0.4.</span></dt>
<dd><p class="first last">A float between 0 and 1, indicating the transparency of the colors in the classifier regions respect the point colors.</p>
</dd>
<dt><strong>legend_plot_points</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True.</span></dt>
<dd><p class="first last">If True, points are plotted in the legend.</p>
</dd>
<dt><strong>legend_plot_regions</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True.</span></dt>
<dd><p class="first last">If True, classifier regions are plotted in the legend.</p>
</dd>
<dt><strong>legend_on_axis</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True.</span></dt>
<dd><p class="first last">If True, the legend is plotted inside the scatter plot. Else, it is plotted out of the scatter plot.</p>
</dd>
<dt><strong>fig_kw</strong> <span class="classifier-delimiter">:</span> <span class="classifier">dict</span></dt>
<dd><p class="first last">Additional keyword args for <code class="xref py py-meth docutils literal"><span class="pre">suplots()</span></code></p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>f</strong> <span class="classifier-delimiter">:</span> <span class="classifier">The plotted :class: <cite>~matplotlib.figure.Figure</cite> object.</span></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="dml.dml_plot.classifier_plot_3d">
<code class="descclassname">dml.dml_plot.</code><code class="descname">classifier_plot_3d</code><span class="sig-paren">(</span><em>X, y, clf, attrs=None, sections='mean', fitted=False, f=None, ax=None, elev=0.0, azim=0.0, title=None, subtitle=None, xrange=None, yrange=None, zrange=None, xlabel=None, ylabel=None, zlabel=None, grid_split=[40, 40, 40], grid_step=[0.1, 0.1, 0.1], label_legend=True, legend_loc='lower right', cmap=None, label_colors=None, plot_points=True, plot_regions='all', region_intensity=0.4, legend_plot_points=True, legend_plot_regions=True, legend_on_axis=True, **fig_kw</em><span class="sig-paren">)</span><a class="headerlink" href="#dml.dml_plot.classifier_plot_3d" title="Permalink to this definition">¶</a></dt>
<dd><p>A 3D-scatter plot for a labeled dataset, together with a classifier that allows to plot each clasiffier region.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like of size (N x d), where N is the number of samples, and d is the number of features.</span></dt>
<dd></dd>
<dt><strong>y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like of size N, where N is the number of samples.</span></dt>
<dd></dd>
<dt><strong>clf</strong> <span class="classifier-delimiter">:</span> <span class="classifier">A classifier. It must support the methods fit(X,y) and predict(X), as specified in <code class="xref py py-class docutils literal"><span class="pre">ClassifierMixin</span></code></span></dt>
<dd></dd>
<dt><strong>attrs</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=None</span></dt>
<dd><p class="first last">A list of three items specifying the dataset attributes to show in the scatter plot. The items can be the keys, if X is a pandas dataset,
or integer indexes with the attribute position. If None, the three first attributes will be taken.</p>
</dd>
<dt><strong>sections</strong> <span class="classifier-delimiter">:</span> <span class="classifier">String, default=fitted</span></dt>
<dd><p class="first">It specifies how to take sections in the features space, if there are more than two features in the dataset. It is used to plot the classifier
fixing the non-ploting attributes in this space section. Allowed values are:</p>
<p>‘mean’ : takes the mean of the remaining attributes to plot the classifier region.</p>
<p class="last">‘zeros’ : takes the remaining attributes as zeros to plot the classifier region.</p>
</dd>
<dt><strong>fitted</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=False.</span></dt>
<dd><p class="first last">It indicates if the classifier has already been fitted. If it is false, the function will call the classifier fit method with parameters X,y.</p>
</dd>
<dt><strong>f</strong> <span class="classifier-delimiter">:</span> <span class="classifier">The :class: <cite>~matplotlib.figure.Figure</cite> object to paint. If None, a new object will be created.</span></dt>
<dd></dd>
<dt><strong>ax</strong> <span class="classifier-delimiter">:</span> <span class="classifier">The :class: <cite>~matplotlib.axes.Axes</cite> object to paint. If None, a new object will be created.</span></dt>
<dd></dd>
<dt><strong>elev</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Float, default=0.0</span></dt>
<dd><p class="first last">The elevation parameter for the 3D plot.</p>
</dd>
<dt><strong>azim</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Float, default=0.0</span></dt>
<dd><p class="first last">The azimut parameter for the 3D plot.</p>
</dd>
<dt><strong>title</strong> <span class="classifier-delimiter">:</span> <span class="classifier">String, default=None. An optional title for the plot.</span></dt>
<dd></dd>
<dt><strong>subtitle</strong> <span class="classifier-delimiter">:</span> <span class="classifier">String, default=None. An optional subtitle for the plot.</span></dt>
<dd></dd>
<dt><strong>xrange</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=None</span></dt>
<dd><p class="first last">A list with two items, specifying the minimum and maximum range to plot in the X axis.
If None, it will be calculated according to the maximum and minimum of the X feature.</p>
</dd>
<dt><strong>yrange</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=None</span></dt>
<dd><p class="first last">A list with two items, specifying the minimum and maximum range to plot in the Y axis.
If None, it will be calculated according to the maximum and minimum of the Y feature.</p>
</dd>
<dt><strong>zrange</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=None</span></dt>
<dd><p class="first last">A list with two items, specifying the minimum and maximum range to plot in the Ζ axis.
If None, it will be calculated according to the maximum and minimum of the Ζ feature.</p>
</dd>
<dt><strong>xlabel</strong> <span class="classifier-delimiter">:</span> <span class="classifier">String, default=None. An optional title for the X axis.</span></dt>
<dd></dd>
<dt><strong>ylabel</strong> <span class="classifier-delimiter">:</span> <span class="classifier">String, default=None. An optional title for the Y axis.</span></dt>
<dd></dd>
<dt><strong>zlabel</strong> <span class="classifier-delimiter">:</span> <span class="classifier">String, default=None. An optional title for the Ζ axis.</span></dt>
<dd></dd>
<dt><strong>grid_split</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=[40, 40, 40]</span></dt>
<dd><p class="first last">A list with three items, specifying the number of partitions, in the X, Y  and Z axis, to make in the plot to paint
the classifier region. Each split will define a point where the predict method of the classifier is evaluated.
It can be None. In this case, the <cite>grid_step</cite> parameter will be considered.</p>
</dd>
<dt><strong>grid_step</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=[0.1, 0.1, 0.1]</span></dt>
<dd><p class="first last">A list with three items, specifying the distance between the points in the grid that defines the classifier plot.classifier
Each created point in this way will define a point where the predict method of the classifier is evaluated.
It is ignored if the parameter <cite>grid_split</cite> is not None.</p>
</dd>
<dt><strong>label_legend</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True. If True, a legend with the labels and its colors will be ploted.</span></dt>
<dd></dd>
<dt><strong>legend_loc</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, string of a pair of floats, default=”lower right”.</span></dt>
<dd><p class="first">Specifies the legend position. Ignored if legend is not plotted. Allowed values are:
‘best’ (0), ‘upper right’ (1), ‘upper left’ (2), ‘lower left’ (3), ‘lower right’ (4),
‘right’ (5), ‘center left’ (6), ‘center right’ (7), ‘lower center’ (8),
‘upper center’ (9), ‘center’ (10).</p>
<p class="last">Alternatively can be a 2-tuple giving x, y of the lower-left corner of the legend in axes coordinates.</p>
</dd>
<dt><strong>cmap</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Colormap, default=None.</span></dt>
<dd><p class="first last">A <code class="xref py py-class docutils literal"><span class="pre">Colormap</span></code> instance or None. If cmap is None and label_colors is None, a default Colormap is used.</p>
</dd>
<dt><strong>label_colors</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=None.</span></dt>
<dd><p class="first last">A list of size C with matplotlib colors, or strings specitying a color, where C is the number of classes in y. Each class will
be plotted with the corresponding color. If cmap is None and label_colors is None, a default Colormap is used.</p>
</dd>
<dt><strong>plot_points</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True.</span></dt>
<dd><p class="first last">If True, points will be plotted.</p>
</dd>
<dt><strong>plot_regions</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True.</span></dt>
<dd><p class="first last">If True, the classifier regions will be plotted.</p>
</dd>
<dt><strong>region_intensity</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Float, default=0.4.</span></dt>
<dd><p class="first last">A float between 0 and 1, indicating the transparency of the colors in the classifier regions respect the point colors.</p>
</dd>
<dt><strong>legend_plot_points</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True.</span></dt>
<dd><p class="first last">If True, points are plotted in the legend.</p>
</dd>
<dt><strong>legend_plot_regions</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True.</span></dt>
<dd><p class="first last">If True, classifier regions are plotted in the legend.</p>
</dd>
<dt><strong>legend_on_axis</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True.</span></dt>
<dd><p class="first last">If True, the legend is plotted inside the scatter plot. Else, it is plotted out of the scatter plot.</p>
</dd>
<dt><strong>fig_kw</strong> <span class="classifier-delimiter">:</span> <span class="classifier">dict</span></dt>
<dd><p class="first last">Additional keyword args for <code class="xref py py-meth docutils literal"><span class="pre">suplots()</span></code></p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>f</strong> <span class="classifier-delimiter">:</span> <span class="classifier">The plotted :class: <cite>~matplotlib.figure.Figure</cite> object.</span></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="dml.dml_plot.dml_multiplot">
<code class="descclassname">dml.dml_plot.</code><code class="descname">dml_multiplot</code><span class="sig-paren">(</span><em>X, y, nrow=None, ncol=None, ks=None, clfs=None, attrs=None, sections='mean', fitted=False, metrics=None, transformers=None, dmls=None, dml_fitted=False, transforms=None, title=None, subtitles=None, xlabels=None, ylabels=None, grid_split=[400, 400], grid_step=[0.1, 0.1], label_legend=True, legend_loc='center right', cmap=None, label_colors=None, plot_points=True, plot_regions=True, region_intensity=0.4, legend_plot_points=True, legend_plot_regions=True, legend_on_axis=False, **fig_kw</em><span class="sig-paren">)</span><a class="headerlink" href="#dml.dml_plot.dml_multiplot" title="Permalink to this definition">¶</a></dt>
<dd><p>This functions allows multiple 2D-scatter plots for a labeled dataset, to plot regions defined by different classifiers and distances.
The distances can be provided by a metric PSD matrix, a matrix of a linear transformation, or by a distance metric
learning algorithm, that can learn the distance during the plotting, or it can be fitted previously.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like of size (N x d), where N is the number of samples, and d is the number of features.</span></dt>
<dd></dd>
<dt><strong>y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like of size N, where N is the number of samples.</span></dt>
<dd></dd>
<dt><strong>nrow</strong> <span class="classifier-delimiter">:</span> <span class="classifier">integer, default=None.</span></dt>
<dd><p class="first last">Number of rows of the figure. If any of nrow or ncol is None, it will be generated automatically.</p>
</dd>
<dt><strong>ncol</strong> <span class="classifier-delimiter">:</span> <span class="classifier">integer, default=None.</span></dt>
<dd><p class="first last">Number of columns of the figure. If any of nrow or ncol is None, it will be generated automatically.</p>
</dd>
<dt><strong>ks</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List of int, default=None.</span></dt>
<dd><p class="first last">The number of neighbors for the k-NN classifier in each plot. List size must be equal to the number of plots.
ks[i] is ignored if clfs[i] is specified.</p>
</dd>
<dt><strong>clfs</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List of <code class="xref py py-class docutils literal"><span class="pre">ClassifierMixin</span></code>. Default=None.</span></dt>
<dd><p class="first last">The classifier to use in each plot. List size must be equal to the number of plots.</p>
</dd>
<dt><strong>attrs</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=None</span></dt>
<dd><p class="first last">A list of two items specifying the dataset attributes to show in the scatter plot. The items can be the keys, if X is a pandas dataset,
or integer indexes with the attribute position. If None, the two first attributes will be taken.</p>
</dd>
<dt><strong>sections</strong> <span class="classifier-delimiter">:</span> <span class="classifier">String, default=fitted</span></dt>
<dd><p class="first">It specifies how to take sections in the features space, if there are more than two features in the dataset. It is used to plot the classifier
fixing the non-ploting attributes in this space section. Allowed values are:</p>
<p>‘mean’ : takes the mean of the remaining attributes to plot the classifier region.</p>
<p class="last">‘zeros’ : takes the remaining attributes as zeros to plot the classifier region.</p>
</dd>
<dt><strong>fitted</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=False.</span></dt>
<dd><p class="first last">It indicates if the classifier has already been fitted. If it is false, the function will call the classifier fit method with parameters X,y.</p>
</dd>
<dt><strong>metrics</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List of Matrix, or 2D-Array. Default=None.</span></dt>
<dd><p class="first last">The metric PSD matrix to use in each plot. List size must be equal to the number of plots.
metrics[i] is ignored if transformers[i] or dmls[i] are provided.</p>
</dd>
<dt><strong>transformers</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List of Matrix, or 2D-Array. Default=None.</span></dt>
<dd><p class="first last">A linear transformation to use in each plot. List size must be equal to the number of plots.
transformers[i] will be ignored if dmls[i] is provided.</p>
</dd>
<dt><strong>dmls</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List of DML_Algorithm, default=None.</span></dt>
<dd><p class="first last">A distance metric learning algorithm for each plot. List size must be equal to the number of plots.</p>
</dd>
<dt><strong>dml_fitted</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True.</span></dt>
<dd><p class="first last">Specifies if the DML algorithms are already fitted. If True, the algorithms’ fit method will not be called.</p>
</dd>
<dt><strong>transforms: List of Boolean, default=True.</strong></dt>
<dd><p class="first last">For each plot where the list item is True, it projects the data by the learned transformer and plots the transform data.
Else, the classifier region will be ploted with the original data, but the regions will change according to the learned distance.
List size must be equal to the number of plots.</p>
</dd>
<dt><strong>f</strong> <span class="classifier-delimiter">:</span> <span class="classifier">The :class: <cite>~matplotlib.figure.Figure</cite> object to paint. If None, a new object will be created.</span></dt>
<dd></dd>
<dt><strong>ax</strong> <span class="classifier-delimiter">:</span> <span class="classifier">The :class: <cite>~matplotlib.axes.Axes</cite> object to paint. If None, a new object will be created.</span></dt>
<dd></dd>
<dt><strong>title</strong> <span class="classifier-delimiter">:</span> <span class="classifier">String, default=None. An optional title for the plot.</span></dt>
<dd></dd>
<dt><strong>subtitles</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List of String, default=None.</span></dt>
<dd><p class="first last">Optional titles for each subplot. List size must be equal to the number of plots.</p>
</dd>
<dt><strong>xlabels</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List of String, default=None.</span></dt>
<dd><p class="first last">Optional titles for the X axis. List size must be equal to the number of plots.</p>
</dd>
<dt><strong>ylabels</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List of String, default=None.</span></dt>
<dd><p class="first last">Optional titles for the Y axis. List size must be equal to the number of plots.</p>
</dd>
<dt><strong>grid_split</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=[400, 400]</span></dt>
<dd><p class="first last">A list with two items, specifying the number of partitions, in the X and Y axis, to make in the plot to paint
the classifier region. Each split will define a point where the predict method of the classifier is evaluated.
It can be None. In this case, the <cite>grid_step</cite> parameter will be considered.</p>
</dd>
<dt><strong>grid_step</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=[0.1,0.1]</span></dt>
<dd><p class="first last">A list with two items, specifying the distance between the points in the grid that defines the classifier plot.classifier
Each created point in this way will define a point where the predict method of the classifier is evaluated.
It is ignored if the parameter <cite>grid_split</cite> is not None.</p>
</dd>
<dt><strong>label_legend</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True. If True, a legend with the labels and its colors will be ploted.</span></dt>
<dd></dd>
<dt><strong>legend_loc</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, string of a pair of floats, default=”lower right”.</span></dt>
<dd><p class="first">Specifies the legend position. Ignored if legend is not plotted. Allowed values are:
‘best’ (0), ‘upper right’ (1), ‘upper left’ (2), ‘lower left’ (3), ‘lower right’ (4),
‘right’ (5), ‘center left’ (6), ‘center right’ (7), ‘lower center’ (8),
‘upper center’ (9), ‘center’ (10).</p>
<p class="last">Alternatively can be a 2-tuple giving x, y of the lower-left corner of the legend in axes coordinates.</p>
</dd>
<dt><strong>cmap</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Colormap, default=None.</span></dt>
<dd><p class="first last">A <code class="xref py py-class docutils literal"><span class="pre">Colormap</span></code> instance or None. If cmap is None and label_colors is None, a default Colormap is used.</p>
</dd>
<dt><strong>label_colors</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=None.</span></dt>
<dd><p class="first last">A list of size C with matplotlib colors, or strings specitying a color, where C is the number of classes in y. Each class will
be plotted with the corresponding color. If cmap is None and label_colors is None, a default Colormap is used.</p>
</dd>
<dt><strong>plot_points</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True.</span></dt>
<dd><p class="first last">If True, points will be plotted.</p>
</dd>
<dt><strong>plot_regions</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True.</span></dt>
<dd><p class="first last">If True, the classifier regions will be plotted.</p>
</dd>
<dt><strong>region_intensity</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Float, default=0.4.</span></dt>
<dd><p class="first last">A float between 0 and 1, indicating the transparency of the colors in the classifier regions respect the point colors.</p>
</dd>
<dt><strong>legend_plot_points</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True.</span></dt>
<dd><p class="first last">If True, points are plotted in the legend.</p>
</dd>
<dt><strong>legend_plot_regions</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True.</span></dt>
<dd><p class="first last">If True, classifier regions are plotted in the legend.</p>
</dd>
<dt><strong>legend_on_axis</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=False.</span></dt>
<dd><p class="first last">If True, the legend is plotted inside the scatter plot. Else, it is plotted out of the scatter plot.</p>
</dd>
<dt><strong>fig_kw</strong> <span class="classifier-delimiter">:</span> <span class="classifier">dict</span></dt>
<dd><p class="first last">Additional keyword args for <code class="xref py py-meth docutils literal"><span class="pre">suplots()</span></code></p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>f</strong> <span class="classifier-delimiter">:</span> <span class="classifier">The plotted :class: <cite>~matplotlib.figure.Figure</cite> object.</span></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="dml.dml_plot.dml_pairplots">
<code class="descclassname">dml.dml_plot.</code><code class="descname">dml_pairplots</code><span class="sig-paren">(</span><em>X, y, clf, attrs=None, xattrs=None, yattrs=None, diag='hist', sections='mean', fitted=False, metric=None, transformer=None, dml=None, dml_fitted=False, title=None, grid_split=[400, 400], grid_step=[0.1, 0.1], label_legend=True, legend_loc='center right', cmap=None, label_colors=None, plot_points=True, plot_regions=True, region_intensity=0.4, legend_plot_points=True, legend_plot_regions=True, legend_on_axis=False, **fig_kw</em><span class="sig-paren">)</span><a class="headerlink" href="#dml.dml_plot.dml_pairplots" title="Permalink to this definition">¶</a></dt>
<dd><p>This function allows multiple 2D-scatter plots for different pairs of attributes of the same dataset, and
to plot regions defined by different classifiers and a distance.
The distance can be provided by a metric PSD matrix, a matrix of a linear transformation, or by a distance metric
learning algorithm, that can learn the distance during the plotting, or it can be fitted previously.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like of size (N x d), where N is the number of samples, and d is the number of features.</span></dt>
<dd></dd>
<dt><strong>y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like of size N, where N is the number of samples.</span></dt>
<dd></dd>
<dt><strong>clf</strong> <span class="classifier-delimiter">:</span> <span class="classifier">A <code class="xref py py-class docutils literal"><span class="pre">ClassifierMixin</span></code>.</span></dt>
<dd><p class="first last">A classifier. It must support the methods fit(X,y) and predict(X), as specified in <code class="xref py py-class docutils literal"><span class="pre">ClassifierMixin</span></code></p>
</dd>
<dt><strong>attrs</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=None</span></dt>
<dd><p class="first last">A list specifying the dataset attributes to show in the scatter plot. The items can be the keys, if X is a pandas dataset,
or integer indexes with the attribute position. If None, and xattrs and yattrs are None, all the attributes will be taken.</p>
</dd>
<dt><strong>xattrs</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=None</span></dt>
<dd><p class="first last">A list specifying the dataset attributes to show in X axis. The items can be the keys, if X is a pandas dataset,
or integer indexes with the attribute position. Ignored if attrs is specified.</p>
</dd>
<dt><strong>yattrs</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=None</span></dt>
<dd><p class="first last">A list specifying the dataset attributes to show in Y axis. The items can be the keys, if X is a pandas dataset,
or integer indexes with the attribute position. Ignored if attrs is specified.</p>
</dd>
<dt><strong>sections</strong> <span class="classifier-delimiter">:</span> <span class="classifier">String, default=fitted</span></dt>
<dd><p class="first">It specifies how to take sections in the features space, if there are more than two features in the dataset. It is used to plot the classifier
fixing the non-ploting attributes in this space section. Allowed values are:</p>
<p>‘mean’ : takes the mean of the remaining attributes to plot the classifier region.</p>
<p class="last">‘zeros’ : takes the remaining attributes as zeros to plot the classifier region.</p>
</dd>
<dt><strong>fitted</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=False.</span></dt>
<dd><p class="first last">It indicates if the classifier has already been fitted. If it is false, the function will call the classifier fit method with parameters X,y.</p>
</dd>
<dt><strong>metric</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Matrix, or 2D-Array. Default=None.</span></dt>
<dd><p class="first last">A positive semidefinite matrix of size (d x d), where d is the number of features. Ignored if dml or transformer is specified.</p>
</dd>
<dt><strong>transformer</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Matrix, or 2D-Array. Default=None.</span></dt>
<dd><p class="first last">A matrix of size (d’ x d), where d is the number of features and d’ is the desired dimension. Ignored if dml is specified.</p>
</dd>
<dt><strong>dml</strong> <span class="classifier-delimiter">:</span> <span class="classifier">DML_Algorithm, default=None.</span></dt>
<dd><p class="first last">A distance metric learning algorithm. If metric, transformer and dml are None, no distances are used in the plot.</p>
</dd>
<dt><strong>dml_fitted</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True.</span></dt>
<dd><p class="first last">Specifies if the DML algorithm is already fitted. If True, the algorithm’s fit method will not be called.</p>
</dd>
<dt><strong>transform: Boolean, default=True.</strong></dt>
<dd><p class="first last">If True, projects the data by the learned transformer and plots the transform data. Else, the classifier region will
be ploted with the original data, but the regions will change according to the learned distance.</p>
</dd>
<dt><strong>f</strong> <span class="classifier-delimiter">:</span> <span class="classifier">The :class: <cite>~matplotlib.figure.Figure</cite> object to paint. If None, a new object will be created.</span></dt>
<dd></dd>
<dt><strong>ax</strong> <span class="classifier-delimiter">:</span> <span class="classifier">The :class: <cite>~matplotlib.axes.Axes</cite> object to paint. If None, a new object will be created.</span></dt>
<dd></dd>
<dt><strong>title</strong> <span class="classifier-delimiter">:</span> <span class="classifier">String, default=None. An optional title for the plot.</span></dt>
<dd></dd>
<dt><strong>grid_split</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=[400, 400]</span></dt>
<dd><p class="first last">A list with two items, specifying the number of partitions, in the X and Y axis, to make in the plot to paint
the classifier region. Each split will define a point where the predict method of the classifier is evaluated.
It can be None. In this case, the <cite>grid_step</cite> parameter will be considered.</p>
</dd>
<dt><strong>grid_step</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=[0.1,0.1]</span></dt>
<dd><p class="first last">A list with two items, specifying the distance between the points in the grid that defines the classifier plot.classifier
Each created point in this way will define a point where the predict method of the classifier is evaluated.
It is ignored if the parameter <cite>grid_split</cite> is not None.</p>
</dd>
<dt><strong>label_legend</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True. If True, a legend with the labels and its colors will be ploted.</span></dt>
<dd></dd>
<dt><strong>legend_loc</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, string of a pair of floats, default=”lower right”.</span></dt>
<dd><p class="first">Specifies the legend position. Ignored if legend is not plotted. Allowed values are:
‘best’ (0), ‘upper right’ (1), ‘upper left’ (2), ‘lower left’ (3), ‘lower right’ (4),
‘right’ (5), ‘center left’ (6), ‘center right’ (7), ‘lower center’ (8),
‘upper center’ (9), ‘center’ (10).</p>
<p class="last">Alternatively can be a 2-tuple giving x, y of the lower-left corner of the legend in axes coordinates.</p>
</dd>
<dt><strong>cmap</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Colormap, default=None.</span></dt>
<dd><p class="first last">A <code class="xref py py-class docutils literal"><span class="pre">Colormap</span></code> instance or None. If cmap is None and label_colors is None, a default Colormap is used.</p>
</dd>
<dt><strong>label_colors</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=None.</span></dt>
<dd><p class="first last">A list of size C with matplotlib colors, or strings specitying a color, where C is the number of classes in y. Each class will
be plotted with the corresponding color. If cmap is None and label_colors is None, a default Colormap is used.</p>
</dd>
<dt><strong>plot_points</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True.</span></dt>
<dd><p class="first last">If True, points will be plotted.</p>
</dd>
<dt><strong>plot_regions</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True.</span></dt>
<dd><p class="first last">If True, the classifier regions will be plotted.</p>
</dd>
<dt><strong>region_intensity</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Float, default=0.4.</span></dt>
<dd><p class="first last">A float between 0 and 1, indicating the transparency of the colors in the classifier regions respect the point colors.</p>
</dd>
<dt><strong>legend_plot_points</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True.</span></dt>
<dd><p class="first last">If True, points are plotted in the legend.</p>
</dd>
<dt><strong>legend_plot_regions</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True.</span></dt>
<dd><p class="first last">If True, classifier regions are plotted in the legend.</p>
</dd>
<dt><strong>legend_on_axis</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True.</span></dt>
<dd><p class="first last">If True, the legend is plotted inside the scatter plot. Else, it is plotted out of the scatter plot.</p>
</dd>
<dt><strong>fig_kw</strong> <span class="classifier-delimiter">:</span> <span class="classifier">dict</span></dt>
<dd><p class="first last">Additional keyword args for <code class="xref py py-meth docutils literal"><span class="pre">suplots()</span></code></p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>f</strong> <span class="classifier-delimiter">:</span> <span class="classifier">The plotted :class: <cite>~matplotlib.figure.Figure</cite> object.</span></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="dml.dml_plot.dml_plot">
<code class="descclassname">dml.dml_plot.</code><code class="descname">dml_plot</code><span class="sig-paren">(</span><em>X, y, clf, attrs=None, sections='mean', fitted=False, metric=None, transformer=None, dml=None, dml_fitted=False, transform=True, f=None, ax=None, title=None, subtitle=None, xrange=None, yrange=None, xlabel=None, ylabel=None, grid_split=[400, 400], grid_step=[0.1, 0.1], label_legend=True, legend_loc='lower right', cmap=None, label_colors=None, plot_points=True, plot_regions=True, region_intensity=0.4, legend_plot_points=True, legend_plot_regions=True, legend_on_axis=True, **fig_kw</em><span class="sig-paren">)</span><a class="headerlink" href="#dml.dml_plot.dml_plot" title="Permalink to this definition">¶</a></dt>
<dd><p>A 2D-scatter plot for a labeled dataset, together with a classifier that allows to plot each clasiffier region, and a distance that can be
used by the classifier. The distance can be provided by a metric PSD matrix, a matrix of a linear transformation, or by a distance metric
learning algorithm, that can learn the distance during the plotting, or it can be fitted previously.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like of size (N x d), where N is the number of samples, and d is the number of features.</span></dt>
<dd></dd>
<dt><strong>y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like of size N, where N is the number of samples.</span></dt>
<dd></dd>
<dt><strong>clf</strong> <span class="classifier-delimiter">:</span> <span class="classifier">A classifier. It must support the methods fit(X,y) and predict(X), as specified in <code class="xref py py-class docutils literal"><span class="pre">ClassifierMixin</span></code></span></dt>
<dd></dd>
<dt><strong>attrs</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=None</span></dt>
<dd><p class="first last">A list of two items specifying the dataset attributes to show in the scatter plot. The items can be the keys, if X is a pandas dataset,
or integer indexes with the attribute position. If None, the two first attributes will be taken.</p>
</dd>
<dt><strong>sections</strong> <span class="classifier-delimiter">:</span> <span class="classifier">String, default=fitted</span></dt>
<dd><p class="first">It specifies how to take sections in the features space, if there are more than two features in the dataset. It is used to plot the classifier
fixing the non-ploting attributes in this space section. Allowed values are:</p>
<p>‘mean’ : takes the mean of the remaining attributes to plot the classifier region.</p>
<p class="last">‘zeros’ : takes the remaining attributes as zeros to plot the classifier region.</p>
</dd>
<dt><strong>fitted</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=False.</span></dt>
<dd><p class="first last">It indicates if the classifier has already been fitted. If it is false, the function will call the classifier fit method with parameters X,y.</p>
</dd>
<dt><strong>metric</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Matrix, or 2D-Array. Default=None.</span></dt>
<dd><p class="first last">A positive semidefinite matrix of size (d x d), where d is the number of features. Ignored if dml or transformer is specified.</p>
</dd>
<dt><strong>transformer</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Matrix, or 2D-Array. Default=None.</span></dt>
<dd><p class="first last">A matrix of size (d’ x d), where d is the number of features and d’ is the desired dimension. Ignored if dml is specified.</p>
</dd>
<dt><strong>dml</strong> <span class="classifier-delimiter">:</span> <span class="classifier">DML_Algorithm, default=None.</span></dt>
<dd><p class="first last">A distance metric learning algorithm. If metric, transformer and dml are None, no distances are used in the plot.</p>
</dd>
<dt><strong>transform: Boolean, default=True.</strong></dt>
<dd><p class="first last">If True, projects the data by the learned transformer and plots the transform data. Else, the classifier region will
be ploted with the original data, but the regions will change according to the learned distance.</p>
</dd>
<dt><strong>f</strong> <span class="classifier-delimiter">:</span> <span class="classifier">The :class: <cite>~matplotlib.figure.Figure</cite> object to paint. If None, a new object will be created.</span></dt>
<dd></dd>
<dt><strong>ax</strong> <span class="classifier-delimiter">:</span> <span class="classifier">The :class: <cite>~matplotlib.axes.Axes</cite> object to paint. If None, a new object will be created.</span></dt>
<dd></dd>
<dt><strong>title</strong> <span class="classifier-delimiter">:</span> <span class="classifier">String, default=None. An optional title for the plot.</span></dt>
<dd></dd>
<dt><strong>subtitle</strong> <span class="classifier-delimiter">:</span> <span class="classifier">String, default=None. An optional subtitle for the plot.</span></dt>
<dd></dd>
<dt><strong>xrange</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=None</span></dt>
<dd><p class="first last">A list with two items, specifying the minimum and maximum range to plot in the X axis.
If None, it will be calculated according to the maximum and minimum of the X feature.</p>
</dd>
<dt><strong>yrange</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=None</span></dt>
<dd><p class="first last">A list with two items, specifying the minimum and maximum range to plot in the Y axis.
If None, it will be calculated according to the maximum and minimum of the Y feature.</p>
</dd>
<dt><strong>xlabel</strong> <span class="classifier-delimiter">:</span> <span class="classifier">String, default=None. An optional title for the X axis.</span></dt>
<dd></dd>
<dt><strong>ylabel</strong> <span class="classifier-delimiter">:</span> <span class="classifier">String, default=None. An optional title for the Y axis.</span></dt>
<dd></dd>
<dt><strong>grid_split</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=[400, 400]</span></dt>
<dd><p class="first last">A list with two items, specifying the number of partitions, in the X and Y axis, to make in the plot to paint
the classifier region. Each split will define a point where the predict method of the classifier is evaluated.
It can be None. In this case, the <cite>grid_step</cite> parameter will be considered.</p>
</dd>
<dt><strong>grid_step</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=[0.1,0.1]</span></dt>
<dd><p class="first last">A list with two items, specifying the distance between the points in the grid that defines the classifier plot.classifier
Each created point in this way will define a point where the predict method of the classifier is evaluated.
It is ignored if the parameter <cite>grid_split</cite> is not None.</p>
</dd>
<dt><strong>label_legend</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True. If True, a legend with the labels and its colors will be ploted.</span></dt>
<dd></dd>
<dt><strong>legend_loc</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, string of a pair of floats, default=”lower right”.</span></dt>
<dd><p class="first">Specifies the legend position. Ignored if legend is not plotted. Allowed values are:
‘best’ (0), ‘upper right’ (1), ‘upper left’ (2), ‘lower left’ (3), ‘lower right’ (4),
‘right’ (5), ‘center left’ (6), ‘center right’ (7), ‘lower center’ (8),
‘upper center’ (9), ‘center’ (10).</p>
<p class="last">Alternatively can be a 2-tuple giving x, y of the lower-left corner of the legend in axes coordinates.</p>
</dd>
<dt><strong>cmap</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Colormap, default=None.</span></dt>
<dd><p class="first last">A <code class="xref py py-class docutils literal"><span class="pre">Colormap</span></code> instance or None. If cmap is None and label_colors is None, a default Colormap is used.</p>
</dd>
<dt><strong>label_colors</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=None.</span></dt>
<dd><p class="first last">A list of size C with matplotlib colors, or strings specitying a color, where C is the number of classes in y. Each class will
be plotted with the corresponding color. If cmap is None and label_colors is None, a default Colormap is used.</p>
</dd>
<dt><strong>plot_points</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True.</span></dt>
<dd><p class="first last">If True, points will be plotted.</p>
</dd>
<dt><strong>plot_regions</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True.</span></dt>
<dd><p class="first last">If True, the classifier regions will be plotted.</p>
</dd>
<dt><strong>region_intensity</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Float, default=0.4.</span></dt>
<dd><p class="first last">A float between 0 and 1, indicating the transparency of the colors in the classifier regions respect the point colors.</p>
</dd>
<dt><strong>legend_plot_points</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True.</span></dt>
<dd><p class="first last">If True, points are plotted in the legend.</p>
</dd>
<dt><strong>legend_plot_regions</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True.</span></dt>
<dd><p class="first last">If True, classifier regions are plotted in the legend.</p>
</dd>
<dt><strong>legend_on_axis</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True.</span></dt>
<dd><p class="first last">If True, the legend is plotted inside the scatter plot. Else, it is plotted out of the scatter plot.</p>
</dd>
<dt><strong>fig_kw</strong> <span class="classifier-delimiter">:</span> <span class="classifier">dict</span></dt>
<dd><p class="first last">Additional keyword args for <code class="xref py py-meth docutils literal"><span class="pre">suplots()</span></code></p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>f</strong> <span class="classifier-delimiter">:</span> <span class="classifier">The plotted :class: <cite>~matplotlib.figure.Figure</cite> object.</span></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="dml.dml_plot.knn_pairplots">
<code class="descclassname">dml.dml_plot.</code><code class="descname">knn_pairplots</code><span class="sig-paren">(</span><em>X, y, k=1, attrs=None, xattrs=None, yattrs=None, diag='hist', sections='mean', knn_clf=None, fitted=False, metric=None, transformer=None, dml=None, dml_fitted=False, title=None, grid_split=[400, 400], grid_step=[0.1, 0.1], label_legend=True, legend_loc='center right', cmap=None, label_colors=None, plot_points=True, plot_regions=True, region_intensity=0.4, legend_plot_points=True, legend_plot_regions=True, legend_on_axis=False, **fig_kw</em><span class="sig-paren">)</span><a class="headerlink" href="#dml.dml_plot.knn_pairplots" title="Permalink to this definition">¶</a></dt>
<dd><p>This function allows multiple 2D-scatter plots for different pairs of attributes of the same dataset, and
to plot regions defined by a k-NN classifier and a distance.
The distance can be provided by a metric PSD matrix, a matrix of a linear transformation, or by a distance metric
learning algorithm, that can learn the distance during the plotting, or it can be fitted previously.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like of size (N x d), where N is the number of samples, and d is the number of features.</span></dt>
<dd></dd>
<dt><strong>y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like of size N, where N is the number of samples.</span></dt>
<dd></dd>
<dt><strong>k</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=1.</span></dt>
<dd><p class="first last">The number of neighbors for the k-NN classifier. Ignored if knn_clf is specified.</p>
</dd>
<dt><strong>knn_clf</strong> <span class="classifier-delimiter">:</span> <span class="classifier">A <code class="xref py py-class docutils literal"><span class="pre">ClassifierMixin</span></code>.</span></dt>
<dd><p class="first last">An already defined kNN classifier. It can be any other classifier, but then options are the same as in :meth: <cite>~dml_plot</cite>.</p>
</dd>
<dt><strong>attrs</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=None</span></dt>
<dd><p class="first last">A list specifying the dataset attributes to show in the scatter plot. The items can be the keys, if X is a pandas dataset,
or integer indexes with the attribute position. If None, and xattrs and yattrs are None, all the attributes will be taken.</p>
</dd>
<dt><strong>xattrs</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=None</span></dt>
<dd><p class="first last">A list specifying the dataset attributes to show in X axis. The items can be the keys, if X is a pandas dataset,
or integer indexes with the attribute position. Ignored if attrs is specified.</p>
</dd>
<dt><strong>yattrs</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=None</span></dt>
<dd><p class="first last">A list specifying the dataset attributes to show in Y axis. The items can be the keys, if X is a pandas dataset,
or integer indexes with the attribute position. Ignored if attrs is specified.</p>
</dd>
<dt><strong>sections</strong> <span class="classifier-delimiter">:</span> <span class="classifier">String, default=fitted</span></dt>
<dd><p class="first">It specifies how to take sections in the features space, if there are more than two features in the dataset. It is used to plot the classifier
fixing the non-ploting attributes in this space section. Allowed values are:</p>
<p>‘mean’ : takes the mean of the remaining attributes to plot the classifier region.</p>
<p class="last">‘zeros’ : takes the remaining attributes as zeros to plot the classifier region.</p>
</dd>
<dt><strong>fitted</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=False.</span></dt>
<dd><p class="first last">It indicates if the classifier has already been fitted. If it is false, the function will call the classifier fit method with parameters X,y.</p>
</dd>
<dt><strong>metric</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Matrix, or 2D-Array. Default=None.</span></dt>
<dd><p class="first last">A positive semidefinite matrix of size (d x d), where d is the number of features. Ignored if dml or transformer is specified.</p>
</dd>
<dt><strong>transformer</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Matrix, or 2D-Array. Default=None.</span></dt>
<dd><p class="first last">A matrix of size (d’ x d), where d is the number of features and d’ is the desired dimension. Ignored if dml is specified.</p>
</dd>
<dt><strong>dml</strong> <span class="classifier-delimiter">:</span> <span class="classifier">DML_Algorithm, default=None.</span></dt>
<dd><p class="first last">A distance metric learning algorithm. If metric, transformer and dml are None, no distances are used in the plot.</p>
</dd>
<dt><strong>dml_fitted</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True.</span></dt>
<dd><p class="first last">Specifies if the DML algorithm is already fitted. If True, the algorithm’s fit method will not be called.</p>
</dd>
<dt><strong>transform: Boolean, default=True.</strong></dt>
<dd><p class="first last">If True, projects the data by the learned transformer and plots the transform data. Else, the classifier region will
be ploted with the original data, but the regions will change according to the learned distance.</p>
</dd>
<dt><strong>f</strong> <span class="classifier-delimiter">:</span> <span class="classifier">The :class: <cite>~matplotlib.figure.Figure</cite> object to paint. If None, a new object will be created.</span></dt>
<dd></dd>
<dt><strong>ax</strong> <span class="classifier-delimiter">:</span> <span class="classifier">The :class: <cite>~matplotlib.axes.Axes</cite> object to paint. If None, a new object will be created.</span></dt>
<dd></dd>
<dt><strong>title</strong> <span class="classifier-delimiter">:</span> <span class="classifier">String, default=None. An optional title for the plot.</span></dt>
<dd></dd>
<dt><strong>grid_split</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=[400, 400]</span></dt>
<dd><p class="first last">A list with two items, specifying the number of partitions, in the X and Y axis, to make in the plot to paint
the classifier region. Each split will define a point where the predict method of the classifier is evaluated.
It can be None. In this case, the <cite>grid_step</cite> parameter will be considered.</p>
</dd>
<dt><strong>grid_step</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=[0.1,0.1]</span></dt>
<dd><p class="first last">A list with two items, specifying the distance between the points in the grid that defines the classifier plot.classifier
Each created point in this way will define a point where the predict method of the classifier is evaluated.
It is ignored if the parameter <cite>grid_split</cite> is not None.</p>
</dd>
<dt><strong>label_legend</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True. If True, a legend with the labels and its colors will be ploted.</span></dt>
<dd></dd>
<dt><strong>legend_loc</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, string of a pair of floats, default=”lower right”.</span></dt>
<dd><p class="first">Specifies the legend position. Ignored if legend is not plotted. Allowed values are:
‘best’ (0), ‘upper right’ (1), ‘upper left’ (2), ‘lower left’ (3), ‘lower right’ (4),
‘right’ (5), ‘center left’ (6), ‘center right’ (7), ‘lower center’ (8),
‘upper center’ (9), ‘center’ (10).</p>
<p class="last">Alternatively can be a 2-tuple giving x, y of the lower-left corner of the legend in axes coordinates.</p>
</dd>
<dt><strong>cmap</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Colormap, default=None.</span></dt>
<dd><p class="first last">A <code class="xref py py-class docutils literal"><span class="pre">Colormap</span></code> instance or None. If cmap is None and label_colors is None, a default Colormap is used.</p>
</dd>
<dt><strong>label_colors</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=None.</span></dt>
<dd><p class="first last">A list of size C with matplotlib colors, or strings specitying a color, where C is the number of classes in y. Each class will
be plotted with the corresponding color. If cmap is None and label_colors is None, a default Colormap is used.</p>
</dd>
<dt><strong>plot_points</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True.</span></dt>
<dd><p class="first last">If True, points will be plotted.</p>
</dd>
<dt><strong>plot_regions</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True.</span></dt>
<dd><p class="first last">If True, the classifier regions will be plotted.</p>
</dd>
<dt><strong>region_intensity</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Float, default=0.4.</span></dt>
<dd><p class="first last">A float between 0 and 1, indicating the transparency of the colors in the classifier regions respect the point colors.</p>
</dd>
<dt><strong>legend_plot_points</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True.</span></dt>
<dd><p class="first last">If True, points are plotted in the legend.</p>
</dd>
<dt><strong>legend_plot_regions</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True.</span></dt>
<dd><p class="first last">If True, classifier regions are plotted in the legend.</p>
</dd>
<dt><strong>legend_on_axis</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True.</span></dt>
<dd><p class="first last">If True, the legend is plotted inside the scatter plot. Else, it is plotted out of the scatter plot.</p>
</dd>
<dt><strong>fig_kw</strong> <span class="classifier-delimiter">:</span> <span class="classifier">dict</span></dt>
<dd><p class="first last">Additional keyword args for <code class="xref py py-meth docutils literal"><span class="pre">suplots()</span></code></p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>f</strong> <span class="classifier-delimiter">:</span> <span class="classifier">The plotted :class: <cite>~matplotlib.figure.Figure</cite> object.</span></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="dml.dml_plot.knn_plot">
<code class="descclassname">dml.dml_plot.</code><code class="descname">knn_plot</code><span class="sig-paren">(</span><em>X, y, k=1, attrs=None, sections='mean', knn_clf=None, fitted=False, metric=None, transformer=None, dml=None, dml_fitted=False, transform=True, f=None, ax=None, title=None, subtitle=None, xrange=None, yrange=None, xlabel=None, ylabel=None, grid_split=[400, 400], grid_step=[0.1, 0.1], label_legend=True, legend_loc='lower right', cmap=None, label_colors=None, plot_points=True, plot_regions=True, region_intensity=0.4, legend_plot_points=True, legend_plot_regions=True, legend_on_axis=True, **fig_kw</em><span class="sig-paren">)</span><a class="headerlink" href="#dml.dml_plot.knn_plot" title="Permalink to this definition">¶</a></dt>
<dd><p>A 2D-scatter plot for a labeled dataset to plot regions defined by a k-NN classifier and a distance. The distance can be provided by a metric PSD matrix, a matrix of a linear transformation, or by a distance metric
learning algorithm, that can learn the distance during the plotting, or it can be fitted previously.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like of size (N x d), where N is the number of samples, and d is the number of features.</span></dt>
<dd></dd>
<dt><strong>y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like of size N, where N is the number of samples.</span></dt>
<dd></dd>
<dt><strong>k</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=1.</span></dt>
<dd><p class="first last">The number of neighbors for the k-NN classifier. Ignored if knn_clf is specified.</p>
</dd>
<dt><strong>knn_clf</strong> <span class="classifier-delimiter">:</span> <span class="classifier">A <code class="xref py py-class docutils literal"><span class="pre">ClassifierMixin</span></code>.</span></dt>
<dd><p class="first last">An already defined kNN classifier. It can be any other classifier, but then options are the same as in :meth: <cite>~dml_plot</cite>.</p>
</dd>
<dt><strong>attrs</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=None</span></dt>
<dd><p class="first last">A list of two items specifying the dataset attributes to show in the scatter plot. The items can be the keys, if X is a pandas dataset,
or integer indexes with the attribute position. If None, the two first attributes will be taken.</p>
</dd>
<dt><strong>sections</strong> <span class="classifier-delimiter">:</span> <span class="classifier">String, default=fitted</span></dt>
<dd><p class="first">It specifies how to take sections in the features space, if there are more than two features in the dataset. It is used to plot the classifier
fixing the non-ploting attributes in this space section. Allowed values are:</p>
<p>‘mean’ : takes the mean of the remaining attributes to plot the classifier region.</p>
<p class="last">‘zeros’ : takes the remaining attributes as zeros to plot the classifier region.</p>
</dd>
<dt><strong>fitted</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=False.</span></dt>
<dd><p class="first last">It indicates if the classifier has already been fitted. If it is false, the function will call the classifier fit method with parameters X,y.</p>
</dd>
<dt><strong>metric</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Matrix, or 2D-Array. Default=None.</span></dt>
<dd><p class="first last">A positive semidefinite matrix of size (d x d), where d is the number of features. Ignored if dml or transformer is specified.</p>
</dd>
<dt><strong>transformer</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Matrix, or 2D-Array. Default=None.</span></dt>
<dd><p class="first last">A matrix of size (d’ x d), where d is the number of features and d’ is the desired dimension. Ignored if dml is specified.</p>
</dd>
<dt><strong>dml</strong> <span class="classifier-delimiter">:</span> <span class="classifier">DML_Algorithm, default=None.</span></dt>
<dd><p class="first last">A distance metric learning algorithm. If metric, transformer and dml are None, no distances are used in the plot.</p>
</dd>
<dt><strong>dml_fitted</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True.</span></dt>
<dd><p class="first last">Specifies if the DML algorithm is already fitted. If True, the algorithm’s fit method will not be called.</p>
</dd>
<dt><strong>transform: Boolean, default=True.</strong></dt>
<dd><p class="first last">If True, projects the data by the learned transformer and plots the transform data. Else, the classifier region will
be ploted with the original data, but the regions will change according to the learned distance.</p>
</dd>
<dt><strong>f</strong> <span class="classifier-delimiter">:</span> <span class="classifier">The :class: <cite>~matplotlib.figure.Figure</cite> object to paint. If None, a new object will be created.</span></dt>
<dd></dd>
<dt><strong>ax</strong> <span class="classifier-delimiter">:</span> <span class="classifier">The :class: <cite>~matplotlib.axes.Axes</cite> object to paint. If None, a new object will be created.</span></dt>
<dd></dd>
<dt><strong>title</strong> <span class="classifier-delimiter">:</span> <span class="classifier">String, default=None. An optional title for the plot.</span></dt>
<dd></dd>
<dt><strong>subtitle</strong> <span class="classifier-delimiter">:</span> <span class="classifier">String, default=None. An optional subtitle for the plot.</span></dt>
<dd></dd>
<dt><strong>xrange</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=None</span></dt>
<dd><p class="first last">A list with two items, specifying the minimum and maximum range to plot in the X axis.
If None, it will be calculated according to the maximum and minimum of the X feature.</p>
</dd>
<dt><strong>yrange</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=None</span></dt>
<dd><p class="first last">A list with two items, specifying the minimum and maximum range to plot in the Y axis.
If None, it will be calculated according to the maximum and minimum of the Y feature.</p>
</dd>
<dt><strong>xlabel</strong> <span class="classifier-delimiter">:</span> <span class="classifier">String, default=None. An optional title for the X axis.</span></dt>
<dd></dd>
<dt><strong>ylabel</strong> <span class="classifier-delimiter">:</span> <span class="classifier">String, default=None. An optional title for the Y axis.</span></dt>
<dd></dd>
<dt><strong>grid_split</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=[400, 400]</span></dt>
<dd><p class="first last">A list with two items, specifying the number of partitions, in the X and Y axis, to make in the plot to paint
the classifier region. Each split will define a point where the predict method of the classifier is evaluated.
It can be None. In this case, the <cite>grid_step</cite> parameter will be considered.</p>
</dd>
<dt><strong>grid_step</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=[0.1,0.1]</span></dt>
<dd><p class="first last">A list with two items, specifying the distance between the points in the grid that defines the classifier plot.classifier
Each created point in this way will define a point where the predict method of the classifier is evaluated.
It is ignored if the parameter <cite>grid_split</cite> is not None.</p>
</dd>
<dt><strong>label_legend</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True. If True, a legend with the labels and its colors will be ploted.</span></dt>
<dd></dd>
<dt><strong>legend_loc</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, string of a pair of floats, default=”lower right”.</span></dt>
<dd><p class="first">Specifies the legend position. Ignored if legend is not plotted. Allowed values are:
‘best’ (0), ‘upper right’ (1), ‘upper left’ (2), ‘lower left’ (3), ‘lower right’ (4),
‘right’ (5), ‘center left’ (6), ‘center right’ (7), ‘lower center’ (8),
‘upper center’ (9), ‘center’ (10).</p>
<p class="last">Alternatively can be a 2-tuple giving x, y of the lower-left corner of the legend in axes coordinates.</p>
</dd>
<dt><strong>cmap</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Colormap, default=None.</span></dt>
<dd><p class="first last">A <code class="xref py py-class docutils literal"><span class="pre">Colormap</span></code> instance or None. If cmap is None and label_colors is None, a default Colormap is used.</p>
</dd>
<dt><strong>label_colors</strong> <span class="classifier-delimiter">:</span> <span class="classifier">List, default=None.</span></dt>
<dd><p class="first last">A list of size C with matplotlib colors, or strings specitying a color, where C is the number of classes in y. Each class will
be plotted with the corresponding color. If cmap is None and label_colors is None, a default Colormap is used.</p>
</dd>
<dt><strong>plot_points</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True.</span></dt>
<dd><p class="first last">If True, points will be plotted.</p>
</dd>
<dt><strong>plot_regions</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True.</span></dt>
<dd><p class="first last">If True, the classifier regions will be plotted.</p>
</dd>
<dt><strong>region_intensity</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Float, default=0.4.</span></dt>
<dd><p class="first last">A float between 0 and 1, indicating the transparency of the colors in the classifier regions respect the point colors.</p>
</dd>
<dt><strong>legend_plot_points</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True.</span></dt>
<dd><p class="first last">If True, points are plotted in the legend.</p>
</dd>
<dt><strong>legend_plot_regions</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True.</span></dt>
<dd><p class="first last">If True, classifier regions are plotted in the legend.</p>
</dd>
<dt><strong>legend_on_axis</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=True.</span></dt>
<dd><p class="first last">If True, the legend is plotted inside the scatter plot. Else, it is plotted out of the scatter plot.</p>
</dd>
<dt><strong>fig_kw</strong> <span class="classifier-delimiter">:</span> <span class="classifier">dict</span></dt>
<dd><p class="first last">Additional keyword args for <span class="math">\(~Matplotlib.suplots\)</span></p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>f</strong> <span class="classifier-delimiter">:</span> <span class="classifier">The plotted :class: <cite>~matplotlib.figure.Figure</cite> object.</span></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="module-dml.dml_utils">
<span id="dml-dml-utils-module"></span><h2>dml.dml_utils module<a class="headerlink" href="#module-dml.dml_utils" title="Permalink to this headline">¶</a></h2>
<p>Utility functions for different DML algoritms</p>
<dl class="function">
<dt id="dml.dml_utils.SDProject">
<code class="descclassname">dml.dml_utils.</code><code class="descname">SDProject</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#dml.dml_utils.SDProject" title="Permalink to this definition">¶</a></dt>
<dd><p>Projects a symmetric matrix onto the positive semidefinite cone (considering the Frobenius norm).
The projection is made by taking the non negative eigenvalues after diagonalizing.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>M</strong> <span class="classifier-delimiter">:</span> <span class="classifier">2D-Array or Matrix</span></dt>
<dd><p class="first last">A symmetric matrix.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>Mplus</strong> <span class="classifier-delimiter">:</span> <span class="classifier">2D-Array</span></dt>
<dd><p class="first last">The projection of M onto the positive semidefinite cone.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="dml.dml_utils.calc_outers">
<code class="descclassname">dml.dml_utils.</code><code class="descname">calc_outers</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#dml.dml_utils.calc_outers" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculates the outer products between two datasets. All outer products are calculated, so memory may be not enough.
To avoid memory errors the output of this function should be used in the input of <a class="reference internal" href="#dml.dml_utils.calc_outers_i" title="dml.dml_utils.calc_outers_i"><code class="xref py py-func docutils literal"><span class="pre">calc_outers_i()</span></code></a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Numpy array, shape (N x d)</span></dt>
<dd><p class="first last">A 2D-array, where N is the number of samples and d is the number of features.</p>
</dd>
<dt><strong>Y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Numpy array, shape (M x d), default=None</span></dt>
<dd><p class="first last">A 2D-array, where M is the number of samples in Y and d is the number of features.
If None, Y is taken as X.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>outers</strong> <span class="classifier-delimiter">:</span> <span class="classifier">A 4D-array, of shape (N x M x d x d), where outers[i,j] is the outer product between X[i] and Y[j].</span></dt>
<dd><p class="first last">It can also be None, if memory was not enough. In this case, outers will be calculated in <a class="reference internal" href="#dml.dml_utils.calc_outers_i" title="dml.dml_utils.calc_outers_i"><code class="xref py py-func docutils literal"><span class="pre">calc_outers_i()</span></code></a>.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="dml.dml_utils.calc_outers_i">
<code class="descclassname">dml.dml_utils.</code><code class="descname">calc_outers_i</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#dml.dml_utils.calc_outers_i" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtains a subset of outer products from the calculated in <a class="reference internal" href="#dml.dml_utils.calc_outers" title="dml.dml_utils.calc_outers"><code class="xref py py-func docutils literal"><span class="pre">calc_outers()</span></code></a>.
If memory was enough, this function just returns a row of outer products from the calculated matrix of outer products.
Else, this method calculates this row.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Numpy array, shape (N x d)</span></dt>
<dd><p class="first last">A 2D-array, where N is the number of samples and d is the number of features.</p>
</dd>
<dt><strong>outers</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Numpy array, or None</span></dt>
<dd><p class="first last">The output of the function <a class="reference internal" href="#dml.dml_utils.calc_outers" title="dml.dml_utils.calc_outers"><code class="xref py py-func docutils literal"><span class="pre">calc_outers()</span></code></a>.</p>
</dd>
<dt><strong>i</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">The row to fetch from outers, from 0 to N-1.</p>
</dd>
<dt><strong>Y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Numpy array, shape (M x d), default=None</span></dt>
<dd><p class="first last">A 2D-array, where M is the number of samples in Y and d is the number of features.
If None, Y is taken as X.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>outers_i</strong> <span class="classifier-delimiter">:</span> <span class="classifier">A 3D-Array, of shape (M x d x d), where outers_i[j] is the outer product between X[i] and Y[j].</span></dt>
<dd><p class="first last">It can also be None, if memory was not enough. In this case, outers will be calculated in <a class="reference internal" href="#dml.dml_utils.calc_outers_ij" title="dml.dml_utils.calc_outers_ij"><code class="xref py py-func docutils literal"><span class="pre">calc_outers_ij()</span></code></a>.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="dml.dml_utils.calc_outers_ij">
<code class="descclassname">dml.dml_utils.</code><code class="descname">calc_outers_ij</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#dml.dml_utils.calc_outers_ij" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtains an outer product between two elements in datasets, from the output calculated in <a class="reference internal" href="#dml.dml_utils.calc_outers" title="dml.dml_utils.calc_outers"><code class="xref py py-func docutils literal"><span class="pre">calc_outers()</span></code></a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Numpy array, shape (N x d)</span></dt>
<dd><p class="first last">A 2D-array, where N is the number of samples and d is the number of features.</p>
</dd>
<dt><strong>outers_i</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Numpy array, or None</span></dt>
<dd><p class="first last">The output of the function <a class="reference internal" href="#dml.dml_utils.calc_outers_i" title="dml.dml_utils.calc_outers_i"><code class="xref py py-func docutils literal"><span class="pre">calc_outers_i()</span></code></a>.</p>
</dd>
<dt><strong>i</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">The row to fetch from outers, from 0 to N-1.</p>
</dd>
<dt><strong>j</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">The column to fetch from outers, from 0 to M-1.</p>
</dd>
<dt><strong>Y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Numpy array, shape (M x d), default=None</span></dt>
<dd><p class="first last">A 2D-array, where M is the number of samples in Y and d is the number of features.
If None, Y is taken as X.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>outers_i</strong> <span class="classifier-delimiter">:</span> <span class="classifier">A 2D-Array, of shape (d x d), with the outer product between X[i] and Y[j].</span></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="dml.dml_utils.matpack">
<code class="descclassname">dml.dml_utils.</code><code class="descname">matpack</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#dml.dml_utils.matpack" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a matrix that takes by columns the elements in the vector v.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>v</strong> <span class="classifier-delimiter">:</span> <span class="classifier">1D-Array</span></dt>
<dd><p class="first last">The vector to fit in a matrix.</p>
</dd>
<dt><strong>n</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">The matrix rows.</p>
</dd>
<dt><strong>m</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">The matrix columns.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>A</strong> <span class="classifier-delimiter">:</span> <span class="classifier">2D-Array, shape (n x m)</span></dt>
<dd><p class="first last">The matrix that takes by columns the elements in v.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="dml.dml_utils.metric_sq_distance">
<code class="descclassname">dml.dml_utils.</code><code class="descname">metric_sq_distance</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#dml.dml_utils.metric_sq_distance" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculates a distance between two points given a metric PSD matrix.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>M</strong> <span class="classifier-delimiter">:</span> <span class="classifier">2D-Array or Matrix</span></dt>
<dd><p class="first last">A positive semidefinite matrix defining the distance.</p>
</dd>
<dt><strong>x</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Array.</span></dt>
<dd><p class="first last">First argument for the distance. It must have the same length as y and the order of M.</p>
</dd>
<dt><strong>y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Array.</span></dt>
<dd><p class="first last">Second argument for the distance. It must have the same length as x and the order of M.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="dml.dml_utils.metric_to_linear">
<code class="descclassname">dml.dml_utils.</code><code class="descname">metric_to_linear</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#dml.dml_utils.metric_to_linear" title="Permalink to this definition">¶</a></dt>
<dd><p>Converts a metric PSD matrix into an associated linear transformation matrix, so the distance defined by the
metric matrix is the same as the euclidean distance after projecting by the linear transformation.
This implementation takes the linear transformation corresponding to the square root of the matrix M.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>M</strong> <span class="classifier-delimiter">:</span> <span class="classifier">2D-Array or Matrix</span></dt>
<dd><p class="first last">A positive semidefinite matrix.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>L</strong> <span class="classifier-delimiter">:</span> <span class="classifier">2D-Array</span></dt>
<dd><p class="first last">The matrix associated to the linear transformation that computes the same distance as M.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="dml.dml_utils.pairwise_sq_distances_from_dot">
<code class="descclassname">dml.dml_utils.</code><code class="descname">pairwise_sq_distances_from_dot</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#dml.dml_utils.pairwise_sq_distances_from_dot" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculates the pairwise squared distance between two datasets given the matrix of dot products.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>K</strong> <span class="classifier-delimiter">:</span> <span class="classifier">2D-Array or Matrix</span></dt>
<dd><p class="first last">A matrix with the dot products between two datasets. It verifies
..math:: K[i,j] = langle x_i, y_j rangle</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>dists</strong> <span class="classifier-delimiter">:</span> <span class="classifier">2D-Array</span></dt>
<dd><p class="first last">A matrix with the squared distances between the elements in both datasets. It verifies
..math:: dists[i,j] = d(x_i, y_j) rangle</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="dml.dml_utils.unroll">
<code class="descclassname">dml.dml_utils.</code><code class="descname">unroll</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#dml.dml_utils.unroll" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a column vector from a matrix with all its columns concatenated.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>A</strong> <span class="classifier-delimiter">:</span> <span class="classifier">2D-Array or Matrix.</span></dt>
<dd><p class="first last">The matrix to unroll.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>v</strong> <span class="classifier-delimiter">:</span> <span class="classifier">1D-Array</span></dt>
<dd><p class="first last">The vector with the unrolled matrix.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="module-dml.dmlmj">
<span id="dml-dmlmj-module"></span><h2>dml.dmlmj module<a class="headerlink" href="#module-dml.dmlmj" title="Permalink to this headline">¶</a></h2>
<p>Distance Metric Learning through the Maximization of the Jeffrey divergence (DMLMJ)</p>
<p>Created on Fri Feb 23 12:34:43 2018</p>
<p>&#64;author: jlsuarezdiaz</p>
<dl class="class">
<dt id="dml.dmlmj.DMLMJ">
<em class="property">class </em><code class="descclassname">dml.dmlmj.</code><code class="descname">DMLMJ</code><a class="headerlink" href="#dml.dmlmj.DMLMJ" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dml.dml_algorithm.DML_Algorithm" title="dml.dml_algorithm.DML_Algorithm"><code class="xref py py-class docutils literal"><span class="pre">dml.dml_algorithm.DML_Algorithm</span></code></a></p>
<p>Distance Metric Learning through the Maximization of the Jeffrey divergence (DMLMJ).</p>
<p>A DML Algorithm that obtains a transformer that maximizes the Jeffrey divergence between
the distribution of differences of same-class neighbors and the distribution of differences between
different-class neighbors.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>num_dims</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=None</span></dt>
<dd><p class="first last">Dimension desired for the transformed data.</p>
</dd>
<dt><strong>n_neighbors</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=3</span></dt>
<dd><p class="first last">Number of neighbors to consider in the computation of the difference spaces.</p>
</dd>
<dt><strong>alpha</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=0.001</span></dt>
<dd><p class="first last">Regularization parameter for inverse matrix computation.</p>
</dd>
<dt><strong>reg_tol</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1e-10</span></dt>
<dd><p class="first last">Tolerance threshold for applying regularization. The tolerance is compared with the matrix determinant.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#dml.dmlmj.DMLMJ.fit" title="dml.dmlmj.DMLMJ.fit"><code class="xref py py-obj docutils literal"><span class="pre">fit</span></code></a></td>
<td>Fit the model from the data in X and the labels in y.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">fit_transform</span></code>(X[,&nbsp;y])</td>
<td>Fit to data, then transform it.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">get_params</span></code>([deep])</td>
<td>Get parameters for this estimator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#dml.dmlmj.DMLMJ.metadata" title="dml.dmlmj.DMLMJ.metadata"><code class="xref py py-obj docutils literal"><span class="pre">metadata</span></code></a></td>
<td>Obtains algorithm metadata.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">metric</span></code>()</td>
<td>Computes the Mahalanobis matrix from the transformation matrix.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">set_params</span></code>(**params)</td>
<td>Set the parameters of this estimator.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">transform</span></code>([X])</td>
<td>Applies the metric transformation.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#dml.dmlmj.DMLMJ.transformer" title="dml.dmlmj.DMLMJ.transformer"><code class="xref py py-obj docutils literal"><span class="pre">transformer</span></code></a></td>
<td>Obtains the learned projection.</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="dml.dmlmj.DMLMJ.fit">
<code class="descname">fit</code><a class="headerlink" href="#dml.dmlmj.DMLMJ.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model from the data in X and the labels in y.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N x d)</span></dt>
<dd><p class="first last">Training vector, where N is the number of samples, and d is the number of features.</p>
</dd>
<dt><strong>y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N)</span></dt>
<dd><p class="first last">Labels vector, where N is the number of samples.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>self</strong> <span class="classifier-delimiter">:</span> <span class="classifier">object</span></dt>
<dd><p class="first last">Returns the instance itself.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="dml.dmlmj.DMLMJ.metadata">
<code class="descname">metadata</code><a class="headerlink" href="#dml.dmlmj.DMLMJ.metadata" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtains algorithm metadata.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>meta</strong> <span class="classifier-delimiter">:</span> <span class="classifier">A dictionary with the following metadata:</span></dt>
<dd><p class="first">acum_eig : eigenvalue rate accumulated in the learned output respect to the total dimension.</p>
<p class="last">num_dims : dimension of the reduced data.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="dml.dmlmj.DMLMJ.transformer">
<code class="descname">transformer</code><a class="headerlink" href="#dml.dmlmj.DMLMJ.transformer" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtains the learned projection.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>L</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(d’xd) matrix, where d’ is the desired output dimension and d is the number of features.</span></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="dml.dmlmj.KDMLMJ">
<em class="property">class </em><code class="descclassname">dml.dmlmj.</code><code class="descname">KDMLMJ</code><a class="headerlink" href="#dml.dmlmj.KDMLMJ" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dml.dml_algorithm.KernelDML_Algorithm" title="dml.dml_algorithm.KernelDML_Algorithm"><code class="xref py py-class docutils literal"><span class="pre">dml.dml_algorithm.KernelDML_Algorithm</span></code></a></p>
<p>The kernelized version of DMLMJ.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>num_dims</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=None</span></dt>
<dd><p class="first last">Dimension desired for the transformed data.</p>
</dd>
<dt><strong>n_neighbors</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=3</span></dt>
<dd><p class="first last">Number of neighbors to consider in the computation of the difference spaces.</p>
</dd>
<dt><strong>alpha</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=0.001</span></dt>
<dd><p class="first last">Regularization parameter for inverse matrix computation.</p>
</dd>
<dt><strong>reg_tol</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1e-10</span></dt>
<dd><p class="first last">Tolerance threshold for applying regularization. The tolerance is compared with the matrix determinant.</p>
</dd>
<dt><strong>kernel</strong> <span class="classifier-delimiter">:</span> <span class="classifier">“linear” | “poly” | “rbf” | “sigmoid” | “cosine” | “precomputed”</span></dt>
<dd><p class="first last">Kernel. Default=”linear”.</p>
</dd>
<dt><strong>gamma</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1/n_features</span></dt>
<dd><p class="first last">Kernel coefficient for rbf, poly and sigmoid kernels. Ignored by other
kernels.</p>
</dd>
<dt><strong>degree</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=3</span></dt>
<dd><p class="first last">Degree for poly kernels. Ignored by other kernels.</p>
</dd>
<dt><strong>coef0</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1</span></dt>
<dd><p class="first last">Independent term in poly and sigmoid kernels.
Ignored by other kernels.</p>
</dd>
<dt><strong>kernel_params</strong> <span class="classifier-delimiter">:</span> <span class="classifier">mapping of string to any, default=None</span></dt>
<dd><p class="first last">Parameters (keyword arguments) and values for kernel passed as
callable object. Ignored by other kernels.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#dml.dmlmj.KDMLMJ.fit" title="dml.dmlmj.KDMLMJ.fit"><code class="xref py py-obj docutils literal"><span class="pre">fit</span></code></a></td>
<td>Fit the model from the data in X and the labels in y.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">fit_transform</span></code>(X[,&nbsp;y])</td>
<td>Fit to data, then transform it.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">get_params</span></code>([deep])</td>
<td>Get parameters for this estimator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#dml.dmlmj.KDMLMJ.metadata" title="dml.dmlmj.KDMLMJ.metadata"><code class="xref py py-obj docutils literal"><span class="pre">metadata</span></code></a></td>
<td>Obtains algorithm metadata.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">metric</span></code>()</td>
<td>Computes the Mahalanobis matrix from the transformation matrix.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">set_params</span></code>(**params)</td>
<td>Set the parameters of this estimator.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">transform</span></code>([X])</td>
<td>Applies the kernel transformation.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#dml.dmlmj.KDMLMJ.transformer" title="dml.dmlmj.KDMLMJ.transformer"><code class="xref py py-obj docutils literal"><span class="pre">transformer</span></code></a></td>
<td>Obtains the learned projection.</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="dml.dmlmj.KDMLMJ.fit">
<code class="descname">fit</code><a class="headerlink" href="#dml.dmlmj.KDMLMJ.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model from the data in X and the labels in y.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N x d)</span></dt>
<dd><p class="first last">Training vector, where N is the number of samples, and d is the number of features.</p>
</dd>
<dt><strong>y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N)</span></dt>
<dd><p class="first last">Labels vector, where N is the number of samples.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>self</strong> <span class="classifier-delimiter">:</span> <span class="classifier">object</span></dt>
<dd><p class="first last">Returns the instance itself.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="dml.dmlmj.KDMLMJ.metadata">
<code class="descname">metadata</code><a class="headerlink" href="#dml.dmlmj.KDMLMJ.metadata" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtains algorithm metadata.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>meta</strong> <span class="classifier-delimiter">:</span> <span class="classifier">A dictionary with the following metadata:</span></dt>
<dd><p class="first">acum_eig : eigenvalue rate accumulated in the learned output respect to the total dimension.</p>
<p class="last">num_dims : dimension of the reduced data.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="dml.dmlmj.KDMLMJ.transformer">
<code class="descname">transformer</code><a class="headerlink" href="#dml.dmlmj.KDMLMJ.transformer" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtains the learned projection.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>A</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(d’x N) matrix, where d’ is the desired output dimension, and N is the number of samples.</span></dt>
<dd><p class="first last">To apply A to a new sample x, A must be multiplied by the kernel vector of dimension N
obtained by taking the kernels between x and each training sample.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-dml.itml">
<span id="dml-itml-module"></span><h2>dml.itml module<a class="headerlink" href="#module-dml.itml" title="Permalink to this headline">¶</a></h2>
<p>Information Theoretic Metric Learning (ITML)</p>
<p>Created on Thu Feb  1 17:19:12 2018</p>
<p>&#64;author: jlsuarezdiaz</p>
<dl class="class">
<dt id="dml.itml.ITML">
<em class="property">class </em><code class="descclassname">dml.itml.</code><code class="descname">ITML</code><a class="headerlink" href="#dml.itml.ITML" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dml.dml_algorithm.DML_Algorithm" title="dml.dml_algorithm.DML_Algorithm"><code class="xref py py-class docutils literal"><span class="pre">dml.dml_algorithm.DML_Algorithm</span></code></a></p>
<p>Information Theoretic Metric Learning (ITML).</p>
<p>A DML algorithm that learns a metric associated to the nearest gaussian distribution satisfying similarity constraints.
The nearest gaussian distribution is obtained minimizing the Kullback-Leibler divergence.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>initial_metric</strong> <span class="classifier-delimiter">:</span> <span class="classifier">2D-Array or Matrix</span></dt>
<dd><p class="first last">A positive definite matrix that defines the initial metric used to compare.</p>
</dd>
<dt><strong>upper_bound</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=None</span></dt>
<dd><p class="first last">Bound for dissimilarity constraints. If None, it will be estimated from upper_perc.</p>
</dd>
<dt><strong>lower_bound</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=None</span></dt>
<dd><p class="first last">Bound for similarity constraints. If None, it will be estimated from lower_perc.</p>
</dd>
<dt><strong>num_constraints</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=None</span></dt>
<dd><p class="first last">Number of constraints to generate. If None, it will be taken as 40 * k * (k-1), where k is the number of classes.</p>
</dd>
<dt><strong>gamma</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1.0</span></dt>
<dd><p class="first last">The gamma value for slack variables.</p>
</dd>
<dt><strong>tol</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=0.001</span></dt>
<dd><p class="first last">Tolerance stop criterion for the algorithm.</p>
</dd>
<dt><strong>max_iter</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=100000</span></dt>
<dd><p class="first last">Maximum number of iterations for the algorithm.</p>
</dd>
<dt><strong>low_perc</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=5</span></dt>
<dd><p class="first last">Lower percentile (from 0 to 100) to estimate the lower bound from the dataset. Ignored if lower_bound is provided.</p>
</dd>
<dt><strong>up_perc</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=95</span></dt>
<dd><p class="first last">Upper percentile (from 0 to 100) to estimate the upper bound from the dataset. Ignored if upper_bound is provided.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#dml.itml.ITML.fit" title="dml.itml.ITML.fit"><code class="xref py py-obj docutils literal"><span class="pre">fit</span></code></a></td>
<td>Fit the model from the data in X and the labels in y.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">fit_transform</span></code>(X[,&nbsp;y])</td>
<td>Fit to data, then transform it.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">get_params</span></code>([deep])</td>
<td>Get parameters for this estimator.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">metadata</span></code>()</td>
<td>Obtains the algorithm metadata.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#dml.itml.ITML.metric" title="dml.itml.ITML.metric"><code class="xref py py-obj docutils literal"><span class="pre">metric</span></code></a></td>
<td>Obtains the learned metric.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">set_params</span></code>(**params)</td>
<td>Set the parameters of this estimator.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">transform</span></code>([X])</td>
<td>Applies the metric transformation.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">transformer</span></code>()</td>
<td>Computes a transformation matrix from the Mahalanobis matrix.</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="dml.itml.ITML.fit">
<code class="descname">fit</code><a class="headerlink" href="#dml.itml.ITML.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model from the data in X and the labels in y.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N x d)</span></dt>
<dd><p class="first last">Training vector, where N is the number of samples, and d is the number of features.</p>
</dd>
<dt><strong>y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N)</span></dt>
<dd><p class="first last">Labels vector, where N is the number of samples.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>self</strong> <span class="classifier-delimiter">:</span> <span class="classifier">object</span></dt>
<dd><p class="first last">Returns the instance itself.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="dml.itml.ITML.metric">
<code class="descname">metric</code><a class="headerlink" href="#dml.itml.ITML.metric" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtains the learned metric.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>M</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(dxd) positive semidefinite matrix, where d is the number of features.</span></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-dml.kda">
<span id="dml-kda-module"></span><h2>dml.kda module<a class="headerlink" href="#module-dml.kda" title="Permalink to this headline">¶</a></h2>
<p>Kernel Discriminant Analysis (KDA)</p>
<p>Created on Sun Feb 18 18:38:16 2018</p>
<p>&#64;author: jlsuarezdiaz</p>
<dl class="class">
<dt id="dml.kda.KDA">
<em class="property">class </em><code class="descclassname">dml.kda.</code><code class="descname">KDA</code><a class="headerlink" href="#dml.kda.KDA" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dml.dml_algorithm.KernelDML_Algorithm" title="dml.dml_algorithm.KernelDML_Algorithm"><code class="xref py py-class docutils literal"><span class="pre">dml.dml_algorithm.KernelDML_Algorithm</span></code></a></p>
<p>Kernel Discriminant Analysis (KDA)</p>
<p>Discriminant Analysis in high dimensionality using the kernel trick.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>solver</strong> <span class="classifier-delimiter">:</span> <span class="classifier">string, default=’eigen’.</span></dt>
<dd><dl class="first last docutils">
<dt>Solver to use, posible values:</dt>
<dd><ul class="first last simple">
<li>‘eigen’: Eigenvalue decomposition.</li>
</ul>
</dd>
</dl>
</dd>
<dt><strong>n_components</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=None.</span></dt>
<dd><p class="first last">Number of components (lower than number of classes -1) for dimensionality reduction.</p>
</dd>
<dt><strong>tol</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1e-4</span></dt>
<dd><p class="first last">Singularity toleration level.</p>
</dd>
<dt><strong>kernel</strong> <span class="classifier-delimiter">:</span> <span class="classifier">“linear” | “poly” | “rbf” | “sigmoid” | “cosine” | “precomputed”</span></dt>
<dd><p class="first last">Kernel. Default=”linear”.</p>
</dd>
<dt><strong>gamma</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1/n_features</span></dt>
<dd><p class="first last">Kernel coefficient for rbf, poly and sigmoid kernels. Ignored by other
kernels.</p>
</dd>
<dt><strong>degree</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=3</span></dt>
<dd><p class="first last">Degree for poly kernels. Ignored by other kernels.</p>
</dd>
<dt><strong>coef0</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1</span></dt>
<dd><p class="first last">Independent term in poly and sigmoid kernels.
Ignored by other kernels.</p>
</dd>
<dt><strong>kernel_params</strong> <span class="classifier-delimiter">:</span> <span class="classifier">mapping of string to any, default=None</span></dt>
<dd><p class="first last">Parameters (keyword arguments) and values for kernel passed as
callable object. Ignored by other kernels.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#dml.kda.KDA.fit" title="dml.kda.KDA.fit"><code class="xref py py-obj docutils literal"><span class="pre">fit</span></code></a></td>
<td>Fit the model from the data in X and the labels in y.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">fit_transform</span></code>(X[,&nbsp;y])</td>
<td>Fit to data, then transform it.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">get_params</span></code>([deep])</td>
<td>Get parameters for this estimator.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">metadata</span></code>()</td>
<td>Obtains the algorithm metadata.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">metric</span></code>()</td>
<td>Computes the Mahalanobis matrix from the transformation matrix.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">set_params</span></code>(**params)</td>
<td>Set the parameters of this estimator.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">transform</span></code>([X])</td>
<td>Applies the kernel transformation.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#dml.kda.KDA.transformer" title="dml.kda.KDA.transformer"><code class="xref py py-obj docutils literal"><span class="pre">transformer</span></code></a></td>
<td>Obtains the learned projection.</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="dml.kda.KDA.fit">
<code class="descname">fit</code><a class="headerlink" href="#dml.kda.KDA.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model from the data in X and the labels in y.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N x d)</span></dt>
<dd><p class="first last">Training vector, where N is the number of samples, and d is the number of features.</p>
</dd>
<dt><strong>y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N)</span></dt>
<dd><p class="first last">Labels vector, where N is the number of samples.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>self</strong> <span class="classifier-delimiter">:</span> <span class="classifier">object</span></dt>
<dd><p class="first last">Returns the instance itself.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="dml.kda.KDA.transformer">
<code class="descname">transformer</code><a class="headerlink" href="#dml.kda.KDA.transformer" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtains the learned projection.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>A</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(d’x N) matrix, where d’ is the desired output dimension, and N is the number of samples.</span></dt>
<dd><p class="first last">To apply A to a new sample x, A must be multiplied by the kernel vector of dimension N
obtained by taking the kernels between x and each training sample.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-dml.knn">
<span id="dml-knn-module"></span><h2>dml.knn module<a class="headerlink" href="#module-dml.knn" title="Permalink to this headline">¶</a></h2>
<p>k-Nearest Neighbors (kNN)</p>
<p>An interface for kNN adapted to distance metric learning algorithms.</p>
<dl class="class">
<dt id="dml.knn.kNN">
<em class="property">class </em><code class="descclassname">dml.knn.</code><code class="descname">kNN</code><span class="sig-paren">(</span><em>n_neighbors</em>, <em>dml_algorithm</em><span class="sig-paren">)</span><a class="headerlink" href="#dml.knn.kNN" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">object</span></code></p>
<p>k-Nearest Neighbors (kNN)
The nearest neighbors classifier adapted to be used with distance metric learning algorithms.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>n_neighbors</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">Number of neighbors to consider in classification.</p>
</dd>
<dt><strong>dml_algorithm</strong> <span class="classifier-delimiter">:</span> <span class="classifier">DML_Algorithm</span></dt>
<dd><p class="first last">The distance metric learning algorithm that will provide the distance in kNN.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#dml.knn.kNN.fit" title="dml.knn.kNN.fit"><code class="xref py py-obj docutils literal"><span class="pre">fit</span></code></a>(X,&nbsp;y)</td>
<td>Fit the model from the data in X and the labels in y.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#dml.knn.kNN.loo_pred" title="dml.knn.kNN.loo_pred"><code class="xref py py-obj docutils literal"><span class="pre">loo_pred</span></code></a>(X)</td>
<td>Obtains the predicted for the given data using them as a training and with Leave One Out.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#dml.knn.kNN.loo_prob" title="dml.knn.kNN.loo_prob"><code class="xref py py-obj docutils literal"><span class="pre">loo_prob</span></code></a>(X)</td>
<td>Predicts the probabilities for the given data using them as a training and with Leave One Out.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#dml.knn.kNN.loo_score" title="dml.knn.kNN.loo_score"><code class="xref py py-obj docutils literal"><span class="pre">loo_score</span></code></a>(X)</td>
<td>Obtains the score for the given data using them as a training and with Leave One Out.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#dml.knn.kNN.predict" title="dml.knn.kNN.predict"><code class="xref py py-obj docutils literal"><span class="pre">predict</span></code></a>([X])</td>
<td>Predicts the labels for the given data.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#dml.knn.kNN.predict_orig" title="dml.knn.kNN.predict_orig"><code class="xref py py-obj docutils literal"><span class="pre">predict_orig</span></code></a>([X])</td>
<td>Predicts the labels for the given data with the Euclidean distance (with no dml transformations).</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#dml.knn.kNN.predict_proba" title="dml.knn.kNN.predict_proba"><code class="xref py py-obj docutils literal"><span class="pre">predict_proba</span></code></a>([X])</td>
<td>Predicts the probabilities for the given data.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#dml.knn.kNN.predict_proba_orig" title="dml.knn.kNN.predict_proba_orig"><code class="xref py py-obj docutils literal"><span class="pre">predict_proba_orig</span></code></a>([X])</td>
<td>Predicts the probabilities for the given data with euclidean distance (with no dml transformations).</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#dml.knn.kNN.score" title="dml.knn.kNN.score"><code class="xref py py-obj docutils literal"><span class="pre">score</span></code></a>([X,&nbsp;y])</td>
<td>Obtains the classification score for the given data.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#dml.knn.kNN.score_orig" title="dml.knn.kNN.score_orig"><code class="xref py py-obj docutils literal"><span class="pre">score_orig</span></code></a>([X,&nbsp;y])</td>
<td>Obtains the classification score for the given data with euclidean distance (with no dml transformation).</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="dml.knn.kNN.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em><span class="sig-paren">)</span><a class="headerlink" href="#dml.knn.kNN.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model from the data in X and the labels in y.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N x d)</span></dt>
<dd><p class="first last">Training vector, where N is the number of samples, and d is the number of features.</p>
</dd>
<dt><strong>y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N)</span></dt>
<dd><p class="first last">Labels vector, where N is the number of samples.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>self</strong> <span class="classifier-delimiter">:</span> <span class="classifier">object</span></dt>
<dd><p class="first last">Returns the instance itself.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="dml.knn.kNN.loo_pred">
<code class="descname">loo_pred</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#dml.knn.kNN.loo_pred" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtains the predicted for the given data using them as a training and with Leave One Out.</p>
<p>X : 2D-Array or Matrix, default=None</p>
<blockquote>
<div>The dataset to be used.</div></blockquote>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">1D-Array</span></dt>
<dd><p class="first last">The vector with the label predictions.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="dml.knn.kNN.loo_prob">
<code class="descname">loo_prob</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#dml.knn.kNN.loo_prob" title="Permalink to this definition">¶</a></dt>
<dd><p>Predicts the probabilities for the given data using them as a training and with Leave One Out.</p>
<p>X : 2D-Array or Matrix, default=None</p>
<blockquote>
<div>The dataset to be used.</div></blockquote>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>T</strong> <span class="classifier-delimiter">:</span> <span class="classifier">2D-Array, shape (N x c)</span></dt>
<dd><p class="first last">A matrix with the probabilities for each class. N is the number of samples and c is the number of classes.
The element i, j shows the probability of sample X[i] to be in class j.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="dml.knn.kNN.loo_score">
<code class="descname">loo_score</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#dml.knn.kNN.loo_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtains the score for the given data using them as a training and with Leave One Out.</p>
<p>X : 2D-Array or Matrix, default=None</p>
<blockquote>
<div>The dataset to be used.</div></blockquote>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>score</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">The classification score at kNN. It is calculated as
..math:: card(y_pred == y_real) / n_samples</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="dml.knn.kNN.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X=None</em><span class="sig-paren">)</span><a class="headerlink" href="#dml.knn.kNN.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predicts the labels for the given data. Model needs to be already fitted.</p>
<p>X : 2D-Array or Matrix, default=None</p>
<blockquote>
<div>The dataset to be used. If None, the training set will be used. In this case, the prediction will be made
using Leave One Out (that is, the sample to predict will be taken away from the training set).</div></blockquote>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">1D-Array</span></dt>
<dd><p class="first last">The vector with the label predictions.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="dml.knn.kNN.predict_orig">
<code class="descname">predict_orig</code><span class="sig-paren">(</span><em>X=None</em><span class="sig-paren">)</span><a class="headerlink" href="#dml.knn.kNN.predict_orig" title="Permalink to this definition">¶</a></dt>
<dd><p>Predicts the labels for the given data with the Euclidean distance (with no dml transformations). Model needs to be already fitted.</p>
<p>X : 2D-Array or Matrix, default=None</p>
<blockquote>
<div>The dataset to be used. If None, the training set will be used. In this case, the prediction will be made
using Leave One Out (that is, the sample to predict will be taken away from the training set).</div></blockquote>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">1D-Array</span></dt>
<dd><p class="first last">The vector with the label predictions.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="dml.knn.kNN.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>X=None</em><span class="sig-paren">)</span><a class="headerlink" href="#dml.knn.kNN.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Predicts the probabilities for the given data. Model needs to be already fitted.</p>
<p>X : 2D-Array or Matrix, default=None</p>
<blockquote>
<div>The dataset to be used. If None, the training set will be used. In this case, the prediction will be made
using Leave One Out (that is, the sample to predict will be taken away from the training set).</div></blockquote>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>T</strong> <span class="classifier-delimiter">:</span> <span class="classifier">2D-Array, shape (N x c)</span></dt>
<dd><p class="first last">A matrix with the probabilities for each class. N is the number of samples and c is the number of classes.
The element i, j shows the probability of sample X[i] to be in class j.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="dml.knn.kNN.predict_proba_orig">
<code class="descname">predict_proba_orig</code><span class="sig-paren">(</span><em>X=None</em><span class="sig-paren">)</span><a class="headerlink" href="#dml.knn.kNN.predict_proba_orig" title="Permalink to this definition">¶</a></dt>
<dd><p>Predicts the probabilities for the given data with euclidean distance (with no dml transformations). Model needs to be already fitted.</p>
<p>X : 2D-Array or Matrix, default=None</p>
<blockquote>
<div>The dataset to be used. If None, the training set will be used. In this case, the prediction will be made
using Leave One Out (that is, the sample to predict will be taken away from the training set).</div></blockquote>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>T</strong> <span class="classifier-delimiter">:</span> <span class="classifier">2D-Array, shape (N x c)</span></dt>
<dd><p class="first last">A matrix with the probabilities for each class. N is the number of samples and c is the number of classes.
The element i, j shows the probability of sample X[i] to be in class j.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="dml.knn.kNN.score">
<code class="descname">score</code><span class="sig-paren">(</span><em>X=None</em>, <em>y=None</em><span class="sig-paren">)</span><a class="headerlink" href="#dml.knn.kNN.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtains the classification score for the given data. Model needs to be already fitted.</p>
<p>X : 2D-Array or Matrix, default=None</p>
<blockquote>
<div>The dataset to be used. If None, the training set will be used. In this case, the prediction will be made
using Leave One Out (that is, the sample to predict will be taken away from the training set).</div></blockquote>
<p>y : 1D-Array, default=None</p>
<blockquote>
<div>The real labels for the dataset. It can be None only if X is None.</div></blockquote>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>score</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">The classification score at kNN. It is calculated as
..math:: card(y_pred == y_real) / n_samples</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="dml.knn.kNN.score_orig">
<code class="descname">score_orig</code><span class="sig-paren">(</span><em>X=None</em>, <em>y=None</em><span class="sig-paren">)</span><a class="headerlink" href="#dml.knn.kNN.score_orig" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtains the classification score for the given data with euclidean distance (with no dml transformation). Model needs to be already fitted.</p>
<p>X : 2D-Array or Matrix, default=None</p>
<blockquote>
<div>The dataset to be used. If None, the training set will be used. In this case, the prediction will be made
using Leave One Out (that is, the sample to predict will be taken away from the training set).</div></blockquote>
<p>y : 1D-Array, default=None</p>
<blockquote>
<div>The true labels for the dataset. It can be None only if X is None.</div></blockquote>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>score</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">The classification score at kNN. It is calculated as
..math:: card(y_pred == y_real) / n_samples</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-dml.lda">
<span id="dml-lda-module"></span><h2>dml.lda module<a class="headerlink" href="#module-dml.lda" title="Permalink to this headline">¶</a></h2>
<p>Linear Discriminant Analysis (LDA)</p>
<dl class="class">
<dt id="dml.lda.LDA">
<em class="property">class </em><code class="descclassname">dml.lda.</code><code class="descname">LDA</code><a class="headerlink" href="#dml.lda.LDA" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dml.dml_algorithm.DML_Algorithm" title="dml.dml_algorithm.DML_Algorithm"><code class="xref py py-class docutils literal"><span class="pre">dml.dml_algorithm.DML_Algorithm</span></code></a></p>
<p>Linear Discriminant Analysis (LDA).</p>
<p>A distance metric learning algorithm for supervised dimensionality reduction, maximizing the ratio of variances between classes and within classes.
This class is a wrapper for <code class="xref py py-class docutils literal"><span class="pre">LinearDiscriminantAnalysis</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>num_dims</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=None</span></dt>
<dd><p class="first last">Number of components (&lt; n_classes - 1) for dimensionality reduction. If None, it will be taken as n_classes - 1. Ignored if thres is provided.</p>
</dd>
<dt><strong>thres</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Fraction of variability to keep, from 0 to 1. Data dimension will be reduced until the lowest dimension that keeps ‘thres’ explained variance.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#dml.lda.LDA.fit" title="dml.lda.LDA.fit"><code class="xref py py-obj docutils literal"><span class="pre">fit</span></code></a></td>
<td>Fit the model from the data in X and the labels in y.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">fit_transform</span></code>(X[,&nbsp;y])</td>
<td>Fit to data, then transform it.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">get_params</span></code>([deep])</td>
<td>Get parameters for this estimator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#dml.lda.LDA.metadata" title="dml.lda.LDA.metadata"><code class="xref py py-obj docutils literal"><span class="pre">metadata</span></code></a></td>
<td>Obtains algorithm metadata.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">metric</span></code>()</td>
<td>Computes the Mahalanobis matrix from the transformation matrix.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">set_params</span></code>(**params)</td>
<td>Set the parameters of this estimator.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#dml.lda.LDA.transformer" title="dml.lda.LDA.transformer"><code class="xref py py-obj docutils literal"><span class="pre">transformer</span></code></a></td>
<td>Obtains the learned projection.</td>
</tr>
</tbody>
</table>
<table border="1" class="docutils">
<colgroup>
<col width="57%" />
<col width="43%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><strong>transform</strong></td>
<td>&#160;</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="dml.lda.LDA.fit">
<code class="descname">fit</code><a class="headerlink" href="#dml.lda.LDA.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model from the data in X and the labels in y.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N x d)</span></dt>
<dd><p class="first last">Training vector, where N is the number of samples, and d is the number of features.</p>
</dd>
<dt><strong>y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N)</span></dt>
<dd><p class="first last">Labels vector, where N is the number of samples.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>self</strong> <span class="classifier-delimiter">:</span> <span class="classifier">object</span></dt>
<dd><p class="first last">Returns the instance itself.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="dml.lda.LDA.metadata">
<code class="descname">metadata</code><a class="headerlink" href="#dml.lda.LDA.metadata" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtains algorithm metadata.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>meta</strong> <span class="classifier-delimiter">:</span> <span class="classifier">A dictionary with the following metadata:</span></dt>
<dd><p class="first">acum_eig : eigenvalue rate accumulated in the learned output respect to the total dimension.</p>
<p class="last">num_dims : dimension of the reduced data.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="dml.lda.LDA.transform">
<code class="descname">transform</code><a class="headerlink" href="#dml.lda.LDA.transform" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="dml.lda.LDA.transformer">
<code class="descname">transformer</code><a class="headerlink" href="#dml.lda.LDA.transformer" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtains the learned projection.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>L</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(d’xd) matrix, where d’ is the desired output dimension and d is the number of features.</span></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-dml.ldml">
<span id="dml-ldml-module"></span><h2>dml.ldml module<a class="headerlink" href="#module-dml.ldml" title="Permalink to this headline">¶</a></h2>
<p>Logistic Discriminant Metric Learning (LDML)</p>
<p>Created on Mon Mar 12 18:26:53 2018</p>
<p>&#64;author: jlsuarezdiaz</p>
<dl class="class">
<dt id="dml.ldml.LDML">
<em class="property">class </em><code class="descclassname">dml.ldml.</code><code class="descname">LDML</code><a class="headerlink" href="#dml.ldml.LDML" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dml.dml_algorithm.DML_Algorithm" title="dml.dml_algorithm.DML_Algorithm"><code class="xref py py-class docutils literal"><span class="pre">dml.dml_algorithm.DML_Algorithm</span></code></a></p>
<p>Logistic Discriminant Metric Learning (LDML).</p>
<p>Distance Metric Learning through the likelihood maximization of a logistic based probability distribution.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>num_dims</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=None.</span></dt>
<dd><p class="first last">Number of dimensions for dimensionality reduction. Not supported yet.</p>
</dd>
<dt><strong>b</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1e-3</span></dt>
<dd><p class="first last">Logistic function positive threshold.</p>
</dd>
<dt><strong>learning_rate</strong> <span class="classifier-delimiter">:</span> <span class="classifier">string, default=’adaptive’</span></dt>
<dd><p class="first">Type of learning rate update for gradient descent. Possible values are:</p>
<ul class="last simple">
<li>‘adaptive’ : the learning rate will increase if the gradient step is succesful, else it will decrease.</li>
<li>‘constant’ : the learning rate will be constant during all the gradient steps.</li>
</ul>
</dd>
<dt><strong>eta0</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=0.3</span></dt>
<dd><p class="first last">The initial value for learning rate.</p>
</dd>
<dt><strong>initial_metric</strong> <span class="classifier-delimiter">:</span> <span class="classifier">2D-Array or Matrix (d x d), or string, default=None.</span></dt>
<dd><p class="first">If array or matrix, it must be a positive semidefinite matrix with the starting metric for gradient descent, where d is the number of features.
If None, euclidean distance will be used. If a string, the following values are allowed:</p>
<ul class="last simple">
<li>‘euclidean’ : the euclidean distance.</li>
<li>‘scale’ : a diagonal matrix that normalizes each attribute according to its range will be used.</li>
</ul>
</dd>
<dt><strong>max_iter</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=10</span></dt>
<dd><p class="first last">Maximum number of iterations of gradient descent.</p>
</dd>
<dt><strong>prec</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1e-3</span></dt>
<dd><p class="first last">Precision stop criterion (gradient norm).</p>
</dd>
<dt><strong>tol</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1e-3</span></dt>
<dd><p class="first last">Tolerance stop criterion (difference between two iterations)</p>
</dd>
<dt><strong>descent_method</strong> <span class="classifier-delimiter">:</span> <span class="classifier">string, default=’SDP’</span></dt>
<dd><p class="first">The descent method to use. Allowed values are:</p>
<ul class="last simple">
<li>‘SDP’ : semidefinite programming, consisting of gradient descent with projections onto the PSD cone.</li>
</ul>
</dd>
<dt><strong>eta_thres</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1e-14</span></dt>
<dd><p class="first last">A learning rate threshold stop criterion.</p>
</dd>
<dt><strong>learn_inc</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1.01</span></dt>
<dd><p class="first last">Increase factor for learning rate. Ignored if learning_rate is not ‘adaptive’.</p>
</dd>
<dt><strong>learn_dec</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=0.5</span></dt>
<dd><p class="first last">Decrease factor for learning rate. Ignored if learning_rate is not ‘adaptive’.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#dml.ldml.LDML.fit" title="dml.ldml.LDML.fit"><code class="xref py py-obj docutils literal"><span class="pre">fit</span></code></a></td>
<td>Fit the model from the data in X and the labels in y.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">fit_transform</span></code>(X[,&nbsp;y])</td>
<td>Fit to data, then transform it.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">get_params</span></code>([deep])</td>
<td>Get parameters for this estimator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#dml.ldml.LDML.metadata" title="dml.ldml.LDML.metadata"><code class="xref py py-obj docutils literal"><span class="pre">metadata</span></code></a></td>
<td>Obtains algorithm metadata.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#dml.ldml.LDML.metric" title="dml.ldml.LDML.metric"><code class="xref py py-obj docutils literal"><span class="pre">metric</span></code></a></td>
<td>Obtains the learned metric.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">set_params</span></code>(**params)</td>
<td>Set the parameters of this estimator.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">transform</span></code>([X])</td>
<td>Applies the metric transformation.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">transformer</span></code>()</td>
<td>Computes a transformation matrix from the Mahalanobis matrix.</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="dml.ldml.LDML.fit">
<code class="descname">fit</code><a class="headerlink" href="#dml.ldml.LDML.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model from the data in X and the labels in y.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N x d)</span></dt>
<dd><p class="first last">Training vector, where N is the number of samples, and d is the number of features.</p>
</dd>
<dt><strong>y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N)</span></dt>
<dd><p class="first last">Labels vector, where N is the number of samples.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>self</strong> <span class="classifier-delimiter">:</span> <span class="classifier">object</span></dt>
<dd><p class="first last">Returns the instance itself.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="dml.ldml.LDML.metadata">
<code class="descname">metadata</code><a class="headerlink" href="#dml.ldml.LDML.metadata" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtains algorithm metadata.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>meta</strong> <span class="classifier-delimiter">:</span> <span class="classifier">A dictionary with the following metadata:</span></dt>
<dd><ul class="first last simple">
<li>‘num_iters’ : Number of iterations that the descent method took.</li>
<li>‘initial_error’ : Initial value of the objective function.</li>
<li>‘final_error’ : Final value of the objective function.</li>
</ul>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="dml.ldml.LDML.metric">
<code class="descname">metric</code><a class="headerlink" href="#dml.ldml.LDML.metric" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtains the learned metric.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>M</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(dxd) positive semidefinite matrix, where d is the number of features.</span></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-dml.lmnn">
<span id="dml-lmnn-module"></span><h2>dml.lmnn module<a class="headerlink" href="#module-dml.lmnn" title="Permalink to this headline">¶</a></h2>
<p>Large Margin Nearest Neighbors (LMNN)</p>
<dl class="class">
<dt id="dml.lmnn.KLMNN">
<em class="property">class </em><code class="descclassname">dml.lmnn.</code><code class="descname">KLMNN</code><a class="headerlink" href="#dml.lmnn.KLMNN" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dml.dml_algorithm.KernelDML_Algorithm" title="dml.dml_algorithm.KernelDML_Algorithm"><code class="xref py py-class docutils literal"><span class="pre">dml.dml_algorithm.KernelDML_Algorithm</span></code></a></p>
<p>The kernelized version of LMNN.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>num_dims</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=None</span></dt>
<dd><p class="first last">Desired value for dimensionality reduction. Ignored if solver is ‘SDP’.</p>
</dd>
<dt><strong>learning_rate</strong> <span class="classifier-delimiter">:</span> <span class="classifier">string, default=’adaptive’</span></dt>
<dd><p class="first">Type of learning rate update for gradient descent. Possible values are:</p>
<ul class="last simple">
<li>‘adaptive’ : the learning rate will increase if the gradient step is succesful, else it will decrease.</li>
<li>‘constant’ : the learning rate will be constant during all the gradient steps.</li>
</ul>
</dd>
<dt><strong>eta0</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=0.3</span></dt>
<dd><p class="first last">The initial value for learning rate.</p>
</dd>
<dt><strong>initial_metric</strong> <span class="classifier-delimiter">:</span> <span class="classifier">2D-Array or Matrix (d’ x d), or string, default=None.</span></dt>
<dd><p class="first">If array or matrix, and solver is SDP, it must be a positive semidefinite matrix with the starting metric (d x d) for gradient descent, where d is the number of features.
If None, euclidean distance will be used. If a string, the following values are allowed:</p>
<ul class="simple">
<li>‘euclidean’ : the euclidean distance.</li>
<li>‘scale’ : a diagonal matrix that normalizes each attribute according to its range will be used.</li>
</ul>
<p class="last">If solver is SGD, then the array or matrix will represent a linear map (d’ x d), where d’ is the dimension provided in num_dims.</p>
</dd>
<dt><strong>max_iter</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=100</span></dt>
<dd><p class="first last">Maximum number of iterations of gradient descent.</p>
</dd>
<dt><strong>prec</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1e-8</span></dt>
<dd><p class="first last">Precision stop criterion (gradient norm).</p>
</dd>
<dt><strong>tol</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1e-8</span></dt>
<dd><p class="first last">Tolerance stop criterion (difference between two iterations)</p>
</dd>
<dt><strong>k</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=3</span></dt>
<dd><p class="first last">Number of target neighbors to take. If this algorithm is used for nearest neighbors classification, a good choice is
to take k as the number of neighbors.</p>
</dd>
<dt><strong>mu</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=0.5</span></dt>
<dd><p class="first last">The weight of the push error in the minimization algorithm. The objective function is composed of a push error, given by the impostors,
with weight mu, and a pull error, given by the target neighbors, with weight (1-mu). It must be between 0.0 and 1.0.</p>
</dd>
<dt><strong>learn_inc</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1.01</span></dt>
<dd><p class="first last">Increase factor for learning rate. Ignored if learning_rate is not ‘adaptive’.</p>
</dd>
<dt><strong>learn_dec</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=0.5</span></dt>
<dd><p class="first last">Decrease factor for learning rate. Ignored if learning_rate is not ‘adaptive’.</p>
</dd>
<dt><strong>eta_thres</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1e-14</span></dt>
<dd><p class="first last">A learning rate threshold stop criterion.</p>
</dd>
<dt><strong>kernel</strong> <span class="classifier-delimiter">:</span> <span class="classifier">“linear” | “poly” | “rbf” | “sigmoid” | “cosine” | “precomputed”</span></dt>
<dd><p class="first last">Kernel. Default=”linear”.</p>
</dd>
<dt><strong>gamma</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1/n_features</span></dt>
<dd><p class="first last">Kernel coefficient for rbf, poly and sigmoid kernels. Ignored by other
kernels.</p>
</dd>
<dt><strong>degree</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=3</span></dt>
<dd><p class="first last">Degree for poly kernels. Ignored by other kernels.</p>
</dd>
<dt><strong>coef0</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1</span></dt>
<dd><p class="first last">Independent term in poly and sigmoid kernels.
Ignored by other kernels.</p>
</dd>
<dt><strong>kernel_params</strong> <span class="classifier-delimiter">:</span> <span class="classifier">mapping of string to any, default=None</span></dt>
<dd><p class="first last">Parameters (keyword arguments) and values for kernel passed as
callable object. Ignored by other kernels.</p>
</dd>
<dt><strong>target_selecion</strong> <span class="classifier-delimiter">:</span> <span class="classifier">string, default=’kernel’</span></dt>
<dd><p class="first">How to find the target neighbors. Allowed values are:</p>
<ul class="last simple">
<li>‘kernel’ : using the euclidean distance in the kernel space.</li>
<li>‘original’ : using the euclidean distance in the original space.</li>
</ul>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#dml.lmnn.KLMNN.fit" title="dml.lmnn.KLMNN.fit"><code class="xref py py-obj docutils literal"><span class="pre">fit</span></code></a></td>
<td>Fit the model from the data in X and the labels in y.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">fit_transform</span></code>(X[,&nbsp;y])</td>
<td>Fit to data, then transform it.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">get_params</span></code>([deep])</td>
<td>Get parameters for this estimator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#dml.lmnn.KLMNN.metadata" title="dml.lmnn.KLMNN.metadata"><code class="xref py py-obj docutils literal"><span class="pre">metadata</span></code></a></td>
<td>Obtains algorithm metadata.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">metric</span></code>()</td>
<td>Computes the Mahalanobis matrix from the transformation matrix.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">set_params</span></code>(**params)</td>
<td>Set the parameters of this estimator.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">transform</span></code>([X])</td>
<td>Applies the kernel transformation.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#dml.lmnn.KLMNN.transformer" title="dml.lmnn.KLMNN.transformer"><code class="xref py py-obj docutils literal"><span class="pre">transformer</span></code></a></td>
<td>Obtains the learned projection.</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="dml.lmnn.KLMNN.fit">
<code class="descname">fit</code><a class="headerlink" href="#dml.lmnn.KLMNN.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model from the data in X and the labels in y.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N x d)</span></dt>
<dd><p class="first last">Training vector, where N is the number of samples, and d is the number of features.</p>
</dd>
<dt><strong>y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N)</span></dt>
<dd><p class="first last">Labels vector, where N is the number of samples.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>self</strong> <span class="classifier-delimiter">:</span> <span class="classifier">object</span></dt>
<dd><p class="first last">Returns the instance itself.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="dml.lmnn.KLMNN.metadata">
<code class="descname">metadata</code><a class="headerlink" href="#dml.lmnn.KLMNN.metadata" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtains algorithm metadata.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>meta</strong> <span class="classifier-delimiter">:</span> <span class="classifier">A dictionary with the following metadata:</span></dt>
<dd><ul class="first last simple">
<li>‘num_iters’ : Number of iterations that the descent method took.</li>
<li>‘initial_error’ : Initial value of the objective function.</li>
<li>‘final_error’ : Final value of the objective function.</li>
</ul>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="dml.lmnn.KLMNN.transformer">
<code class="descname">transformer</code><a class="headerlink" href="#dml.lmnn.KLMNN.transformer" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtains the learned projection.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>A</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(d’x N) matrix, where d’ is the desired output dimension, and N is the number of samples.</span></dt>
<dd><p class="first last">To apply A to a new sample x, A must be multiplied by the kernel vector of dimension N
obtained by taking the kernels between x and each training sample.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="dml.lmnn.LMNN">
<em class="property">class </em><code class="descclassname">dml.lmnn.</code><code class="descname">LMNN</code><a class="headerlink" href="#dml.lmnn.LMNN" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dml.dml_algorithm.DML_Algorithm" title="dml.dml_algorithm.DML_Algorithm"><code class="xref py py-class docutils literal"><span class="pre">dml.dml_algorithm.DML_Algorithm</span></code></a>, <code class="xref py py-class docutils literal"><span class="pre">sklearn.base.ClassifierMixin</span></code></p>
<p>Large Margin Nearest Neighbors (LMNN)</p>
<p>A distance metric learning algorithm that obtains a metric with target neighbors as near as possible and impostors as far as possible</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>num_dims</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=None</span></dt>
<dd><p class="first last">Desired value for dimensionality reduction. Ignored if solver is ‘SDP’.</p>
</dd>
<dt><strong>learning_rate</strong> <span class="classifier-delimiter">:</span> <span class="classifier">string, default=’adaptive’</span></dt>
<dd><p class="first">Type of learning rate update for gradient descent. Possible values are:</p>
<ul class="last simple">
<li>‘adaptive’ : the learning rate will increase if the gradient step is succesful, else it will decrease.</li>
<li>‘constant’ : the learning rate will be constant during all the gradient steps.</li>
</ul>
</dd>
<dt><strong>eta0</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=0.3</span></dt>
<dd><p class="first last">The initial value for learning rate.</p>
</dd>
<dt><strong>initial_metric</strong> <span class="classifier-delimiter">:</span> <span class="classifier">2D-Array or Matrix (d’ x d), or string, default=None.</span></dt>
<dd><p class="first">If array or matrix, and solver is SDP, it must be a positive semidefinite matrix with the starting metric (d x d) for gradient descent, where d is the number of features.
If None, euclidean distance will be used. If a string, the following values are allowed:</p>
<ul class="simple">
<li>‘euclidean’ : the euclidean distance.</li>
<li>‘scale’ : a diagonal matrix that normalizes each attribute according to its range will be used.</li>
</ul>
<p class="last">If solver is SGD, then the array or matrix will represent a linear map (d’ x d), where d’ is the dimension provided in num_dims.</p>
</dd>
<dt><strong>max_iter</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=100</span></dt>
<dd><p class="first last">Maximum number of iterations of gradient descent.</p>
</dd>
<dt><strong>prec</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1e-8</span></dt>
<dd><p class="first last">Precision stop criterion (gradient norm).</p>
</dd>
<dt><strong>tol</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1e-8</span></dt>
<dd><p class="first last">Tolerance stop criterion (difference between two iterations)</p>
</dd>
<dt><strong>k</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=3</span></dt>
<dd><p class="first last">Number of target neighbors to take. If this algorithm is used for nearest neighbors classification, a good choice is
to take k as the number of neighbors.</p>
</dd>
<dt><strong>mu</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=0.5</span></dt>
<dd><p class="first last">The weight of the push error in the minimization algorithm. The objective function is composed of a push error, given by the impostors,
with weight mu, and a pull error, given by the target neighbors, with weight (1-mu). It must be between 0.0 and 1.0.</p>
</dd>
<dt><strong>soft_comp_interval</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=1</span></dt>
<dd><p class="first last">Intervals of soft computation. The soft computation relaxes the gradient descent conditions, but makes the algorithm more efficient.
This value provides the length of a soft computation interval. After soft_comp_interval iterations of gradient descent, a complete
gradient step is performed.</p>
</dd>
<dt><strong>learn_inc</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1.01</span></dt>
<dd><p class="first last">Increase factor for learning rate. Ignored if learning_rate is not ‘adaptive’.</p>
</dd>
<dt><strong>learn_dec</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=0.5</span></dt>
<dd><p class="first last">Decrease factor for learning rate. Ignored if learning_rate is not ‘adaptive’.</p>
</dd>
<dt><strong>eta_thres</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1e-14</span></dt>
<dd><p class="first last">A learning rate threshold stop criterion.</p>
</dd>
<dt><strong>solver</strong> <span class="classifier-delimiter">:</span> <span class="classifier">string, default=’SDP’</span></dt>
<dd><p class="first">The algorithm used for minimization. Allowed values are:</p>
<ul class="last simple">
<li><dl class="first docutils">
<dt>‘SDP’ <span class="classifier-delimiter">:</span> <span class="classifier">semidefinite programming, consisting of gradient descent with projections onto the positive semidefinite cone.</span></dt>
<dd>It learns a metric.</dd>
</dl>
</li>
<li>‘SGD’ : stochastic gradient descent. It learns a linear transformer.</li>
</ul>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#dml.lmnn.LMNN.fit" title="dml.lmnn.LMNN.fit"><code class="xref py py-obj docutils literal"><span class="pre">fit</span></code></a></td>
<td>Fit the model from the data in X and the labels in y.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">fit_transform</span></code>(X[,&nbsp;y])</td>
<td>Fit to data, then transform it.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">get_params</span></code>([deep])</td>
<td>Get parameters for this estimator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#dml.lmnn.LMNN.metadata" title="dml.lmnn.LMNN.metadata"><code class="xref py py-obj docutils literal"><span class="pre">metadata</span></code></a></td>
<td>Obtains algorithm metadata.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">metric</span></code>()</td>
<td>Computes the Mahalanobis matrix from the transformation matrix.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#dml.lmnn.LMNN.predict" title="dml.lmnn.LMNN.predict"><code class="xref py py-obj docutils literal"><span class="pre">predict</span></code></a></td>
<td>Predict the class labels for the provided data, according to the LMNN energy method.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">score</span></code>(X,&nbsp;y[,&nbsp;sample_weight])</td>
<td>Returns the mean accuracy on the given test data and labels.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">set_params</span></code>(**params)</td>
<td>Set the parameters of this estimator.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">transform</span></code>([X])</td>
<td>Applies the metric transformation.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">transformer</span></code>()</td>
<td>Computes a transformation matrix from the Mahalanobis matrix.</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="dml.lmnn.LMNN.fit">
<code class="descname">fit</code><a class="headerlink" href="#dml.lmnn.LMNN.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model from the data in X and the labels in y.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N x d)</span></dt>
<dd><p class="first last">Training vector, where N is the number of samples, and d is the number of features.</p>
</dd>
<dt><strong>y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N)</span></dt>
<dd><p class="first last">Labels vector, where N is the number of samples.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>self</strong> <span class="classifier-delimiter">:</span> <span class="classifier">object</span></dt>
<dd><p class="first last">Returns the instance itself.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="dml.lmnn.LMNN.metadata">
<code class="descname">metadata</code><a class="headerlink" href="#dml.lmnn.LMNN.metadata" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtains algorithm metadata.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>meta</strong> <span class="classifier-delimiter">:</span> <span class="classifier">A dictionary with the following metadata:</span></dt>
<dd><ul class="first last simple">
<li>num_iters : Number of iterations that the descent method took.</li>
<li>initial_error : Initial value of the objective function.</li>
<li>final_error : Final value of the objective function.</li>
</ul>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="dml.lmnn.LMNN.predict">
<code class="descname">predict</code><a class="headerlink" href="#dml.lmnn.LMNN.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the class labels for the provided data, according to the LMNN energy method.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N x d)</span></dt>
<dd><p class="first last">Test samples. N is the number of samples and d the number of features. If None, training set will be used.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array of shape (N)</span></dt>
<dd><p class="first last">Class labels for each data sample.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-dml.lsi">
<span id="dml-lsi-module"></span><h2>dml.lsi module<a class="headerlink" href="#module-dml.lsi" title="Permalink to this headline">¶</a></h2>
<p>Learning with Side Information (LSI)</p>
<dl class="class">
<dt id="dml.lsi.LSI">
<em class="property">class </em><code class="descclassname">dml.lsi.</code><code class="descname">LSI</code><a class="headerlink" href="#dml.lsi.LSI" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dml.dml_algorithm.DML_Algorithm" title="dml.dml_algorithm.DML_Algorithm"><code class="xref py py-class docutils literal"><span class="pre">dml.dml_algorithm.DML_Algorithm</span></code></a></p>
<p>Learning with Side Information (LSI)</p>
<p>A distance metric learning algorithm that minimizes the sum of distances between similar data, with non similar
data constrained to be separated.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>initial_metric</strong> <span class="classifier-delimiter">:</span> <span class="classifier">2D-Array or Matrix (d x d), or string, default=None.</span></dt>
<dd><p class="first">If array or matrix, it must be a positive semidefinite matrix with the starting metric for gradient descent, where d is the number of features.
If None, euclidean distance will be used. If a string, the following values are allowed:</p>
<ul class="last simple">
<li>‘euclidean’ : the euclidean distance.</li>
<li>‘scale’ : a diagonal matrix that normalizes each attribute according to its range will be used.</li>
</ul>
</dd>
<dt><strong>learning_rate</strong> <span class="classifier-delimiter">:</span> <span class="classifier">string, default=’adaptive’</span></dt>
<dd><p class="first">Type of learning rate update for gradient descent. Possible values are:</p>
<ul class="last simple">
<li>‘adaptive’ : the learning rate will increase if the gradient step is succesful, else it will decrease.</li>
<li>‘constant’ : the learning rate will be constant during all the gradient steps.</li>
</ul>
</dd>
<dt><strong>eta0</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=0.1</span></dt>
<dd><p class="first last">The initial value for learning rate.</p>
</dd>
<dt><strong>max_iter</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=100</span></dt>
<dd><p class="first last">Number of iterations for gradient descent.</p>
</dd>
<dt><strong>max_proj_iter</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=5000</span></dt>
<dd><p class="first last">Number of iterations for iterated projections.</p>
</dd>
<dt><strong>itproj_err</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1e-3</span></dt>
<dd><p class="first last">Convergence error criterion for iterated projections</p>
</dd>
<dt><strong>err</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1e-3</span></dt>
<dd><p class="first last">Convergence error stop criterion for gradient descent.</p>
</dd>
<dt><strong>supervised</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Boolean, default=False</span></dt>
<dd><p class="first last">If True, the algorithm will accept a labeled dataset (X,y). Else, it will accept the dataset and the similarity sets, (X,S,D).</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#dml.lsi.LSI.fit" title="dml.lsi.LSI.fit"><code class="xref py py-obj docutils literal"><span class="pre">fit</span></code></a></td>
<td>Fit the model from the data in X and the side information in side</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">fit_transform</span></code>(X[,&nbsp;y])</td>
<td>Fit to data, then transform it.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">get_params</span></code>([deep])</td>
<td>Get parameters for this estimator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#dml.lsi.LSI.metadata" title="dml.lsi.LSI.metadata"><code class="xref py py-obj docutils literal"><span class="pre">metadata</span></code></a></td>
<td>Obtains algorithm metadata.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#dml.lsi.LSI.metric" title="dml.lsi.LSI.metric"><code class="xref py py-obj docutils literal"><span class="pre">metric</span></code></a></td>
<td>Obtains the learned metric.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">set_params</span></code>(**params)</td>
<td>Set the parameters of this estimator.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">transform</span></code>([X])</td>
<td>Applies the metric transformation.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">transformer</span></code>()</td>
<td>Computes a transformation matrix from the Mahalanobis matrix.</td>
</tr>
</tbody>
</table>
<table border="1" class="docutils">
<colgroup>
<col width="73%" />
<col width="27%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><strong>fD</strong></td>
<td>&#160;</td>
</tr>
<tr class="row-even"><td><strong>fD1</strong></td>
<td>&#160;</td>
</tr>
<tr class="row-odd"><td><strong>fS</strong></td>
<td>&#160;</td>
</tr>
<tr class="row-even"><td><strong>fS1</strong></td>
<td>&#160;</td>
</tr>
<tr class="row-odd"><td><strong>grad_projection</strong></td>
<td>&#160;</td>
</tr>
<tr class="row-even"><td><strong>label_to_similarity_set</strong></td>
<td>&#160;</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="dml.lsi.LSI.fD">
<code class="descname">fD</code><a class="headerlink" href="#dml.lsi.LSI.fD" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="dml.lsi.LSI.fD1">
<code class="descname">fD1</code><a class="headerlink" href="#dml.lsi.LSI.fD1" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="dml.lsi.LSI.fS">
<code class="descname">fS</code><a class="headerlink" href="#dml.lsi.LSI.fS" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="dml.lsi.LSI.fS1">
<code class="descname">fS1</code><a class="headerlink" href="#dml.lsi.LSI.fS1" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="dml.lsi.LSI.fit">
<code class="descname">fit</code><a class="headerlink" href="#dml.lsi.LSI.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model from the data in X and the side information in side</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N x d)</span></dt>
<dd><p class="first last">Training vector, where N is the number of samples, and d is the number of features.</p>
</dd>
<dt><strong>side</strong> <span class="classifier-delimiter">:</span> <span class="classifier">list of array-like, or 1D-array (N)</span></dt>
<dd><dl class="first last docutils">
<dt>The side information, or the label set. Options:</dt>
<dd><ul class="first simple">
<li>side = y, the label set (only if supervised = True)</li>
<li>side = [S,D], where S is the set of indices of similar data and D is the set of indices of dissimilar data.</li>
<li>side = [S], where S is the set of indices of similar data. The set D will be the complement of S.</li>
</ul>
<p class="last">Sets S and D are represented as a boolean matrix (S[i,j]==True iff (i,j) in S)</p>
</dd>
</dl>
</dd>
<dt><strong>Returns</strong></dt>
<dd></dd>
<dt><strong>——-</strong></dt>
<dd></dd>
<dt><strong>self</strong> <span class="classifier-delimiter">:</span> <span class="classifier">object</span></dt>
<dd><p class="first last">Returns the instance itself.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="dml.lsi.LSI.grad_projection">
<code class="descname">grad_projection</code><a class="headerlink" href="#dml.lsi.LSI.grad_projection" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="dml.lsi.LSI.label_to_similarity_set">
<code class="descname">label_to_similarity_set</code><a class="headerlink" href="#dml.lsi.LSI.label_to_similarity_set" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="dml.lsi.LSI.metadata">
<code class="descname">metadata</code><a class="headerlink" href="#dml.lsi.LSI.metadata" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtains algorithm metadata.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>meta</strong> <span class="classifier-delimiter">:</span> <span class="classifier">A dictionary with the following metadata:</span></dt>
<dd><ul class="first last simple">
<li>‘initial_objective’ : Initial value of the objective function.</li>
<li>‘initial_constraint’ : Initial calue of the constraint function.</li>
<li>‘final_objective’ : Final value of the objective function.</li>
<li>‘final_constraint’ : Final value of the constraint function.</li>
<li>‘iterative_projections_conv_exp’ : Convergence ratio, from 0 to 1, of the iterative projections.</li>
<li>‘projection_iterations_avg’ : Average iterations needed in iterative projections.</li>
<li>‘num_its’ : Number of iterations of gradient descent.</li>
</ul>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="dml.lsi.LSI.metric">
<code class="descname">metric</code><a class="headerlink" href="#dml.lsi.LSI.metric" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtains the learned metric.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>M</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(dxd) positive semidefinite matrix, where d is the number of features.</span></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-dml.mcml">
<span id="dml-mcml-module"></span><h2>dml.mcml module<a class="headerlink" href="#module-dml.mcml" title="Permalink to this headline">¶</a></h2>
<p>Maximally collapsing metric learning (MCML)</p>
<p>Created on Mon Mar 12 10:47:23 2018</p>
<p>&#64;author: jlsuarezdiaz</p>
<dl class="class">
<dt id="dml.mcml.MCML">
<em class="property">class </em><code class="descclassname">dml.mcml.</code><code class="descname">MCML</code><a class="headerlink" href="#dml.mcml.MCML" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dml.dml_algorithm.DML_Algorithm" title="dml.dml_algorithm.DML_Algorithm"><code class="xref py py-class docutils literal"><span class="pre">dml.dml_algorithm.DML_Algorithm</span></code></a></p>
<p>Maximally Collapsing Metric Learning (MCML)</p>
<p>A distance metric learning algorithm that learns minimizing the KL divergence to the maximally collapsing distribution.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>num_dims</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=None.</span></dt>
<dd><p class="first last">Number of dimensions for dimensionality reduction. Not supported yet.</p>
</dd>
<dt><strong>learning_rate</strong> <span class="classifier-delimiter">:</span> <span class="classifier">string, default=’adaptive’</span></dt>
<dd><p class="first">Type of learning rate update for gradient descent. Possible values are:</p>
<ul class="last simple">
<li>‘adaptive’ : the learning rate will increase if the gradient step is succesful, else it will decrease.</li>
<li>‘constant’ : the learning rate will be constant during all the gradient steps.</li>
</ul>
</dd>
<dt><strong>eta0</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=0.01</span></dt>
<dd><p class="first last">The initial value for learning rate.</p>
</dd>
<dt><strong>initial_metric</strong> <span class="classifier-delimiter">:</span> <span class="classifier">2D-Array or Matrix (d x d), or string, default=None.</span></dt>
<dd><p class="first">If array or matrix, it must be a positive semidefinite matrix with the starting metric for gradient descent, where d is the number of features.
If None, euclidean distance will be used. If a string, the following values are allowed:</p>
<ul class="last simple">
<li>‘euclidean’ : the euclidean distance.</li>
<li>‘scale’ : a diagonal matrix that normalizes each attribute according to its range will be used.</li>
</ul>
</dd>
<dt><strong>max_iter</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=20</span></dt>
<dd><p class="first last">Maximum number of iterations of gradient descent.</p>
</dd>
<dt><strong>prec</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1e-3</span></dt>
<dd><p class="first last">Precision stop criterion (gradient norm).</p>
</dd>
<dt><strong>tol</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1e-3</span></dt>
<dd><p class="first last">Tolerance stop criterion (difference between two iterations)</p>
</dd>
<dt><strong>descent_method</strong> <span class="classifier-delimiter">:</span> <span class="classifier">string, default=’SDP’</span></dt>
<dd><p class="first">The descent method to use. Allowed values are:</p>
<ul class="last simple">
<li>‘SDP’ : semidefinite programming, consisting of gradient descent with projections onto the PSD cone.</li>
</ul>
</dd>
<dt><strong>eta_thres</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1e-14</span></dt>
<dd><p class="first last">A learning rate threshold stop criterion.</p>
</dd>
<dt><strong>learn_inc</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1.01</span></dt>
<dd><p class="first last">Increase factor for learning rate. Ignored if learning_rate is not ‘adaptive’.</p>
</dd>
<dt><strong>learn_dec</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=0.5</span></dt>
<dd><p class="first last">Decrease factor for learning rate. Ignored if learning_rate is not ‘adaptive’.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#dml.mcml.MCML.fit" title="dml.mcml.MCML.fit"><code class="xref py py-obj docutils literal"><span class="pre">fit</span></code></a></td>
<td>Fit the model from the data in X and the labels in y.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">fit_transform</span></code>(X[,&nbsp;y])</td>
<td>Fit to data, then transform it.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">get_params</span></code>([deep])</td>
<td>Get parameters for this estimator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#dml.mcml.MCML.metadata" title="dml.mcml.MCML.metadata"><code class="xref py py-obj docutils literal"><span class="pre">metadata</span></code></a></td>
<td>Obtains algorithm metadata.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#dml.mcml.MCML.metric" title="dml.mcml.MCML.metric"><code class="xref py py-obj docutils literal"><span class="pre">metric</span></code></a></td>
<td>Obtains the learned metric.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">set_params</span></code>(**params)</td>
<td>Set the parameters of this estimator.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">transform</span></code>([X])</td>
<td>Applies the metric transformation.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">transformer</span></code>()</td>
<td>Computes a transformation matrix from the Mahalanobis matrix.</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="dml.mcml.MCML.fit">
<code class="descname">fit</code><a class="headerlink" href="#dml.mcml.MCML.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model from the data in X and the labels in y.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N x d)</span></dt>
<dd><p class="first last">Training vector, where N is the number of samples, and d is the number of features.</p>
</dd>
<dt><strong>y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N)</span></dt>
<dd><p class="first last">Labels vector, where N is the number of samples.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>self</strong> <span class="classifier-delimiter">:</span> <span class="classifier">object</span></dt>
<dd><p class="first last">Returns the instance itself.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="dml.mcml.MCML.metadata">
<code class="descname">metadata</code><a class="headerlink" href="#dml.mcml.MCML.metadata" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtains algorithm metadata.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>meta</strong> <span class="classifier-delimiter">:</span> <span class="classifier">A dictionary with the following metadata:</span></dt>
<dd><ul class="first last simple">
<li>‘num_iters’ : Number of iterations that the descent method took.</li>
<li>‘initial_error’ : Initial value of the objective function.</li>
<li>‘final_error’ : Final value of the objective function.</li>
</ul>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="dml.mcml.MCML.metric">
<code class="descname">metric</code><a class="headerlink" href="#dml.mcml.MCML.metric" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtains the learned metric.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>M</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(dxd) positive semidefinite matrix, where d is the number of features.</span></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-dml.multidml_knn">
<span id="dml-multidml-knn-module"></span><h2>dml.multidml_knn module<a class="headerlink" href="#module-dml.multidml_knn" title="Permalink to this headline">¶</a></h2>
<p>Multiple-DML k-Nearest Neighbors (kNN)</p>
<dl class="class">
<dt id="dml.multidml_knn.MultiDML_kNN">
<em class="property">class </em><code class="descclassname">dml.multidml_knn.</code><code class="descname">MultiDML_kNN</code><span class="sig-paren">(</span><em>n_neighbors</em>, <em>dmls=None</em>, <em>verbose=False</em>, <em>**knn_args</em><span class="sig-paren">)</span><a class="headerlink" href="#dml.multidml_knn.MultiDML_kNN" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">object</span></code></p>
<p>Multi-DML k-NN</p>
<p>An interface that allows learning k-NN with different distance metric learners simultaneously.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>n_neighbors</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">The number of neighbors for k-NN.</p>
</dd>
<dt><strong>dmls</strong> <span class="classifier-delimiter">:</span> <span class="classifier">list, default=None</span></dt>
<dd><p class="first last">A list of distance metric learning algorithms to be learned for k-NN. By default, euclidean distance will be added at the first
place of the dml list.</p>
</dd>
<dt><strong>verbose</strong> <span class="classifier-delimiter">:</span> <span class="classifier">boolean, default=False</span></dt>
<dd><p class="first last">If True, console message about the algorithms execution will be printed.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#dml.multidml_knn.MultiDML_kNN.add" title="dml.multidml_knn.MultiDML_kNN.add"><code class="xref py py-obj docutils literal"><span class="pre">add</span></code></a>(dmls)</td>
<td>Adds a new distance metric learning algorithm to the list.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#dml.multidml_knn.MultiDML_kNN.dmls_string" title="dml.multidml_knn.MultiDML_kNN.dmls_string"><code class="xref py py-obj docutils literal"><span class="pre">dmls_string</span></code></a>()</td>
<td>Obtains the strings with the dml names.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#dml.multidml_knn.MultiDML_kNN.elapsed" title="dml.multidml_knn.MultiDML_kNN.elapsed"><code class="xref py py-obj docutils literal"><span class="pre">elapsed</span></code></a>()</td>
<td>Obtains the elapsed time of each DML algorithm</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#dml.multidml_knn.MultiDML_kNN.fit" title="dml.multidml_knn.MultiDML_kNN.fit"><code class="xref py py-obj docutils literal"><span class="pre">fit</span></code></a>(X,&nbsp;y)</td>
<td>Fit the model from the data in X and the labels in y.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#dml.multidml_knn.MultiDML_kNN.predict_all" title="dml.multidml_knn.MultiDML_kNN.predict_all"><code class="xref py py-obj docutils literal"><span class="pre">predict_all</span></code></a>([X])</td>
<td>Predicts the labels for the given data.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#dml.multidml_knn.MultiDML_kNN.predict_proba_all" title="dml.multidml_knn.MultiDML_kNN.predict_proba_all"><code class="xref py py-obj docutils literal"><span class="pre">predict_proba_all</span></code></a>([X])</td>
<td>Predicts the probabilities for the given data.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#dml.multidml_knn.MultiDML_kNN.score_all" title="dml.multidml_knn.MultiDML_kNN.score_all"><code class="xref py py-obj docutils literal"><span class="pre">score_all</span></code></a>([X,&nbsp;y])</td>
<td>Obtains the scores for the given data.</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="dml.multidml_knn.MultiDML_kNN.add">
<code class="descname">add</code><span class="sig-paren">(</span><em>dmls</em><span class="sig-paren">)</span><a class="headerlink" href="#dml.multidml_knn.MultiDML_kNN.add" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a new distance metric learning algorithm to the list.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>dmls</strong> <span class="classifier-delimiter">:</span> <span class="classifier">DML_Algorithm, or list of DMÑ_Algorithm</span></dt>
<dd><p class="first last">The DML algorithm or algorithms to add.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="dml.multidml_knn.MultiDML_kNN.dmls_string">
<code class="descname">dmls_string</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#dml.multidml_knn.MultiDML_kNN.dmls_string" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtains the strings with the dml names.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>strings</strong> <span class="classifier-delimiter">:</span> <span class="classifier">A list with the names of each dml.</span></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="dml.multidml_knn.MultiDML_kNN.elapsed">
<code class="descname">elapsed</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#dml.multidml_knn.MultiDML_kNN.elapsed" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtains the elapsed time of each DML algorithm</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>elapsed</strong> <span class="classifier-delimiter">:</span> <span class="classifier">A list of float with the time of each DML.</span></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="dml.multidml_knn.MultiDML_kNN.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em><span class="sig-paren">)</span><a class="headerlink" href="#dml.multidml_knn.MultiDML_kNN.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model from the data in X and the labels in y.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N x d)</span></dt>
<dd><p class="first last">Training vector, where N is the number of samples, and d is the number of features.</p>
</dd>
<dt><strong>y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N)</span></dt>
<dd><p class="first last">Labels vector, where N is the number of samples.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>self</strong> <span class="classifier-delimiter">:</span> <span class="classifier">object</span></dt>
<dd><p class="first last">Returns the instance itself.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="dml.multidml_knn.MultiDML_kNN.predict_all">
<code class="descname">predict_all</code><span class="sig-paren">(</span><em>X=None</em><span class="sig-paren">)</span><a class="headerlink" href="#dml.multidml_knn.MultiDML_kNN.predict_all" title="Permalink to this definition">¶</a></dt>
<dd><p>Predicts the labels for the given data. Model needs to be already fitted.</p>
<p>X : 2D-Array or Matrix, default=None</p>
<blockquote>
<div>The dataset to be used. If None, the training set will be used. In this case, the prediction will be made
using Leave One Out (that is, the sample to predict will be taken away from the training set).</div></blockquote>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">list of 1D-Arrays</span></dt>
<dd><p class="first last">A list with the vectors with the label predictions for each DML.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="dml.multidml_knn.MultiDML_kNN.predict_proba_all">
<code class="descname">predict_proba_all</code><span class="sig-paren">(</span><em>X=None</em><span class="sig-paren">)</span><a class="headerlink" href="#dml.multidml_knn.MultiDML_kNN.predict_proba_all" title="Permalink to this definition">¶</a></dt>
<dd><p>Predicts the probabilities for the given data. Model needs to be already fitted.</p>
<p>X : 2D-Array or Matrix, default=None</p>
<blockquote>
<div>The dataset to be used. If None, the training set will be used. In this case, the prediction will be made
using Leave One Out (that is, the sample to predict will be taken away from the training set).</div></blockquote>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>T</strong> <span class="classifier-delimiter">:</span> <span class="classifier">list of 2D-Arrays</span></dt>
<dd><p class="first last">A list with the matrices with the label probabilities for each class, for each DML.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="dml.multidml_knn.MultiDML_kNN.score_all">
<code class="descname">score_all</code><span class="sig-paren">(</span><em>X=None</em>, <em>y=None</em><span class="sig-paren">)</span><a class="headerlink" href="#dml.multidml_knn.MultiDML_kNN.score_all" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtains the scores for the given data. Model needs to be already fitted.</p>
<p>X : 2D-Array or Matrix, default=None</p>
<blockquote>
<div>The dataset to be used. If None, the training set will be used. In this case, the prediction will be made
using Leave One Out (that is, the sample to predict will be taken away from the training set).</div></blockquote>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>s</strong> <span class="classifier-delimiter">:</span> <span class="classifier">list of float</span></dt>
<dd><p class="first last">A list with the k-NN scores for each DML.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-dml.nca">
<span id="dml-nca-module"></span><h2>dml.nca module<a class="headerlink" href="#module-dml.nca" title="Permalink to this headline">¶</a></h2>
<p>Neighbourhood Component Analysis (NCA)</p>
<dl class="class">
<dt id="dml.nca.NCA">
<em class="property">class </em><code class="descclassname">dml.nca.</code><code class="descname">NCA</code><a class="headerlink" href="#dml.nca.NCA" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dml.dml_algorithm.DML_Algorithm" title="dml.dml_algorithm.DML_Algorithm"><code class="xref py py-class docutils literal"><span class="pre">dml.dml_algorithm.DML_Algorithm</span></code></a></p>
<p>Neighborhood Component Analysis (NCA)</p>
<p>A distance metric learning algorithm that tries to minimize kNN expected error.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>num_dims</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=None</span></dt>
<dd><p class="first last">Desired value for dimensionality reduction. If None, the dimension of transformed data will be the same as the original.</p>
</dd>
<dt><strong>learning_rate</strong> <span class="classifier-delimiter">:</span> <span class="classifier">string, default=’adaptive’</span></dt>
<dd><p class="first">Type of learning rate update for gradient descent. Possible values are:</p>
<ul class="last simple">
<li>‘adaptive’ : the learning rate will increase if the gradient step is succesful, else it will decrease.</li>
<li>‘constant’ : the learning rate will be constant during all the gradient steps.</li>
</ul>
</dd>
<dt><strong>eta0</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=0.3</span></dt>
<dd><p class="first last">The initial value for learning rate.</p>
</dd>
<dt><strong>initial_transform</strong> <span class="classifier-delimiter">:</span> <span class="classifier">2D-Array or Matrix (d’ x d), or string, default=None.</span></dt>
<dd><p class="first">If array or matrix that will represent the starting linear map for gradient descent, where d is the number of features,
and d’ is the dimension specified in num_dims.
If None, euclidean distance will be used. If a string, the following values are allowed:</p>
<ul class="last simple">
<li>‘euclidean’ : the euclidean distance.</li>
<li>‘scale’ : a diagonal matrix that normalizes each attribute according to its range will be used.</li>
</ul>
</dd>
<dt><strong>max_iter</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=100</span></dt>
<dd><p class="first last">Maximum number of gradient descent iterations.</p>
</dd>
<dt><strong>prec</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1e-8</span></dt>
<dd><p class="first last">Precision stop criterion (gradient norm).</p>
</dd>
<dt><strong>tol</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1e-8</span></dt>
<dd><p class="first last">Tolerance stop criterion (difference between two iterations)</p>
</dd>
<dt><strong>descent_method</strong> <span class="classifier-delimiter">:</span> <span class="classifier">string, default=’SGD’</span></dt>
<dd><p class="first">The descent method to use. Allowed values are:</p>
<ul class="last simple">
<li>‘SGD’ : stochastic gradient descent.</li>
<li>‘BGD’ : batch gradient descent.</li>
</ul>
</dd>
<dt><strong>eta_thres</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1e-14</span></dt>
<dd><p class="first last">A learning rate threshold stop criterion.</p>
</dd>
<dt><strong>learn_inc</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1.01</span></dt>
<dd><p class="first last">Increase factor for learning rate. Ignored if learning_rate is not ‘adaptive’.</p>
</dd>
<dt><strong>learn_dec</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=0.5</span></dt>
<dd><p class="first last">Decrease factor for learning rate. Ignored if learning_rate is not ‘adaptive’.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#dml.nca.NCA.fit" title="dml.nca.NCA.fit"><code class="xref py py-obj docutils literal"><span class="pre">fit</span></code></a></td>
<td>Fit the model from the data in X and the labels in y.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">fit_transform</span></code>(X[,&nbsp;y])</td>
<td>Fit to data, then transform it.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">get_params</span></code>([deep])</td>
<td>Get parameters for this estimator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#dml.nca.NCA.metadata" title="dml.nca.NCA.metadata"><code class="xref py py-obj docutils literal"><span class="pre">metadata</span></code></a></td>
<td>Obtains algorithm metadata.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">metric</span></code>()</td>
<td>Computes the Mahalanobis matrix from the transformation matrix.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">set_params</span></code>(**params)</td>
<td>Set the parameters of this estimator.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">transform</span></code>([X])</td>
<td>Applies the metric transformation.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#dml.nca.NCA.transformer" title="dml.nca.NCA.transformer"><code class="xref py py-obj docutils literal"><span class="pre">transformer</span></code></a></td>
<td>Obtains the learned projection.</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="dml.nca.NCA.fit">
<code class="descname">fit</code><a class="headerlink" href="#dml.nca.NCA.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model from the data in X and the labels in y.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N x d)</span></dt>
<dd><p class="first last">Training vector, where N is the number of samples, and d is the number of features.</p>
</dd>
<dt><strong>y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N)</span></dt>
<dd><p class="first last">Labels vector, where N is the number of samples.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>self</strong> <span class="classifier-delimiter">:</span> <span class="classifier">object</span></dt>
<dd><p class="first last">Returns the instance itself.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="dml.nca.NCA.metadata">
<code class="descname">metadata</code><a class="headerlink" href="#dml.nca.NCA.metadata" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtains algorithm metadata.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>meta</strong> <span class="classifier-delimiter">:</span> <span class="classifier">A dictionary with the following metadata:</span></dt>
<dd><ul class="first last simple">
<li>num_iters : Number of iterations that the descent method took.</li>
<li>initial_expectance : Initial value of the objective function (the expected LOO score)</li>
<li>final_expectance : Final value of the objective function (the expected LOO score)</li>
</ul>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="dml.nca.NCA.transformer">
<code class="descname">transformer</code><a class="headerlink" href="#dml.nca.NCA.transformer" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtains the learned projection.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>L</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(d’xd) matrix, where d’ is the desired output dimension and d is the number of features.</span></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-dml.ncmc">
<span id="dml-ncmc-module"></span><h2>dml.ncmc module<a class="headerlink" href="#module-dml.ncmc" title="Permalink to this headline">¶</a></h2>
<p>Nearest Class with Multiple Centroids (NCMC)</p>
<p>Created on Wed Feb 28 16:18:39 2018</p>
<p>&#64;author: jlsuarezdiaz</p>
<dl class="class">
<dt id="dml.ncmc.NCMC">
<em class="property">class </em><code class="descclassname">dml.ncmc.</code><code class="descname">NCMC</code><a class="headerlink" href="#dml.ncmc.NCMC" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dml.dml_algorithm.DML_Algorithm" title="dml.dml_algorithm.DML_Algorithm"><code class="xref py py-class docutils literal"><span class="pre">dml.dml_algorithm.DML_Algorithm</span></code></a></p>
<p>Nearest Class with Multiple Centroids distance metric learner (NCMC).</p>
<p>A distance metric learning algorithm to improve the nearest class with multiple centroids classifier.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>num_dims</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=None</span></dt>
<dd><p class="first last">Desired value for dimensionality reduction. If None, the dimension of transformed data will be the same as the original.</p>
</dd>
<dt><strong>centroids_num</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, or list of int, default=3</span></dt>
<dd><p class="first last">If it is a list, it must have the same size as the number of classes. In this case, i-th item will be the number of
centroids to take in the i-th class. If it is an int, every class will have the same number of centroids.</p>
</dd>
<dt><strong>learning_rate</strong> <span class="classifier-delimiter">:</span> <span class="classifier">string, default=’adaptive’</span></dt>
<dd><p class="first">Type of learning rate update for gradient descent. Possible values are:</p>
<ul class="last simple">
<li>‘adaptive’ : the learning rate will increase if the gradient step is succesful, else it will decrease.</li>
<li>‘constant’ : the learning rate will be constant during all the gradient steps.</li>
</ul>
</dd>
<dt><strong>eta0</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=0.3</span></dt>
<dd><p class="first last">The initial value for learning rate.</p>
</dd>
<dt><strong>initial_transform</strong> <span class="classifier-delimiter">:</span> <span class="classifier">2D-Array or Matrix (d’ x d), or string, default=None.</span></dt>
<dd><p class="first">If array or matrix that will represent the starting linear map for gradient descent, where d is the number of features,
and d’ is the dimension specified in num_dims.
If None, euclidean distance will be used. If a string, the following values are allowed:</p>
<ul class="last simple">
<li>‘euclidean’ : the euclidean distance.</li>
<li>‘scale’ : a diagonal matrix that normalizes each attribute according to its range will be used.</li>
</ul>
</dd>
<dt><strong>max_iter</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=300</span></dt>
<dd><p class="first last">Maximum number of gradient descent iterations.</p>
</dd>
<dt><strong>prec</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1e-15</span></dt>
<dd><p class="first last">Precision stop criterion (gradient norm).</p>
</dd>
<dt><strong>tol</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1e-15</span></dt>
<dd><p class="first last">Tolerance stop criterion (difference between two iterations)</p>
</dd>
<dt><strong>descent_method</strong> <span class="classifier-delimiter">:</span> <span class="classifier">string, default=’SGD’</span></dt>
<dd><p class="first">The descent method to use. Allowed values are:</p>
<ul class="last simple">
<li>‘SGD’ : stochastic gradient descent.</li>
<li>‘BGD’ : batch gradient descent.</li>
</ul>
</dd>
<dt><strong>eta_thres</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1e-14</span></dt>
<dd><p class="first last">A learning rate threshold stop criterion.</p>
</dd>
<dt><strong>learn_inc</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1.01</span></dt>
<dd><p class="first last">Increase factor for learning rate. Ignored if learning_rate is not ‘adaptive’.</p>
</dd>
<dt><strong>learn_dec</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=0.5</span></dt>
<dd><p class="first last">Decrease factor for learning rate. Ignored if learning_rate is not ‘adaptive’.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#dml.ncmc.NCMC.fit" title="dml.ncmc.NCMC.fit"><code class="xref py py-obj docutils literal"><span class="pre">fit</span></code></a></td>
<td>Fit the model from the data in X and the labels in y.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">fit_transform</span></code>(X[,&nbsp;y])</td>
<td>Fit to data, then transform it.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">get_params</span></code>([deep])</td>
<td>Get parameters for this estimator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#dml.ncmc.NCMC.metadata" title="dml.ncmc.NCMC.metadata"><code class="xref py py-obj docutils literal"><span class="pre">metadata</span></code></a></td>
<td>Obtains algorithm metadata.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">metric</span></code>()</td>
<td>Computes the Mahalanobis matrix from the transformation matrix.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">set_params</span></code>(**params)</td>
<td>Set the parameters of this estimator.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">transform</span></code>([X])</td>
<td>Applies the metric transformation.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#dml.ncmc.NCMC.transformer" title="dml.ncmc.NCMC.transformer"><code class="xref py py-obj docutils literal"><span class="pre">transformer</span></code></a></td>
<td>Obtains the learned projection.</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="dml.ncmc.NCMC.fit">
<code class="descname">fit</code><a class="headerlink" href="#dml.ncmc.NCMC.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model from the data in X and the labels in y.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N x d)</span></dt>
<dd><p class="first last">Training vector, where N is the number of samples, and d is the number of features.</p>
</dd>
<dt><strong>y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N)</span></dt>
<dd><p class="first last">Labels vector, where N is the number of samples.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>self</strong> <span class="classifier-delimiter">:</span> <span class="classifier">object</span></dt>
<dd><p class="first last">Returns the instance itself.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="dml.ncmc.NCMC.metadata">
<code class="descname">metadata</code><a class="headerlink" href="#dml.ncmc.NCMC.metadata" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtains algorithm metadata.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>meta</strong> <span class="classifier-delimiter">:</span> <span class="classifier">A dictionary with the following metadata:</span></dt>
<dd><ul class="first last simple">
<li>num_iters : Number of iterations that the descent method took.</li>
<li>initial_expectance : Initial value of the objective function (the expected score)</li>
<li>final_expectance : Final value of the objective function (the expected score)</li>
</ul>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="dml.ncmc.NCMC.transformer">
<code class="descname">transformer</code><a class="headerlink" href="#dml.ncmc.NCMC.transformer" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtains the learned projection.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>L</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(d’xd) matrix, where d’ is the desired output dimension and d is the number of features.</span></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="dml.ncmc.NCMC_Classifier">
<em class="property">class </em><code class="descclassname">dml.ncmc.</code><code class="descname">NCMC_Classifier</code><a class="headerlink" href="#dml.ncmc.NCMC_Classifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">sklearn.base.BaseEstimator</span></code>, <code class="xref py py-class docutils literal"><span class="pre">sklearn.base.ClassifierMixin</span></code></p>
<p>Nearest Class with Multiple Centroids classifier.</p>
<p>A classifier that makes its predictions by choosing the class who has a centroid the nearest to the point.
For each class, an arbitrary number of centroids can be set. This centroids are calculated using k-Means
over each class sub-dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>centroids_num</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, or list of int, default=3</span></dt>
<dd><p class="first last">If it is a list, it must have the same size as the number of classes. In this case, i-th item will be the number of
centroids to take in the i-th class. If it is an int, every class will have the same number of centroids.</p>
</dd>
<dt><strong>kmeans_args</strong> <span class="classifier-delimiter">:</span> <span class="classifier">dictionary</span></dt>
<dd><p class="first last">Additional keyword args for k-Means.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#dml.ncmc.NCMC_Classifier.fit" title="dml.ncmc.NCMC_Classifier.fit"><code class="xref py py-obj docutils literal"><span class="pre">fit</span></code></a></td>
<td>Fit the model from the data in X and the labels in y.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">get_params</span></code>([deep])</td>
<td>Get parameters for this estimator.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#dml.ncmc.NCMC_Classifier.predict" title="dml.ncmc.NCMC_Classifier.predict"><code class="xref py py-obj docutils literal"><span class="pre">predict</span></code></a></td>
<td>Predicts the labels for the given data.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">score</span></code>(X,&nbsp;y[,&nbsp;sample_weight])</td>
<td>Returns the mean accuracy on the given test data and labels.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">set_params</span></code>(**params)</td>
<td>Set the parameters of this estimator.</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="dml.ncmc.NCMC_Classifier.fit">
<code class="descname">fit</code><a class="headerlink" href="#dml.ncmc.NCMC_Classifier.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model from the data in X and the labels in y.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N x d)</span></dt>
<dd><p class="first last">Training vector, where N is the number of samples, and d is the number of features.</p>
</dd>
<dt><strong>y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N)</span></dt>
<dd><p class="first last">Labels vector, where N is the number of samples.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>self</strong> <span class="classifier-delimiter">:</span> <span class="classifier">object</span></dt>
<dd><p class="first last">Returns the instance itself.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="dml.ncmc.NCMC_Classifier.predict">
<code class="descname">predict</code><a class="headerlink" href="#dml.ncmc.NCMC_Classifier.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predicts the labels for the given data. Model needs to be already fitted.</p>
<p>X : 2D-Array or Matrix, default=None</p>
<blockquote>
<div>The dataset to be used. If None, the training set will be used. In this case, the prediction will be made
using Leave One Out (that is, the sample to predict will be taken away from the training set).</div></blockquote>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">1D-Array</span></dt>
<dd><p class="first last">The vector with the label predictions.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-dml.ncmml">
<span id="dml-ncmml-module"></span><h2>dml.ncmml module<a class="headerlink" href="#module-dml.ncmml" title="Permalink to this headline">¶</a></h2>
<p>Nearest Class Mean Metric Learning (NCMML)</p>
<p>Created on Wed Feb 28 12:07:43 2018</p>
<p>&#64;author: jlsuarezdiaz</p>
<dl class="class">
<dt id="dml.ncmml.NCMML">
<em class="property">class </em><code class="descclassname">dml.ncmml.</code><code class="descname">NCMML</code><a class="headerlink" href="#dml.ncmml.NCMML" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dml.dml_algorithm.DML_Algorithm" title="dml.dml_algorithm.DML_Algorithm"><code class="xref py py-class docutils literal"><span class="pre">dml.dml_algorithm.DML_Algorithm</span></code></a></p>
<p>Nearest Class Mean Metric Learning (NCMML)</p>
<p>A distance metric learning algorithm to improve the nearest class mean classifier.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>num_dims</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=None</span></dt>
<dd><p class="first last">Desired value for dimensionality reduction. If None, the dimension of transformed data will be the same as the original.</p>
</dd>
<dt><strong>learning_rate</strong> <span class="classifier-delimiter">:</span> <span class="classifier">string, default=’adaptive’</span></dt>
<dd><p class="first">Type of learning rate update for gradient descent. Possible values are:</p>
<ul class="last simple">
<li>‘adaptive’ : the learning rate will increase if the gradient step is succesful, else it will decrease.</li>
<li>‘constant’ : the learning rate will be constant during all the gradient steps.</li>
</ul>
</dd>
<dt><strong>eta0</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=0.3</span></dt>
<dd><p class="first last">The initial value for learning rate.</p>
</dd>
<dt><strong>initial_transform</strong> <span class="classifier-delimiter">:</span> <span class="classifier">2D-Array or Matrix (d’ x d), or string, default=None.</span></dt>
<dd><p class="first">If array or matrix that will represent the starting linear map for gradient descent, where d is the number of features,
and d’ is the dimension specified in num_dims.
If None, euclidean distance will be used. If a string, the following values are allowed:</p>
<ul class="last simple">
<li>‘euclidean’ : the euclidean distance.</li>
<li>‘scale’ : a diagonal matrix that normalizes each attribute according to its range will be used.</li>
</ul>
</dd>
<dt><strong>max_iter</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=300</span></dt>
<dd><p class="first last">Maximum number of gradient descent iterations.</p>
</dd>
<dt><strong>prec</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1e-15</span></dt>
<dd><p class="first last">Precision stop criterion (gradient norm).</p>
</dd>
<dt><strong>tol</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1e-15</span></dt>
<dd><p class="first last">Tolerance stop criterion (difference between two iterations)</p>
</dd>
<dt><strong>descent_method</strong> <span class="classifier-delimiter">:</span> <span class="classifier">string, default=’SGD’</span></dt>
<dd><p class="first">The descent method to use. Allowed values are:</p>
<ul class="last simple">
<li>‘SGD’ : stochastic gradient descent.</li>
<li>‘BGD’ : batch gradient descent.</li>
</ul>
</dd>
<dt><strong>eta_thres</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1e-14</span></dt>
<dd><p class="first last">A learning rate threshold stop criterion.</p>
</dd>
<dt><strong>learn_inc</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=1.01</span></dt>
<dd><p class="first last">Increase factor for learning rate. Ignored if learning_rate is not ‘adaptive’.</p>
</dd>
<dt><strong>learn_dec</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, default=0.5</span></dt>
<dd><p class="first last">Decrease factor for learning rate. Ignored if learning_rate is not ‘adaptive’.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#dml.ncmml.NCMML.fit" title="dml.ncmml.NCMML.fit"><code class="xref py py-obj docutils literal"><span class="pre">fit</span></code></a></td>
<td>Fit the model from the data in X and the labels in y.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">fit_transform</span></code>(X[,&nbsp;y])</td>
<td>Fit to data, then transform it.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">get_params</span></code>([deep])</td>
<td>Get parameters for this estimator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#dml.ncmml.NCMML.metadata" title="dml.ncmml.NCMML.metadata"><code class="xref py py-obj docutils literal"><span class="pre">metadata</span></code></a></td>
<td>Obtains algorithm metadata.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">metric</span></code>()</td>
<td>Computes the Mahalanobis matrix from the transformation matrix.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">set_params</span></code>(**params)</td>
<td>Set the parameters of this estimator.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">transform</span></code>([X])</td>
<td>Applies the metric transformation.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#dml.ncmml.NCMML.transformer" title="dml.ncmml.NCMML.transformer"><code class="xref py py-obj docutils literal"><span class="pre">transformer</span></code></a></td>
<td>Obtains algorithm metadata.</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="dml.ncmml.NCMML.fit">
<code class="descname">fit</code><a class="headerlink" href="#dml.ncmml.NCMML.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model from the data in X and the labels in y.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N x d)</span></dt>
<dd><p class="first last">Training vector, where N is the number of samples, and d is the number of features.</p>
</dd>
<dt><strong>y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N)</span></dt>
<dd><p class="first last">Labels vector, where N is the number of samples.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>self</strong> <span class="classifier-delimiter">:</span> <span class="classifier">object</span></dt>
<dd><p class="first last">Returns the instance itself.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="dml.ncmml.NCMML.metadata">
<code class="descname">metadata</code><a class="headerlink" href="#dml.ncmml.NCMML.metadata" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtains algorithm metadata.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>meta</strong> <span class="classifier-delimiter">:</span> <span class="classifier">A dictionary with the following metadata:</span></dt>
<dd><ul class="first last simple">
<li>num_iters : Number of iterations that the descent method took.</li>
<li>initial_expectance : Initial value of the objective function (the expected score)</li>
<li>final_expectance : Final value of the objective function (the expected score)</li>
</ul>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="dml.ncmml.NCMML.transformer">
<code class="descname">transformer</code><a class="headerlink" href="#dml.ncmml.NCMML.transformer" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtains algorithm metadata.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>meta</strong> <span class="classifier-delimiter">:</span> <span class="classifier">A dictionary with the following metadata:</span></dt>
<dd><ul class="first last simple">
<li>num_iters : Number of iterations that the descent method took.</li>
<li>initial_expectance : Initial value of the objective function (the expected score)</li>
<li>final_expectance : Final value of the objective function (the expected score)</li>
</ul>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-dml.pca">
<span id="dml-pca-module"></span><h2>dml.pca module<a class="headerlink" href="#module-dml.pca" title="Permalink to this headline">¶</a></h2>
<p>Principal Component Analysis (PCA)</p>
<dl class="class">
<dt id="dml.pca.PCA">
<em class="property">class </em><code class="descclassname">dml.pca.</code><code class="descname">PCA</code><a class="headerlink" href="#dml.pca.PCA" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dml.dml_algorithm.DML_Algorithm" title="dml.dml_algorithm.DML_Algorithm"><code class="xref py py-class docutils literal"><span class="pre">dml.dml_algorithm.DML_Algorithm</span></code></a></p>
<p>Principal Component Analysis (PCA)</p>
<p>A distance metric learning algorithm for unsupervised dimensionality reduction, obtaining orthogonal directions that maximize the variance.
This class is a wrapper for <code class="xref py py-class docutils literal"><span class="pre">PCA</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>num_dims</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=None</span></dt>
<dd><p class="first last">Number of components for dimensionality reduction. If None, all the principal components will be taken. Ignored if thres is provided.</p>
</dd>
<dt><strong>thres</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Fraction of variability to keep, from 0 to 1. Data dimension will be reduced until the lowest dimension that keeps ‘thres’ explained variance.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#dml.pca.PCA.fit" title="dml.pca.PCA.fit"><code class="xref py py-obj docutils literal"><span class="pre">fit</span></code></a></td>
<td>Fit the model from the data in X and the labels in y.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">fit_transform</span></code>(X[,&nbsp;y])</td>
<td>Fit to data, then transform it.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">get_params</span></code>([deep])</td>
<td>Get parameters for this estimator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#dml.pca.PCA.metadata" title="dml.pca.PCA.metadata"><code class="xref py py-obj docutils literal"><span class="pre">metadata</span></code></a></td>
<td>Obtains algorithm metadata.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">metric</span></code>()</td>
<td>Computes the Mahalanobis matrix from the transformation matrix.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">set_params</span></code>(**params)</td>
<td>Set the parameters of this estimator.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#dml.pca.PCA.transform" title="dml.pca.PCA.transform"><code class="xref py py-obj docutils literal"><span class="pre">transform</span></code></a></td>
<td>Applies the kernel transformation.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#dml.pca.PCA.transformer" title="dml.pca.PCA.transformer"><code class="xref py py-obj docutils literal"><span class="pre">transformer</span></code></a></td>
<td>Obtains the learned projection.</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="dml.pca.PCA.fit">
<code class="descname">fit</code><a class="headerlink" href="#dml.pca.PCA.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model from the data in X and the labels in y.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N x d)</span></dt>
<dd><p class="first last">Training vector, where N is the number of samples, and d is the number of features.</p>
</dd>
<dt><strong>y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N)</span></dt>
<dd><p class="first last">Labels vector, where N is the number of samples.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>self</strong> <span class="classifier-delimiter">:</span> <span class="classifier">object</span></dt>
<dd><p class="first last">Returns the instance itself.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="dml.pca.PCA.metadata">
<code class="descname">metadata</code><a class="headerlink" href="#dml.pca.PCA.metadata" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtains algorithm metadata.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>meta</strong> <span class="classifier-delimiter">:</span> <span class="classifier">A dictionary with the following metadata:</span></dt>
<dd><p class="first">num_dims : dimension of the reduced data.</p>
<p class="last">acum_eig : eigenvalue rate accumulated in the learned output respect to the total dimension.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="dml.pca.PCA.transform">
<code class="descname">transform</code><a class="headerlink" href="#dml.pca.PCA.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies the kernel transformation.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(N x d) matrix, optional</span></dt>
<dd><p class="first last">Data to transform. If not supplied, the training data will be used.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>transformed: (N x d’) matrix.</strong></dt>
<dd><p class="first last">Input data transformed by the learned mapping.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="dml.pca.PCA.transformer">
<code class="descname">transformer</code><a class="headerlink" href="#dml.pca.PCA.transformer" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtains the learned projection.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>L</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(d’xd) matrix, where d’ is the desired output dimension and d is the number of features.</span></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-dml.tune">
<span id="dml-tune-module"></span><h2>dml.tune module<a class="headerlink" href="#module-dml.tune" title="Permalink to this headline">¶</a></h2>
<p>Tune utilities for distance metric learning.</p>
<p>Created on Fri Feb  9 19:29:06 2018</p>
<p>&#64;author: jlsuarezdiaz</p>
<dl class="function">
<dt id="dml.tune.cross_validate">
<code class="descclassname">dml.tune.</code><code class="descname">cross_validate</code><span class="sig-paren">(</span><em>alg</em>, <em>X</em>, <em>y</em>, <em>n_folds=5</em>, <em>n_reps=1</em>, <em>verbose=False</em>, <em>seed=None</em><span class="sig-paren">)</span><a class="headerlink" href="#dml.tune.cross_validate" title="Permalink to this definition">¶</a></dt>
<dd><p>Cross validation for a classifier.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>alg</strong> <span class="classifier-delimiter">:</span> <span class="classifier">object.</span></dt>
<dd><p class="first last">A classifier. It must support the methods fit(X,y) and score(X,y), as specified in <code class="xref py py-class docutils literal"><span class="pre">ClassifierMixin</span></code>.</p>
</dd>
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N x d)</span></dt>
<dd><p class="first last">Training vector, where N is the number of samples, and d is the number of features.</p>
</dd>
<dt><strong>y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N)</span></dt>
<dd><p class="first last">Labels vector, where N is the number of samples.</p>
</dd>
<dt><strong>n_folds</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=5</span></dt>
<dd><p class="first last">Number of folds for cross validation.</p>
</dd>
<dt><strong>n_reps</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=1</span></dt>
<dd><p class="first last">Number of cross validations to do.</p>
</dd>
<dt><strong>verbose</strong> <span class="classifier-delimiter">:</span> <span class="classifier">boolean, default=False</span></dt>
<dd><p class="first last">If True, a console log will be printed.</p>
</dd>
<dt><strong>seed</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, RandomState instance or None, optional, default=None</span></dt>
<dd><p class="first last">If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <cite>np.random</cite>. Used when <code class="docutils literal"><span class="pre">shuffle</span></code> == True.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>results</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Pandas Dataframe</span></dt>
<dd><p class="first last">A matrix whose rows represent each fold of the cross validation, including also the mean and the std.
The columns represent the score, the fit time and the predict time of the classifier.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="dml.tune.metadata_cross_validate">
<code class="descclassname">dml.tune.</code><code class="descname">metadata_cross_validate</code><span class="sig-paren">(</span><em>dml</em>, <em>X</em>, <em>y</em>, <em>metrics</em>, <em>n_folds=5</em>, <em>n_reps=1</em>, <em>verbose=False</em>, <em>seed=None</em>, <em>**knn_args</em><span class="sig-paren">)</span><a class="headerlink" href="#dml.tune.metadata_cross_validate" title="Permalink to this definition">¶</a></dt>
<dd><p>Cross validation for distance metric learning algorithms using metadata as metrics.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>dml</strong> <span class="classifier-delimiter">:</span> <span class="classifier">DML_Algorithm</span></dt>
<dd><p class="first last">The distance metric learning algorithm to tune.</p>
</dd>
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N x d)</span></dt>
<dd><p class="first last">Training vector, where N is the number of samples, and d is the number of features.</p>
</dd>
<dt><strong>y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N)</span></dt>
<dd><p class="first last">Labels vector, where N is the number of samples.</p>
</dd>
<dt><strong>metrics</strong> <span class="classifier-delimiter">:</span> <span class="classifier">list of string and int</span></dt>
<dd><p class="first last">The metrics to evaluate. If string, it must be a key of the metadata() function of the DML Algorithm,
or ‘time’. In this last case, the elapsed fitting time will be returned as a metric.
If int, the metric will be the k-NN score, where k is the specified int.</p>
</dd>
<dt><strong>n_folds</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=5</span></dt>
<dd><p class="first last">Number of folds for cross validation.</p>
</dd>
<dt><strong>n_reps</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=1</span></dt>
<dd><p class="first last">Number of cross validations to do.</p>
</dd>
<dt><strong>verbose</strong> <span class="classifier-delimiter">:</span> <span class="classifier">boolean, default=False</span></dt>
<dd><p class="first last">If True, a console log will be printed.</p>
</dd>
<dt><strong>seed</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, RandomState instance or None, optional, default=None</span></dt>
<dd><p class="first last">If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <cite>np.random</cite>. Used when <code class="docutils literal"><span class="pre">shuffle</span></code> == True.</p>
</dd>
<dt><strong>knn_args</strong> <span class="classifier-delimiter">:</span> <span class="classifier">dictionary.</span></dt>
<dd><p class="first last">Additional keyword arguments for k-NN.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>results</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Pandas Dataframe</span></dt>
<dd><p class="first last">A matrix whose rows represent each fold of the cross validation, including also the mean and the std.
The columns represent the scores of each of the metrics specified.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="dml.tune.tune">
<code class="descclassname">dml.tune.</code><code class="descname">tune</code><span class="sig-paren">(</span><em>dml</em>, <em>X</em>, <em>y</em>, <em>dml_params</em>, <em>tune_args</em>, <em>metrics</em>, <em>n_folds=5</em>, <em>n_reps=1</em>, <em>verbose=False</em>, <em>seed=None</em>, <em>**knn_args</em><span class="sig-paren">)</span><a class="headerlink" href="#dml.tune.tune" title="Permalink to this definition">¶</a></dt>
<dd><p>Tune function for a distance metric learning algorithm, allowing as metrics the algorithm metadata,
times and k-NN scores.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>dml</strong> <span class="classifier-delimiter">:</span> <span class="classifier">A DML_Algorithm subclass</span></dt>
<dd><p class="first last">The distance metric algorithm class to tune.</p>
</dd>
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N x d)</span></dt>
<dd><p class="first last">Training vector, where N is the number of samples, and d is the number of features.</p>
</dd>
<dt><strong>y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N)</span></dt>
<dd><p class="first last">Labels vector, where N is the number of samples.</p>
</dd>
<dt><strong>dml_params</strong> <span class="classifier-delimiter">:</span> <span class="classifier">dictionary</span></dt>
<dd><p class="first last">Additional keyword parameters for the distance metric learning algorithm.</p>
</dd>
<dt><strong>tune_args</strong> <span class="classifier-delimiter">:</span> <span class="classifier">dictionary</span></dt>
<dd><p class="first last">Parameters of the DML algorithm to tune. Each key has to be a keyword argument of the DML. The associated values have to be
lists containing all the desired values for the tuning parameters.</p>
</dd>
<dt><strong>metrics</strong> <span class="classifier-delimiter">:</span> <span class="classifier">list of string and int</span></dt>
<dd><p class="first last">The metrics to evaluate. If string, it must be a key of the metadata() function of the DML Algorithm,
or ‘time’. In this last case, the elapsed fitting time will be returned as a metric.
If int, the metric will be the k-NN score, where k is the specified int.</p>
</dd>
<dt><strong>n_folds</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=5</span></dt>
<dd><p class="first last">Number of folds for cross validation.</p>
</dd>
<dt><strong>n_reps</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=1</span></dt>
<dd><p class="first last">Number of cross validations to do.</p>
</dd>
<dt><strong>verbose</strong> <span class="classifier-delimiter">:</span> <span class="classifier">boolean, default=False</span></dt>
<dd><p class="first last">If True, a console log will be printed.</p>
</dd>
<dt><strong>seed</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, RandomState instance or None, optional, default=None</span></dt>
<dd><p class="first last">If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <cite>np.random</cite>. Used when <code class="docutils literal"><span class="pre">shuffle</span></code> == True.</p>
</dd>
<dt><strong>knn_args</strong> <span class="classifier-delimiter">:</span> <span class="classifier">dictionary.</span></dt>
<dd><p class="first last">Additional keyword arguments for k-NN.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>tune_results</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Pandas Dataframe</span></dt>
<dd><p class="first last">A dataframe whose entries are all the cases considered for the tune parameters, and with a single column
that shows the cross validation score for each case.</p>
</dd>
<dt><strong>best_performance</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Tuple</span></dt>
<dd><p class="first last">A pair with the best case obtained, together with its corresponding score.</p>
</dd>
<dt><strong>best_dml</strong> <span class="classifier-delimiter">:</span> <span class="classifier">DML_Algorithm</span></dt>
<dd><p class="first last">The DML Algorithm object that obtained the best result in the tuning.</p>
</dd>
<dt><strong>detailed_results</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Dictionary</span></dt>
<dd><p class="first last">A dictionary whose keys are all the possible cases, and each entry is the cross validation table for the
corresponding case, containing the scores for every fold.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="dml.tune.tune_knn">
<code class="descclassname">dml.tune.</code><code class="descname">tune_knn</code><span class="sig-paren">(</span><em>dml</em>, <em>X</em>, <em>y</em>, <em>n_neighbors</em>, <em>dml_params</em>, <em>tune_args</em>, <em>n_folds=5</em>, <em>n_reps=1</em>, <em>verbose=False</em>, <em>seed=None</em>, <em>**knn_args</em><span class="sig-paren">)</span><a class="headerlink" href="#dml.tune.tune_knn" title="Permalink to this definition">¶</a></dt>
<dd><p>A tune function for a distance metric learning algorithm, using k-NN score as metric.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>dml</strong> <span class="classifier-delimiter">:</span> <span class="classifier">A DML_Algorithm subclass</span></dt>
<dd><p class="first last">The distance metric algorithm class to tune.</p>
</dd>
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N x d)</span></dt>
<dd><p class="first last">Training vector, where N is the number of samples, and d is the number of features.</p>
</dd>
<dt><strong>y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape (N)</span></dt>
<dd><p class="first last">Labels vector, where N is the number of samples.</p>
</dd>
<dt><strong>n_neighbors</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">Number of neighbors for k-NN.</p>
</dd>
<dt><strong>dml_params</strong> <span class="classifier-delimiter">:</span> <span class="classifier">dictionary</span></dt>
<dd><p class="first last">Additional keyword parameters for the distance metric learning algorithm.</p>
</dd>
<dt><strong>tune_args</strong> <span class="classifier-delimiter">:</span> <span class="classifier">dictionary</span></dt>
<dd><p class="first last">Parameters of the DML algorithm to tune. Each key has to be a keyword argument of the DML. The associated values have to be
lists containing all the desired values for the tuning parameters.</p>
</dd>
<dt><strong>n_folds</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=5</span></dt>
<dd><p class="first last">Number of folds for cross validation.</p>
</dd>
<dt><strong>n_reps</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=1</span></dt>
<dd><p class="first last">Number of cross validations to do.</p>
</dd>
<dt><strong>verbose</strong> <span class="classifier-delimiter">:</span> <span class="classifier">boolean, default=False</span></dt>
<dd><p class="first last">If True, a console log will be printed.</p>
</dd>
<dt><strong>seed</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, RandomState instance or None, optional, default=None</span></dt>
<dd><p class="first last">If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <cite>np.random</cite>. Used when <code class="docutils literal"><span class="pre">shuffle</span></code> == True.</p>
</dd>
<dt><strong>knn_args</strong> <span class="classifier-delimiter">:</span> <span class="classifier">dictionary.</span></dt>
<dd><p class="first last">Additional keyword arguments for k-NN.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>tune_results</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Pandas Dataframe</span></dt>
<dd><p class="first last">A dataframe whose entries are all the cases considered for the tune parameters, and with a single column
that shows the cross validation score for each case.</p>
</dd>
<dt><strong>best_performance</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Tuple</span></dt>
<dd><p class="first last">A pair with the best case obtained, together with its corresponding score.</p>
</dd>
<dt><strong>best_dml</strong> <span class="classifier-delimiter">:</span> <span class="classifier">DML_Algorithm</span></dt>
<dd><p class="first last">The DML Algorithm object that obtained the best result in the tuning.</p>
</dd>
<dt><strong>detailed_results</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Dictionary</span></dt>
<dd><p class="first last">A dictionary whose keys are all the possible cases, and each entry is the cross validation table for the
corresponding case, containing the scores for every fold.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="module-dml">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-dml" title="Permalink to this headline">¶</a></h2>
<p>The Distance Metric Learning module.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
      
        <a href="modules.html" class="btn btn-neutral" title="dml" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Juan Luis Suárez Díaz.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'0.0.1',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>