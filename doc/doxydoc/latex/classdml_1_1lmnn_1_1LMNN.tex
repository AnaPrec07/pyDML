\hypertarget{classdml_1_1lmnn_1_1LMNN}{}\section{dml.\+lmnn.\+L\+M\+NN Class Reference}
\label{classdml_1_1lmnn_1_1LMNN}\index{dml.\+lmnn.\+L\+M\+NN@{dml.\+lmnn.\+L\+M\+NN}}


Inheritance diagram for dml.\+lmnn.\+L\+M\+NN\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=264pt]{classdml_1_1lmnn_1_1LMNN__inherit__graph}
\end{center}
\end{figure}


Collaboration diagram for dml.\+lmnn.\+L\+M\+NN\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=264pt]{classdml_1_1lmnn_1_1LMNN__coll__graph}
\end{center}
\end{figure}
\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
def {\bfseries \+\_\+\+\_\+init\+\_\+\+\_\+} (self, num\+\_\+dims=None, learning\+\_\+rate=\char`\"{}adaptive\char`\"{}, eta0=0.\+3, initial\+\_\+metric=None, max\+\_\+iter=100, prec=1e-\/8, tol=1e-\/8, k=3, mu=0.\+5, soft\+\_\+comp\+\_\+interval=1, learn\+\_\+inc=1.\+01, learn\+\_\+dec=0.\+5, eta\+\_\+thres=1e-\/14, solver=\char`\"{}\+S\+D\+P\char`\"{})\hypertarget{classdml_1_1lmnn_1_1LMNN_ab2ab17715d79b9c53b7a414fc8d7a347}{}\label{classdml_1_1lmnn_1_1LMNN_ab2ab17715d79b9c53b7a414fc8d7a347}

\item 
def \hyperlink{classdml_1_1lmnn_1_1LMNN_a112eee35ecdb3476172f4ac4ad2a4c40}{metadata} (self)
\item 
def \hyperlink{classdml_1_1lmnn_1_1LMNN_ac69c9741352a38851e85172b25766af6}{fit} (self, X, y)
\item 
def \hyperlink{classdml_1_1lmnn_1_1LMNN_a06e4bb50c7f50b7e6bac689743198b32}{predict} (self, X=None)
\end{DoxyCompactItemize}
\subsection*{Public Attributes}
\begin{DoxyCompactItemize}
\item 
{\bfseries num\+\_\+dims\+\_\+}\hypertarget{classdml_1_1lmnn_1_1LMNN_afcdbb5898f7f30b6625a4ae89e253064}{}\label{classdml_1_1lmnn_1_1LMNN_afcdbb5898f7f30b6625a4ae89e253064}

\item 
{\bfseries M0\+\_\+}\hypertarget{classdml_1_1lmnn_1_1LMNN_a6b70e7d61aa51b093fb0ce59d12584b9}{}\label{classdml_1_1lmnn_1_1LMNN_a6b70e7d61aa51b093fb0ce59d12584b9}

\item 
{\bfseries max\+\_\+it\+\_\+}\hypertarget{classdml_1_1lmnn_1_1LMNN_aee92343b4aaf79834b86de6d36a35d4d}{}\label{classdml_1_1lmnn_1_1LMNN_aee92343b4aaf79834b86de6d36a35d4d}

\item 
{\bfseries eta0\+\_\+}\hypertarget{classdml_1_1lmnn_1_1LMNN_af54000da768085101c9b5d93c08b3e25}{}\label{classdml_1_1lmnn_1_1LMNN_af54000da768085101c9b5d93c08b3e25}

\item 
{\bfseries eta\+\_\+}\hypertarget{classdml_1_1lmnn_1_1LMNN_ab1df778b4a67aceb70c3cf6a8c79ae9f}{}\label{classdml_1_1lmnn_1_1LMNN_ab1df778b4a67aceb70c3cf6a8c79ae9f}

\item 
{\bfseries learning\+\_\+}\hypertarget{classdml_1_1lmnn_1_1LMNN_ac6a4848ad7fb33bba32ffdb484d2948a}{}\label{classdml_1_1lmnn_1_1LMNN_ac6a4848ad7fb33bba32ffdb484d2948a}

\item 
{\bfseries adaptive\+\_\+}\hypertarget{classdml_1_1lmnn_1_1LMNN_a70f5a8d225cc5d65d4b870927ce944d3}{}\label{classdml_1_1lmnn_1_1LMNN_a70f5a8d225cc5d65d4b870927ce944d3}

\item 
{\bfseries eps\+\_\+}\hypertarget{classdml_1_1lmnn_1_1LMNN_a439da790aa374144e4eaca184b744f1b}{}\label{classdml_1_1lmnn_1_1LMNN_a439da790aa374144e4eaca184b744f1b}

\item 
{\bfseries tol\+\_\+}\hypertarget{classdml_1_1lmnn_1_1LMNN_a3b6c6b17a5ffab3a9d8614b0c48bdfea}{}\label{classdml_1_1lmnn_1_1LMNN_a3b6c6b17a5ffab3a9d8614b0c48bdfea}

\item 
{\bfseries mu\+\_\+}\hypertarget{classdml_1_1lmnn_1_1LMNN_a32684b7381e1f8c440583426546e9fbd}{}\label{classdml_1_1lmnn_1_1LMNN_a32684b7381e1f8c440583426546e9fbd}

\item 
{\bfseries k\+\_\+}\hypertarget{classdml_1_1lmnn_1_1LMNN_a2d5495135fa0b1810a67aa321a1e1832}{}\label{classdml_1_1lmnn_1_1LMNN_a2d5495135fa0b1810a67aa321a1e1832}

\item 
{\bfseries soft\+\_\+comp\+\_\+interval\+\_\+}\hypertarget{classdml_1_1lmnn_1_1LMNN_aaa7bffb95d46970b92c898e4b367a462}{}\label{classdml_1_1lmnn_1_1LMNN_aaa7bffb95d46970b92c898e4b367a462}

\item 
{\bfseries l\+\_\+inc\+\_\+}\hypertarget{classdml_1_1lmnn_1_1LMNN_a50ce218d4840e05839eb84b4ecc8c1ca}{}\label{classdml_1_1lmnn_1_1LMNN_a50ce218d4840e05839eb84b4ecc8c1ca}

\item 
{\bfseries l\+\_\+dec\+\_\+}\hypertarget{classdml_1_1lmnn_1_1LMNN_ad3c3dd709e5e8d41785847f3b6ef2d7d}{}\label{classdml_1_1lmnn_1_1LMNN_ad3c3dd709e5e8d41785847f3b6ef2d7d}

\item 
{\bfseries etamin\+\_\+}\hypertarget{classdml_1_1lmnn_1_1LMNN_a1fc05f5581985840ce49c1207ca45315}{}\label{classdml_1_1lmnn_1_1LMNN_a1fc05f5581985840ce49c1207ca45315}

\item 
{\bfseries solver\+\_\+}\hypertarget{classdml_1_1lmnn_1_1LMNN_aa4b40032aa6c3da2c3b20da8038d66c1}{}\label{classdml_1_1lmnn_1_1LMNN_aa4b40032aa6c3da2c3b20da8038d66c1}

\item 
{\bfseries num\+\_\+its\+\_\+}\hypertarget{classdml_1_1lmnn_1_1LMNN_ad916f82a407b90af4db2bc5d47222cdf}{}\label{classdml_1_1lmnn_1_1LMNN_ad916f82a407b90af4db2bc5d47222cdf}

\item 
{\bfseries initial\+\_\+error\+\_\+}\hypertarget{classdml_1_1lmnn_1_1LMNN_aa398128acb2b0df7b694bbc212d526c3}{}\label{classdml_1_1lmnn_1_1LMNN_aa398128acb2b0df7b694bbc212d526c3}

\item 
{\bfseries final\+\_\+error\+\_\+}\hypertarget{classdml_1_1lmnn_1_1LMNN_a9a24b07e143896e64d6879761bc3a897}{}\label{classdml_1_1lmnn_1_1LMNN_a9a24b07e143896e64d6879761bc3a897}

\item 
{\bfseries target\+\_\+neighbors\+\_\+}\hypertarget{classdml_1_1lmnn_1_1LMNN_a12d7f9b1bbb7730f617cfd618cfd3a91}{}\label{classdml_1_1lmnn_1_1LMNN_a12d7f9b1bbb7730f617cfd618cfd3a91}

\item 
{\bfseries M\+\_\+}\hypertarget{classdml_1_1lmnn_1_1LMNN_a5f5322f8e73abd730cf68689f04eefab}{}\label{classdml_1_1lmnn_1_1LMNN_a5f5322f8e73abd730cf68689f04eefab}

\item 
{\bfseries y\+\_\+}\hypertarget{classdml_1_1lmnn_1_1LMNN_a910e52ed27c964b56a30c34b01e7e21e}{}\label{classdml_1_1lmnn_1_1LMNN_a910e52ed27c964b56a30c34b01e7e21e}

\item 
{\bfseries d\+\_\+}\hypertarget{classdml_1_1lmnn_1_1LMNN_ad286d75fd9c06a901d56eadee26a64e1}{}\label{classdml_1_1lmnn_1_1LMNN_ad286d75fd9c06a901d56eadee26a64e1}

\item 
{\bfseries nd\+\_\+}\hypertarget{classdml_1_1lmnn_1_1LMNN_a69cc3e9fd8cda8d92c20f8505282dea1}{}\label{classdml_1_1lmnn_1_1LMNN_a69cc3e9fd8cda8d92c20f8505282dea1}

\item 
{\bfseries L\+\_\+}\hypertarget{classdml_1_1lmnn_1_1LMNN_a96df0b36af8bafc77b7f0b7c522417e0}{}\label{classdml_1_1lmnn_1_1LMNN_a96df0b36af8bafc77b7f0b7c522417e0}

\item 
{\bfseries X\+\_\+}\hypertarget{classdml_1_1lmnn_1_1LMNN_a4c5e97d524842b7ec2ca0d9ea65f9e04}{}\label{classdml_1_1lmnn_1_1LMNN_a4c5e97d524842b7ec2ca0d9ea65f9e04}

\end{DoxyCompactItemize}


\subsection{Detailed Description}
\begin{DoxyVerb}Large Margin Nearest Neighbors (LMNN)

A distance metric learning algorithm that obtains a metric with target neighbors as near as possible and impostors as far as possible

Parameters
----------

num_dims : int, default=None

    Desired value for dimensionality reduction. Ignored if solver is 'SDP'.

learning_rate : string, default='adaptive'

    Type of learning rate update for gradient descent. Possible values are:

    - 'adaptive' : the learning rate will increase if the gradient step is succesful, else it will decrease.

    - 'constant' : the learning rate will be constant during all the gradient steps.

eta0 : int, default=0.3

    The initial value for learning rate.

initial_metric : 2D-Array or Matrix (d' x d), or string, default=None.

    If array or matrix, and solver is SDP, it must be a positive semidefinite matrix with the starting metric (d x d) for gradient descent, where d is the number of features.
    If None, euclidean distance will be used. If a string, the following values are allowed:

    - 'euclidean' : the euclidean distance.

    - 'scale' : a diagonal matrix that normalizes each attribute according to its range will be used.

    If solver is SGD, then the array or matrix will represent a linear map (d' x d), where d' is the dimension provided in num_dims.

max_iter : int, default=100

    Maximum number of iterations of gradient descent.

prec : float, default=1e-8

    Precision stop criterion (gradient norm).

tol : float, default=1e-8

    Tolerance stop criterion (difference between two iterations)

k : int, default=3

    Number of target neighbors to take. If this algorithm is used for nearest neighbors classification, a good choice is
    to take k as the number of neighbors.

mu : float, default=0.5

    The weight of the push error in the minimization algorithm. The objective function is composed of a push error, given by the impostors,
    with weight mu, and a pull error, given by the target neighbors, with weight (1-mu). It must be between 0.0 and 1.0.

soft_comp_interval : int, default=1

    Intervals of soft computation. The soft computation relaxes the gradient descent conditions, but makes the algorithm more efficient.
    This value provides the length of a soft computation interval. After soft_comp_interval iterations of gradient descent, a complete
    gradient step is performed.

learn_inc : float, default=1.01

    Increase factor for learning rate. Ignored if learning_rate is not 'adaptive'.

learn_dec : float, default=0.5

    Decrease factor for learning rate. Ignored if learning_rate is not 'adaptive'.

eta_thres : float, default=1e-14

    A learning rate threshold stop criterion.

solver : string, default='SDP'

    The algorithm used for minimization. Allowed values are:

    - 'SDP' : semidefinite programming, consisting of gradient descent with projections onto the positive semidefinite cone.
              It learns a metric.

    - 'SGD' : stochastic gradient descent. It learns a linear transformer.

References
----------
    Kilian Q Weinberger and Lawrence K Saul. “Distance metric learning for large margin nearest
    neighbor classification”. In: Journal of Machine Learning Research 10.Feb (2009), pages 207-244.
\end{DoxyVerb}
 

\subsection{Member Function Documentation}
\index{dml\+::lmnn\+::\+L\+M\+NN@{dml\+::lmnn\+::\+L\+M\+NN}!fit@{fit}}
\index{fit@{fit}!dml\+::lmnn\+::\+L\+M\+NN@{dml\+::lmnn\+::\+L\+M\+NN}}
\subsubsection[{\texorpdfstring{fit(self, X, y)}{fit(self, X, y)}}]{\setlength{\rightskip}{0pt plus 5cm}def dml.\+lmnn.\+L\+M\+N\+N.\+fit (
\begin{DoxyParamCaption}
\item[{}]{self, }
\item[{}]{X, }
\item[{}]{y}
\end{DoxyParamCaption}
)}\hypertarget{classdml_1_1lmnn_1_1LMNN_ac69c9741352a38851e85172b25766af6}{}\label{classdml_1_1lmnn_1_1LMNN_ac69c9741352a38851e85172b25766af6}
\begin{DoxyVerb}Fit the model from the data in X and the labels in y.

Parameters
----------
X : array-like, shape (N x d)
    Training vector, where N is the number of samples, and d is the number of features.

y : array-like, shape (N)
    Labels vector, where N is the number of samples.

Returns
-------
self : object
    Returns the instance itself.
\end{DoxyVerb}
 \index{dml\+::lmnn\+::\+L\+M\+NN@{dml\+::lmnn\+::\+L\+M\+NN}!metadata@{metadata}}
\index{metadata@{metadata}!dml\+::lmnn\+::\+L\+M\+NN@{dml\+::lmnn\+::\+L\+M\+NN}}
\subsubsection[{\texorpdfstring{metadata(self)}{metadata(self)}}]{\setlength{\rightskip}{0pt plus 5cm}def dml.\+lmnn.\+L\+M\+N\+N.\+metadata (
\begin{DoxyParamCaption}
\item[{}]{self}
\end{DoxyParamCaption}
)}\hypertarget{classdml_1_1lmnn_1_1LMNN_a112eee35ecdb3476172f4ac4ad2a4c40}{}\label{classdml_1_1lmnn_1_1LMNN_a112eee35ecdb3476172f4ac4ad2a4c40}
\begin{DoxyVerb}Obtains algorithm metadata.

Returns
-------
meta : A dictionary with the following metadata:
    - num_iters : Number of iterations that the descent method took.

    - initial_error : Initial value of the objective function.

    - final_error : Final value of the objective function.
\end{DoxyVerb}
 \index{dml\+::lmnn\+::\+L\+M\+NN@{dml\+::lmnn\+::\+L\+M\+NN}!predict@{predict}}
\index{predict@{predict}!dml\+::lmnn\+::\+L\+M\+NN@{dml\+::lmnn\+::\+L\+M\+NN}}
\subsubsection[{\texorpdfstring{predict(self, X=\+None)}{predict(self, X=None)}}]{\setlength{\rightskip}{0pt plus 5cm}def dml.\+lmnn.\+L\+M\+N\+N.\+predict (
\begin{DoxyParamCaption}
\item[{}]{self, }
\item[{}]{X = {\ttfamily None}}
\end{DoxyParamCaption}
)}\hypertarget{classdml_1_1lmnn_1_1LMNN_a06e4bb50c7f50b7e6bac689743198b32}{}\label{classdml_1_1lmnn_1_1LMNN_a06e4bb50c7f50b7e6bac689743198b32}
\begin{DoxyVerb}Predict the class labels for the provided data, according to the LMNN energy method.

Parameters
----------
X : array-like, shape (N x d)

    Test samples. N is the number of samples and d the number of features. If None, training set will be used.

Returns
-------
y : array of shape (N)

    Class labels for each data sample.
\end{DoxyVerb}
 

The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
dml/lmnn.\+pyx\end{DoxyCompactItemize}
