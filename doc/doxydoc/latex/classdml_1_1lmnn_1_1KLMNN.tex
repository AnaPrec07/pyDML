\hypertarget{classdml_1_1lmnn_1_1KLMNN}{}\section{dml.\+lmnn.\+K\+L\+M\+NN Class Reference}
\label{classdml_1_1lmnn_1_1KLMNN}\index{dml.\+lmnn.\+K\+L\+M\+NN@{dml.\+lmnn.\+K\+L\+M\+NN}}


Inheritance diagram for dml.\+lmnn.\+K\+L\+M\+NN\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=192pt]{classdml_1_1lmnn_1_1KLMNN__inherit__graph}
\end{center}
\end{figure}


Collaboration diagram for dml.\+lmnn.\+K\+L\+M\+NN\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=192pt]{classdml_1_1lmnn_1_1KLMNN__coll__graph}
\end{center}
\end{figure}
\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
def {\bfseries \+\_\+\+\_\+init\+\_\+\+\_\+} (self, num\+\_\+dims=None, learning\+\_\+rate=\char`\"{}adaptive\char`\"{}, eta0=0.\+3, initial\+\_\+metric=None, max\+\_\+iter=100, prec=1e-\/8, tol=1e-\/8, k=3, mu=0.\+5, learn\+\_\+inc=1.\+01, learn\+\_\+dec=0.\+5, eta\+\_\+thres=1e-\/14, kernel=\char`\"{}linear\char`\"{}, gamma=\+None, degree=3, coef0=1, kernel\+\_\+params=\+None, target\+\_\+selection=\char`\"{}kernel\char`\"{})\hypertarget{classdml_1_1lmnn_1_1KLMNN_a339202f51571616cccbb7e82a9538277}{}\label{classdml_1_1lmnn_1_1KLMNN_a339202f51571616cccbb7e82a9538277}

\item 
def \hyperlink{classdml_1_1lmnn_1_1KLMNN_a77fd2cabceaea0fb542887add9dbeac0}{transformer} (self)
\item 
def \hyperlink{classdml_1_1lmnn_1_1KLMNN_aeb84c2956168954dbfddec72a01bc5dd}{metadata} (self)
\item 
def \hyperlink{classdml_1_1lmnn_1_1KLMNN_aed2b8b1e6de22d4e6170d4a270d78623}{fit} (self, X, y)
\end{DoxyCompactItemize}
\subsection*{Public Attributes}
\begin{DoxyCompactItemize}
\item 
{\bfseries num\+\_\+dims\+\_\+}\hypertarget{classdml_1_1lmnn_1_1KLMNN_abb851de27ec3faff37051a238f394643}{}\label{classdml_1_1lmnn_1_1KLMNN_abb851de27ec3faff37051a238f394643}

\item 
{\bfseries M0\+\_\+}\hypertarget{classdml_1_1lmnn_1_1KLMNN_ac4aed1cb11a11a2570f5a4079014145b}{}\label{classdml_1_1lmnn_1_1KLMNN_ac4aed1cb11a11a2570f5a4079014145b}

\item 
{\bfseries max\+\_\+it\+\_\+}\hypertarget{classdml_1_1lmnn_1_1KLMNN_a961924ae72463b2a081067479cc30874}{}\label{classdml_1_1lmnn_1_1KLMNN_a961924ae72463b2a081067479cc30874}

\item 
{\bfseries eta0\+\_\+}\hypertarget{classdml_1_1lmnn_1_1KLMNN_a8fc7f13d4728fbf2d59a29628d9fd541}{}\label{classdml_1_1lmnn_1_1KLMNN_a8fc7f13d4728fbf2d59a29628d9fd541}

\item 
{\bfseries eta\+\_\+}\hypertarget{classdml_1_1lmnn_1_1KLMNN_a29432e1998af99476b418dd3306e19d2}{}\label{classdml_1_1lmnn_1_1KLMNN_a29432e1998af99476b418dd3306e19d2}

\item 
{\bfseries learning\+\_\+}\hypertarget{classdml_1_1lmnn_1_1KLMNN_ab36d0340d3db07c79ad5ce558de81e6d}{}\label{classdml_1_1lmnn_1_1KLMNN_ab36d0340d3db07c79ad5ce558de81e6d}

\item 
{\bfseries adaptive\+\_\+}\hypertarget{classdml_1_1lmnn_1_1KLMNN_a9b1766d62f27a9fcf1dd08955eea24a2}{}\label{classdml_1_1lmnn_1_1KLMNN_a9b1766d62f27a9fcf1dd08955eea24a2}

\item 
{\bfseries eps\+\_\+}\hypertarget{classdml_1_1lmnn_1_1KLMNN_a8690102a13c5833ff12975e566ac009e}{}\label{classdml_1_1lmnn_1_1KLMNN_a8690102a13c5833ff12975e566ac009e}

\item 
{\bfseries tol\+\_\+}\hypertarget{classdml_1_1lmnn_1_1KLMNN_ac4b57f8045030eec291099398fde02d0}{}\label{classdml_1_1lmnn_1_1KLMNN_ac4b57f8045030eec291099398fde02d0}

\item 
{\bfseries mu\+\_\+}\hypertarget{classdml_1_1lmnn_1_1KLMNN_ae6bcf5f3ad2428e949671b07cbec638f}{}\label{classdml_1_1lmnn_1_1KLMNN_ae6bcf5f3ad2428e949671b07cbec638f}

\item 
{\bfseries k\+\_\+}\hypertarget{classdml_1_1lmnn_1_1KLMNN_ae08243645a6f30a97eaa150b45a2d0d3}{}\label{classdml_1_1lmnn_1_1KLMNN_ae08243645a6f30a97eaa150b45a2d0d3}

\item 
{\bfseries l\+\_\+inc\+\_\+}\hypertarget{classdml_1_1lmnn_1_1KLMNN_a967624698fe38a0088950d28db6febc9}{}\label{classdml_1_1lmnn_1_1KLMNN_a967624698fe38a0088950d28db6febc9}

\item 
{\bfseries l\+\_\+dec\+\_\+}\hypertarget{classdml_1_1lmnn_1_1KLMNN_ab4ed062fa5d6b209a1c77dce08a09e0a}{}\label{classdml_1_1lmnn_1_1KLMNN_ab4ed062fa5d6b209a1c77dce08a09e0a}

\item 
{\bfseries etamin\+\_\+}\hypertarget{classdml_1_1lmnn_1_1KLMNN_a977173f0328b2a58321e821c9d41b291}{}\label{classdml_1_1lmnn_1_1KLMNN_a977173f0328b2a58321e821c9d41b291}

\item 
{\bfseries target\+\_\+selection\+\_\+}\hypertarget{classdml_1_1lmnn_1_1KLMNN_aff31653d53a27d82e71d424cd93f404d}{}\label{classdml_1_1lmnn_1_1KLMNN_aff31653d53a27d82e71d424cd93f404d}

\item 
{\bfseries kernel\+\_\+}\hypertarget{classdml_1_1lmnn_1_1KLMNN_a3146f3cf23dd6a51717f45122e9fda22}{}\label{classdml_1_1lmnn_1_1KLMNN_a3146f3cf23dd6a51717f45122e9fda22}

\item 
{\bfseries gamma\+\_\+}\hypertarget{classdml_1_1lmnn_1_1KLMNN_abc910753eb9d73a87723794717442af0}{}\label{classdml_1_1lmnn_1_1KLMNN_abc910753eb9d73a87723794717442af0}

\item 
{\bfseries degree\+\_\+}\hypertarget{classdml_1_1lmnn_1_1KLMNN_ae5913646ad15aa139f56c4b8ed664e49}{}\label{classdml_1_1lmnn_1_1KLMNN_ae5913646ad15aa139f56c4b8ed664e49}

\item 
{\bfseries coef0\+\_\+}\hypertarget{classdml_1_1lmnn_1_1KLMNN_a0d2e3c2fd07d4e5461ff4539f4010aa2}{}\label{classdml_1_1lmnn_1_1KLMNN_a0d2e3c2fd07d4e5461ff4539f4010aa2}

\item 
{\bfseries kernel\+\_\+params\+\_\+}\hypertarget{classdml_1_1lmnn_1_1KLMNN_ac4645004c02107578699d63837bc1e33}{}\label{classdml_1_1lmnn_1_1KLMNN_ac4645004c02107578699d63837bc1e33}

\item 
{\bfseries num\+\_\+its\+\_\+}\hypertarget{classdml_1_1lmnn_1_1KLMNN_a3e2148e093e6b53110904c598a6d01cf}{}\label{classdml_1_1lmnn_1_1KLMNN_a3e2148e093e6b53110904c598a6d01cf}

\item 
{\bfseries initial\+\_\+error\+\_\+}\hypertarget{classdml_1_1lmnn_1_1KLMNN_afe372e1a7bd5c6f011fd5b7e3a4c9c3f}{}\label{classdml_1_1lmnn_1_1KLMNN_afe372e1a7bd5c6f011fd5b7e3a4c9c3f}

\item 
{\bfseries final\+\_\+error\+\_\+}\hypertarget{classdml_1_1lmnn_1_1KLMNN_a96e24c68a6c15bb57ef4aff80a74be9b}{}\label{classdml_1_1lmnn_1_1KLMNN_a96e24c68a6c15bb57ef4aff80a74be9b}

\item 
{\bfseries d\+\_\+}\hypertarget{classdml_1_1lmnn_1_1KLMNN_a06aff9be6116a21617b5887961b7cd95}{}\label{classdml_1_1lmnn_1_1KLMNN_a06aff9be6116a21617b5887961b7cd95}

\item 
{\bfseries nd\+\_\+}\hypertarget{classdml_1_1lmnn_1_1KLMNN_a8d387f7a0308e26a4b4f813d892327dd}{}\label{classdml_1_1lmnn_1_1KLMNN_a8d387f7a0308e26a4b4f813d892327dd}

\item 
{\bfseries L\+\_\+}\hypertarget{classdml_1_1lmnn_1_1KLMNN_ac43a8d7ba9a1c15dfe40de49e2293a84}{}\label{classdml_1_1lmnn_1_1KLMNN_ac43a8d7ba9a1c15dfe40de49e2293a84}

\item 
{\bfseries X\+\_\+}\hypertarget{classdml_1_1lmnn_1_1KLMNN_a9e090d67748917ad69b44dfcd3d49109}{}\label{classdml_1_1lmnn_1_1KLMNN_a9e090d67748917ad69b44dfcd3d49109}

\item 
{\bfseries y\+\_\+}\hypertarget{classdml_1_1lmnn_1_1KLMNN_afee6f4ee6b30f1b0ee3adfacd37c50ee}{}\label{classdml_1_1lmnn_1_1KLMNN_afee6f4ee6b30f1b0ee3adfacd37c50ee}

\end{DoxyCompactItemize}


\subsection{Detailed Description}
\begin{DoxyVerb}The kernelized version of LMNN.

Parameters
----------

num_dims : int, default=None

    Desired value for dimensionality reduction. Ignored if solver is 'SDP'.

learning_rate : string, default='adaptive'

    Type of learning rate update for gradient descent. Possible values are:

    - 'adaptive' : the learning rate will increase if the gradient step is succesful, else it will decrease.

    - 'constant' : the learning rate will be constant during all the gradient steps.

eta0 : float, default=0.3

    The initial value for learning rate.

initial_metric : 2D-Array or Matrix (d' x d), or string, default=None.

    If array or matrix, and solver is SDP, it must be a positive semidefinite matrix with the starting metric (d x d) for gradient descent, where d is the number of features.
    If None, euclidean distance will be used. If a string, the following values are allowed:

    - 'euclidean' : the euclidean distance.

    - 'scale' : a diagonal matrix that normalizes each attribute according to its range will be used.

    If solver is SGD, then the array or matrix will represent a linear map (d' x d), where d' is the dimension provided in num_dims.

max_iter : int, default=100

    Maximum number of iterations of gradient descent.

prec : float, default=1e-8

    Precision stop criterion (gradient norm).

tol : float, default=1e-8

    Tolerance stop criterion (difference between two iterations)

k : int, default=3

    Number of target neighbors to take. If this algorithm is used for nearest neighbors classification, a good choice is
    to take k as the number of neighbors.

mu : float, default=0.5

    The weight of the push error in the minimization algorithm. The objective function is composed of a push error, given by the impostors,
    with weight mu, and a pull error, given by the target neighbors, with weight (1-mu). It must be between 0.0 and 1.0.

learn_inc : float, default=1.01

    Increase factor for learning rate. Ignored if learning_rate is not 'adaptive'.

learn_dec : float, default=0.5

    Decrease factor for learning rate. Ignored if learning_rate is not 'adaptive'.

eta_thres : float, default=1e-14

    A learning rate threshold stop criterion.

kernel : "linear" | "poly" | "rbf" | "sigmoid" | "cosine" | "precomputed"
    Kernel. Default="linear".

gamma : float, default=1/n_features
    Kernel coefficient for rbf, poly and sigmoid kernels. Ignored by other
    kernels.

degree : int, default=3
    Degree for poly kernels. Ignored by other kernels.

coef0 : float, default=1
    Independent term in poly and sigmoid kernels.
    Ignored by other kernels.

kernel_params : mapping of string to any, default=None
    Parameters (keyword arguments) and values for kernel passed as
    callable object. Ignored by other kernels.

target_selecion : string, default='kernel'

    How to find the target neighbors. Allowed values are:

    - 'kernel' : using the euclidean distance in the kernel space.

    - 'original' : using the euclidean distance in the original space.

References
----------
    Kilian Q Weinberger and Lawrence K Saul. “Distance metric learning for large margin nearest
    neighbor classification”. In: Journal of Machine Learning Research 10.Feb (2009), pages 207-244.

    Lorenzo Torresani and Kuang-chih Lee. “Large margin component analysis”. In: Advances in neural
    information processing systems. 2007, pages 1385-1392.
\end{DoxyVerb}
 

\subsection{Member Function Documentation}
\index{dml\+::lmnn\+::\+K\+L\+M\+NN@{dml\+::lmnn\+::\+K\+L\+M\+NN}!fit@{fit}}
\index{fit@{fit}!dml\+::lmnn\+::\+K\+L\+M\+NN@{dml\+::lmnn\+::\+K\+L\+M\+NN}}
\subsubsection[{\texorpdfstring{fit(self, X, y)}{fit(self, X, y)}}]{\setlength{\rightskip}{0pt plus 5cm}def dml.\+lmnn.\+K\+L\+M\+N\+N.\+fit (
\begin{DoxyParamCaption}
\item[{}]{self, }
\item[{}]{X, }
\item[{}]{y}
\end{DoxyParamCaption}
)}\hypertarget{classdml_1_1lmnn_1_1KLMNN_aed2b8b1e6de22d4e6170d4a270d78623}{}\label{classdml_1_1lmnn_1_1KLMNN_aed2b8b1e6de22d4e6170d4a270d78623}
\begin{DoxyVerb}Fit the model from the data in X and the labels in y.

Parameters
----------
X : array-like, shape (N x d)
    Training vector, where N is the number of samples, and d is the number of features.

y : array-like, shape (N)
    Labels vector, where N is the number of samples.

Returns
-------
self : object
    Returns the instance itself.
\end{DoxyVerb}
 \index{dml\+::lmnn\+::\+K\+L\+M\+NN@{dml\+::lmnn\+::\+K\+L\+M\+NN}!metadata@{metadata}}
\index{metadata@{metadata}!dml\+::lmnn\+::\+K\+L\+M\+NN@{dml\+::lmnn\+::\+K\+L\+M\+NN}}
\subsubsection[{\texorpdfstring{metadata(self)}{metadata(self)}}]{\setlength{\rightskip}{0pt plus 5cm}def dml.\+lmnn.\+K\+L\+M\+N\+N.\+metadata (
\begin{DoxyParamCaption}
\item[{}]{self}
\end{DoxyParamCaption}
)}\hypertarget{classdml_1_1lmnn_1_1KLMNN_aeb84c2956168954dbfddec72a01bc5dd}{}\label{classdml_1_1lmnn_1_1KLMNN_aeb84c2956168954dbfddec72a01bc5dd}
\begin{DoxyVerb}Obtains algorithm metadata.

Returns
-------
meta : A dictionary with the following metadata:
    - 'num_iters' : Number of iterations that the descent method took.

    - 'initial_error' : Initial value of the objective function.

    - 'final_error' : Final value of the objective function.\end{DoxyVerb}
 \index{dml\+::lmnn\+::\+K\+L\+M\+NN@{dml\+::lmnn\+::\+K\+L\+M\+NN}!transformer@{transformer}}
\index{transformer@{transformer}!dml\+::lmnn\+::\+K\+L\+M\+NN@{dml\+::lmnn\+::\+K\+L\+M\+NN}}
\subsubsection[{\texorpdfstring{transformer(self)}{transformer(self)}}]{\setlength{\rightskip}{0pt plus 5cm}def dml.\+lmnn.\+K\+L\+M\+N\+N.\+transformer (
\begin{DoxyParamCaption}
\item[{}]{self}
\end{DoxyParamCaption}
)}\hypertarget{classdml_1_1lmnn_1_1KLMNN_a77fd2cabceaea0fb542887add9dbeac0}{}\label{classdml_1_1lmnn_1_1KLMNN_a77fd2cabceaea0fb542887add9dbeac0}
\begin{DoxyVerb}Obtains the learned projection.

Returns
-------
A : (d'x N) matrix, where d' is the desired output dimension, and N is the number of samples.
    To apply A to a new sample x, A must be multiplied by the kernel vector of dimension N
    obtained by taking the kernels between x and each training sample.
\end{DoxyVerb}
 

The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
dml/lmnn.\+pyx\end{DoxyCompactItemize}
